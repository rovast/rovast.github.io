{"meta":{"title":"rovast","subtitle":"rovast's blog","description":null,"author":"John Doe","url":"https://rovast.github.io"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-11-28T08:49:18.041Z","updated":"2020-11-28T08:49:18.041Z","comments":false,"path":"/404.html","permalink":"https://rovast.github.io//404.html","excerpt":"","text":""},{"title":"关于我","date":"2020-11-29T04:07:43.593Z","updated":"2020-11-29T04:07:43.593Z","comments":false,"path":"about/index.html","permalink":"https://rovast.github.io/about/index.html","excerpt":"","text":"后端里最懂前端的，前端里最懂后端的，架构中最懂业务的，业务里最懂架构的。 文能吹大道理，武能撸代码。 啥都懂，啥都不懂。 🍺 追求高效简洁的研发哲学。"},{"title":"友情链接","date":"2020-11-28T08:49:18.091Z","updated":"2020-11-28T08:49:18.091Z","comments":true,"path":"links/index.html","permalink":"https://rovast.github.io/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-11-28T08:49:18.090Z","updated":"2020-11-28T08:49:18.090Z","comments":false,"path":"categories/index.html","permalink":"https://rovast.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-11-28T08:49:18.091Z","updated":"2020-11-28T08:49:18.091Z","comments":false,"path":"tags/index.html","permalink":"https://rovast.github.io/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-11-28T08:49:18.091Z","updated":"2020-11-28T08:49:18.091Z","comments":false,"path":"repository/index.html","permalink":"https://rovast.github.io/repository/index.html","excerpt":"","text":""},{"title":"书单","date":"2020-11-28T08:49:18.090Z","updated":"2020-11-28T08:49:18.090Z","comments":false,"path":"books/index.html","permalink":"https://rovast.github.io/books/index.html","excerpt":"","text":""},{"title":"","date":"2020-11-28T09:37:39.141Z","updated":"2020-11-28T09:37:39.141Z","comments":true,"path":"downloads/code/test.js","permalink":"https://rovast.github.io/downloads/code/test.js","excerpt":"","text":"sdad"}],"posts":[{"title":"meshery 初步试用 & Service Mesh Performance(SMP) 了解","slug":"try-meshery","date":"2022-01-06T08:18:33.000Z","updated":"2022-01-06T08:45:59.215Z","comments":true,"path":"2022/01/06/try-meshery/","link":"","permalink":"https://rovast.github.io/2022/01/06/try-meshery/","excerpt":"","text":"First Try MesheryCreated: January 6, 2022 11:02 AM 零、总结SMP 是用来进行 Service Mesh 的性能测试而生的，并非实际的应用或集群的遥测。它定义了一致的性能测试标准，便于多 Service Mesh 进行统一横向性能比较(apples to apples performance comparisons)。 在 Mesh 和 Application 的遥测方面，Meshery 是通过接入 Grafana 或 Promethues 的方式来满足需求。 0.1 SMP（Service Mesh Performance）—— Service Mesh 性能测试（详情见 2.5 章节）SMP 是用来测试 Service Mesh 的性能表现的统一协议（数据格式）。通过一致的 protobuf 数据格式（在 Meshery 的源码中，就是 import 了 service-mesh-performance 的 go sdk），来完成不同 Service Mesh 的性能横向比较。 协议 按照定义的 metadata 数据接入新 Service Mesh 运行性能测试（图中的 11 是倒计时，点击 run test 后，就会产生一个大大的倒计时数字） 不同 Service Mesh 性能横向比较 0.2 SMI（Service Mesh Interface）这一块在平台上的体现是 SMI 协议合规度检测，从协议定义的 Traffic Spec、Traffic Split、Traffic Access 三个方向进行检测（由于暂未找到应用相关的数据，尚不知晓关于流量方便的具体平台展现形式）。 0.3 文档导读由于 Meshery 是 Layer5 的官方标准实现，此次调研以 Meshery 的平台为主要切入点，看其标准在平台上的具体落实情况来进一步了解，其调研的数据主要来源以下三个地方 官方文档（含 Github） 官方 YouTube 频道 官方提供的在线实验 一、环境准备使用 layer5 官方提供的在线 lab 来运行。 Interactive Service Mesh Labs 有以下两点需要注意： 按照步骤进行运行即可，需要注意的是，当我们正常安装 Meshery 后，添加 Provider 一般是不生效的，我们需要点击 terminal 的 + 号，选择 “Select port to view on Host1”，并且输入端口后 9081 才能访问系统。 另外，当我们正常安装完成后，可查看 meshery 状态都是 ready 后，方可打开 web 12345678$ mesheryctl system statusNAME READY STATUS RESTARTS AGE meshery 1/1 Running 0 2m30smeshery-broker 1/1 Running 0 1m7s meshery-linkerd 1/1 Running 0 2m30smeshery-operator 2/2 Running 0 2m30sMeshery endpoint is http://localhost:9081 通过体验 Meshery 的安装流程，我们发现其安装及其简单，通过一条指令即可完成，这是我们需要思考的，如何让用户以最小的心智来试用。 除了安装友好，在进入系统后，我们安装对应的 service mesh，或者安装示例程序，都是直接在平台上点击操作，无疑大大简化了用户的上手负担。 二、平台模块速览说明：由于实验环境很多数据缺失，所以部分页面从 YouTube 或其他地方截图所得，来源见附录。 2.1 平台初始化配置平台初始化配置主要完成以下工作：1、添加 Provider；2、登录 Choose a provider ↓ Login ↓ 2.2 平台菜单一览菜单分为以下几个部分 Performance(SMP). 用来对 Service Mesh 进行性能测试。 Conformance(SMI). 用来测试 Service Mesh 的协议合规度检测。 Lifecycle. 用来管理不同的 Service Mesh。 SMP&amp;SMI ↓ Configuration ↓ Lifecycle&amp;Service Meshes ↓ 2.3 DashboardDashboard without data Dashboard with data Service Mesh 看板显示了当前接入的 mesh 和组件 Metrics 直接嵌入的 Grafana 或 Promethues 面板 2.4 Install Service Mesh通过 Meshery 可以管理多种 Service Mesh，我们可以在 meshery 中直接添加 service mesh 和示例程序。 Linkerd Adapter 点击加号，添加 Linkerd Service Mesh 点击加号，添加示例程序 2.5 Performance2.5.1 Performance DashboardPerformance Dashboard without data Performance Dashboard with data 2.5.2 ProfilesSMP Profiles without data SMP Profiles 列表 查看 SMP Profile 详情以及具体测试数据结果 ![Meshery - The Service Mesh Manager 35-47 screenshot.png] 2.5.1 Add ProfileProfile 表单 SMP Profile Service Mesh Options，选择具体的 Service Mesh SMP Profile Service Mesh Load Generator，选择负载产生器 SMP Profile Advanced Options，进一步定制压测的请求信息 2.5.4 Run TestRun test 运行测试，倒计时 View Performance Result 查看测试结果 Comparison 比较同一个 Profile 不同测试结果 这一点和 SMP 文档中 apple to apple performance comparison 相对应 2.6 Add Service Mesh MetricsConfigure Service Mesh Metrics Add Grafana Add Promethues Environment &amp; In Cluster Deployment Service Meshes 2.7 Conformance(SMI)在 Manage Service Mesh 地方执行 SMI 协议检测 Service Mesh Interface Conformance Results, SMI 协议标准合规情况检测 摘自文档的更多检查结果 附录 YouTube, Meshery - The Service Mesh Manager Meshery - The Service Mesh Manager Performance Management 文档 Performance Management Run SMI Conformance 文档 Running SMI Conformance Tests","categories":[],"tags":[{"name":"云原生","slug":"云原生","permalink":"https://rovast.github.io/tags/云原生/"}]},{"title":"优雅统一处理 JS 错误(Sentry 上报场景)","slug":"elegant-handler-error-with-sentry","date":"2021-09-18T05:28:30.000Z","updated":"2021-09-18T13:44:55.253Z","comments":true,"path":"2021/09/18/elegant-handler-error-with-sentry/","link":"","permalink":"https://rovast.github.io/2021/09/18/elegant-handler-error-with-sentry/","excerpt":"","text":"一、背景Sentry 可以有效帮助我们发现项目中存在的问题。经过一段时间的使用和了解，我们对其中的错误进行了汇总。 我们发现有大量的错误是由于 HTTP 请求 400 或者 401 导致。 二、错误分析现有的 MSP 请求封装了统一的 request 请求，对 request.repsonse 进行了 interceptor 操作。即：进行了 response 的统一处理，由自己处理完后再返回给业务层。 之前我们在 interceptors.response 中对部分业务码进行了统一处理，如：401 未授权跳转到登录页。 之前为了忽略部分状态码，直接进行了 return 操作，此操作后，业务层会进入 Promise.then 环节。由于在 http status 400 或 401 情况下，API 返回的数据格式异常，所以导致了 Cannot read property of null 的错误。 request-helper.js 的 return 操作 12345678910111213141516171819if (statusCode === 401) &#123; // 未授权的登录，这种情况需要重定向到登录页面 if (window.location.pathname === '/login') return Modal.confirm(&#123; title: '提示', content: '您当前处于未登录状态，部分功能无法使用', okText: '去登录', cancelText: '停留在此页', onOk: () =&gt; &#123; store.dispatch('user/resetToken').then(() =&gt; &#123; window.location.reload() &#125;) &#125;, onCancel: () =&gt; &#123; &#125; &#125;) return&#125; user.js 读取 1234567891011refreshToken(&#123; commit &#125;) &#123; return new Promise((resolve, reject) =&gt; &#123; refreshToken().then(response =&gt; &#123; const &#123; data &#125; = response // 拿不到有效的数据，所以 data 为 null commit('SET_TOKEN', data) resolve() &#125;).catch(error =&gt; &#123; reject(error) &#125;) &#125;) &#125; 三、处理分析关于部分请求的错误，如 401、403我们需要进行放行。理由如下 401，用户没有授权，属于正常业务逻辑，不需要上报 400，参数认证失败，属于正常的业务逻辑，不需要上报 500，待定，此类问题一般由于内部错误导致（还有发版时会遇到），可以先正常上报。 所以我们看到，需要对 reponse 进行统一的兜底处理。但是我们发起方是在业务代码里(vue文件），所以是否存在 业务层的统一处理？ 答案是：存在的。借助 window.onunhandledrejection 统一处理异常 main.js 1234window.onunhandledrejection = function(error) &#123; console.log(`Promise failed: $&#123;error.reason&#125;`) error.preventDefault() // 抑制终端报错&#125; 业务 user.js 12345678return new Promise((resolve, reject) =&gt; &#123; getInfo().then(res =&gt; &#123; commit('SET_USERNAME', username) resolve(username) &#125;).catch(e =&gt; &#123; console.log('业务自行处理异常') reject('我抛给了统一处理') &#125;) 终端输出 猜想：sentry 或者 vue，会不会使用这种方式统一捕捉错误。如果大家都用了，这个错误就不能有效传导了。所以我们需要保留其他已注册函数的处理句柄。 12345678910111213const _oldHandler = window.onunhandledrejectionwindow.onunhandledrejection = function(error) &#123; _oldHandler.apply(this, arguments) console.log(`Promise failed1: $&#123;error.reason&#125;`) error.preventDefault()&#125;const _oldHandler2 = window.onunhandledrejectionwindow.onunhandledrejection = function(error) &#123; _oldHandler2.apply(this, arguments) console.log(`Promise failed2: $&#123;error.reason&#125;`) error.preventDefault()&#125; 通过保留上次处理函数句柄的方式，可以有效传导 四、实现综上，我们设定一个全局的错误处理函数来进行错误捕捉，而不用逐个去修改源码。处理方式如下 1）request 层正常 reject 所有错误（即：正常向上 throw error） 2）在 main.js 中注册全局的错误处理函数 4.1 正常 reject error之前由于其他地方零零散散的会上报错误，部分被注释了，现在统一打开，正常在 Promoise.reject 4.2 注册全局处理函数main.js 注册全局处理函数 12345import &#123; globalErrorHandler &#125; from './error-handler'initSentry(Vue, router)// 自己的全局处理函数一定要在 sentry 后面，这样可以拦截到他的错误上报函数，进而进行 hookglobalErrorHandler() error-handler.js 处理错误 1234567891011121314151617181920212223// 定义需要忽略上报的 http status codeconst SkipHttpStatus = [400, 401]// 处理全局错误export function globalErrorHandler() &#123; const originalErrorHandler = window.onunhandledrejection window.onunhandledrejection = function(error) &#123; const request = error.reason.request if (request) &#123; // 捕捉请求类错误，统一处理状态码 // http status code const status = error.reason.request.status if (SkipHttpStatus.includes(status)) &#123; console.log('Ignore request error, cause the http status is [%s]', status) error.preventDefault() // 取消控制台的报错 return &#125; &#125; // 其他情况，正常上报错误即可，这里主要就是 sentry 注册的处理函数 originalErrorHandler.apply(this, arguments) // 执行之前注册的错误处理函数 &#125;&#125; 这里需要注意的是，需要先拦截到 sentry 的钩子，然后进行对应的情况处理。 当满足我们忽略条件时，不再进行上报。其他情况，正常上报 五、总结 不要干扰正常的异常抛出流程，该抛出异常时，大胆抛出 使用统一处理函数 window.onunhandledrejection 进行统一错误捕获。基本上目前主流的语言(或框架)都会提供统一的错误处理机制，所以首先想到的一定是“统一”处理，而不是每个业务代码都去改动。 PHP 错误全局捕获 set_exception_handler set_error_handler https://www.php.net/manual/en/function.set-error-handler.php https://www.php.net/manual/en/function.set-exception-handler.php 注意使用 window.onunhandledrejection 时，不要干扰已经注册的处理函数，所以可以先“暂存”，之后再“恢复”。这个和 PHP 内核拓展开发时，hook内置的函数有异曲同工之妙。 PHP 内核示例12345678910111213141516171819202122// 通过在 Module Init 环节拦截函数入口，进而 Hook，进行一系列自定义处理PHP_MINIT_FUNCTION(skywalking)&#123; ZEND_INIT_MODULE_GLOBALS(skywalking, php_skywalking_init_globals, NULL); //data_register_hashtable(); REGISTER_INI_ENTRIES(); /* If you have INI entries, uncomment these lines */ if (SKYWALKING_G(enable)) &#123; if (strcasecmp(\"cli\", sapi_module.name) == 0 &amp;&amp; cli_debug == 0) &#123; return SUCCESS; &#125; // 用户自定义函数执行器(php脚本定义的类、函数) ori_execute_ex = zend_execute_ex; zend_execute_ex = sky_execute_ex; // 内部函数执行器(c语言定义的类、函数) ori_execute_internal = zend_execute_internal; zend_execute_internal = sky_execute_internal;","categories":[],"tags":[]},{"title":"","slug":"jia-ban","date":"2021-05-11T01:22:41.039Z","updated":"2021-05-11T01:26:21.779Z","comments":true,"path":"2021/05/11/jia-ban/","link":"","permalink":"https://rovast.github.io/2021/05/11/jia-ban/","excerpt":"","text":"【转】侯慧 何雪松|“不加班不成活”：互联网员工为何沦为流水线上的“加班狗”|劳动节专辑②原创 侯慧 何雪松 探索与争鸣杂志;) 1周前 原文：https://mp.weixin.qq.com/s/87bhDCwhNvSvDg93qvYO_w 编者按：又到了“五一”劳动节。“劳动”是与每个人日常生活息息相关的关键词，中华人民共和国成立以来，“劳动光荣”的风尚一度领社会之风骚。而近年来，在全球化、信息化、工业化、城市化的大时代面前，劳动、劳动者的问题，变得相对复杂化。“处长体验送外卖”等反映劳动者生存状况的事件，牵动着许多人的心。劳动价格被置于市场的天平下反复称量，劳动政策常常游走于现实的夹缝，劳动关系正在经受利益关系微妙的变化和价值冲突严峻的考验。在新的社会条件下，越来越多的人意识到“劳动”不仅是一个经济问题。《探索与争鸣》一贯强调学术研究的问题导向，关注社会前沿议题。近年来，就互联网劳动、数字劳动、情绪劳动等新兴问题，《探索与争鸣》策划了一系列专题讨论。值此“五一”之际，本刊微信公众号推出劳动节专辑，集结这一领域的优质文章，回顾“劳动”概念在中国的历史，审视今天诸多新兴业态中的劳动状况，探索优化劳动者生存状况的可能路径，期望为当下社会最关切的问题提供专家的视角和智慧。 侯慧|华东理工大学社会与公共管理学院博士研究生 何雪松|华东理工大学社会与公共管理学院社会工作系教授 本文原载于《探索与争鸣》2020年第5期 原题《“不加班不成活”：互联网知识劳工的劳动体制》 在过去的一段时间，一个名为“996.ICU”的项目在 GitHub 上发布并引起众多互联网企业员工的跟帖反馈。“996.ICU”意为“早上九点上班、晚上 9 点下班，一周工作 6 天，迟早生病住进重症监护室(ICU)”，项目旨在揭露实行“996”工作制的互联网企业，共同抵制行业普遍存在的高强度加班状况。一周时间内，有 104 家公司被写入“996 公司名单”，国内一系列知名的互联网企业位列其中，可见，“加班”已经成为互联网知识劳工较为普遍的劳动状态。 与普通的工人相比，互联网知识劳工似乎更具自主性与创造性，而这也成为学界对知识劳工核心特点的概括，有学者如梁萌进一步认为知识工人因为掌握着知识社会中稀缺的资源与生产手段——知识，故而可归为“资产阶级”。但在现实中，互联网知识劳工却展现出与此迥然相异的状况。面对如此学术想象与现实之间的张力，亟须从互联网知识劳工生存的内部去寻找其特有的运行逻辑，以理解在不同的社会与技术背景之中互联网知识劳工的常态化加班何以形成，以及对知识劳工产生何种影响。基于此，本文选取互联网企业中重要的一类知识劳工——页面设计师(简称 UI 设计师，主要负责软件的页面设计)为分析对象，采用滚雪球的取样方法和半结构式深度访谈法，从互联网企业知识劳工的劳动过程入手，着重分析互联网企业的劳动控制与知识劳工的自主性发挥机制，尝试揭示互联网知识劳工的劳动生态及“加班”背后的作用机制，为理解知识劳工的劳动生态与制度建议奠定实践基础。 图源：简书App 劳动控制与劳工自主性：理解互联网产业劳动体制的一个理论框架 知识劳工(knowledge worker)这一概念最早由德鲁克提出，指涉在知识经济中具有高等教育经历并具备理论分析能力的新雇佣工作群体，随后这一概念在管理学、社会学等多个学科中被广泛使用。随着网络社会与信息经济的发展，互联网领域知识劳工的类型不断更新迭代，从仅包含硬件从业者扩展至软件的设计者、开发者等知识劳工类别。在这一领域的研究中，主要存在两种理论视角 : 一种是沿袭马克思主义传统，认为劳动控制仍然是劳动过程中的核心问题。资本组织生产的核心目标就是最大限度地获取剩余价值，这就需要拥有对劳动过程的控制权，控制成为劳动过程中的基本问题。从这一理论传统出发，研究认为知识劳工虽然在工作形式上与传统工业的劳工有所差异，但就本质而言仍然在生产中被资本所控制与剥削，其拥有的自主性是片面甚至虚假的，由此研究主要聚焦于资本在互联网知识劳动过程中的控制机制分析。在互联网企业中，资本逐渐发展出适应于互联网技术变迁的“规范控制”(normative control)、责任自治与直接控制等多种管理策略，以达到更为隐秘与严格的劳动控制。互联网时代中竞争激烈的劳动力市场强化了知识劳工“不稳定的工作”(Precarious Work)状态，从而使劳资关系失衡，更加剧了资本的控制与知识劳工被剥削的状态。 图源：东方资讯 另一种是韦伯的理论传统，认为劳动自主性是知识劳工相关研究的基本前提假设。知识劳工因为掌握了最重要的资本——知识，故而在知识经济中有更高的自主性，也拥有其独特的文化资本 ，其阶级位置较产业工人更高。研究主张自主性是知识劳工创新力与工作效率提升的关键 ，同时相较工业生产，互联网技术本身具有自由开放的文化特征，更激发了互联网知识劳工的文化自觉，故而互联网企业需要通过文化资本重塑影响知识劳工的主观意识，以形塑其对劳动与企业的认同。 上述两种理论视角中，马克思传统的研究主要强调劳动控制的客观层面，包括多种管控策略的形成，其中劳工自身被客体化；而韦伯传统的研究则聚焦劳动过程的主观层面，关注劳工的自主性以及资本建构意识形态的策略，二者的分析面向各有侧重。与传统工业时代相比，互联网经济中的知识劳动发生着新的变化，在互联网知识劳动的研究中，两种视角的割裂往往将互联网知识劳动议题的研究片面化。而在这两个理论视角整合的努力中，布洛维的研究无疑提供了一条重要的线索。他通过田野研究试图回答为什么在严苛的管理控制之下，工厂里的工人没有反抗反而卷入赶工游戏之中，研究中既从技术演进与控制方面探讨了劳动控制策略，也关照到劳工的主体性层面，指出工厂“超额”文化使工人产生一种对劳动过程的志愿性服从并生产出对这种生产关系的认同，制造了对于劳动过程的“同意”。布洛维的研究不仅扩展了在马克思主义理论传统框架下对劳动过程与劳动者的理解，也将工人的主体性置于研究的核心位置。 受此启发，本文尝试从布洛维的意识线索出发，以劳动控制与劳工自主性的互构视角作为互联网劳工“加班”的劳动体制的概念工具，力图呈现互联网知识劳动的生态及其所引发的理论反思与对策建议。 布洛维 “制造同意”:互联网企业的劳动控制 互联网企业的劳动控制机制具有隐蔽性与高压性，其通过项目制与弹性工作制度的运作，加之严格的绩效考核、末位淘汰与文化策略等，以期实现知识劳工对于常态化加班的接纳。与此相关的是，其对知识劳工创新性与高质量产出的负面影响，常态化的加班中知识劳工正在遭遇工作与生活边界混沌的状态。 (一)项目制与弹性工作制度的运作 首先，与传统工业劳动形式不同的是，互联网公司大多以项目制为生产的主要推动方式，即根据特定的需求，各个部门抽调员工组成特定虚拟团队，一般包括项目经理(PMO)、产品经理(PM)、交互设计师 (UE)、界面设计师(UI)、程序员(RD)、质量控制(QA)等工种的知识劳工，互相配合执行项目。首先，项目制运作中掩盖了知识劳工的超负荷工作，并将加班归为自愿的劳动付出，从而大大降低了企业的付薪成本。在项目制运作的逻辑中，规定时间内完成项目任务成为核心目标。这里的项目制与传统工业的计件式劳动形式有着一定的区别，传统工业以计件直接勾连个体利益，以此激发工人的主动性，而在互联网企业的项目制中，每个成员形成一环扣一环的项目推进机制，一旦有成员超期往往会影响整个项目的进度。在这样的压力下，很多 UI 设计师不得不选择加班，以在规定时间内完成自己的工作任务，“为赶项目而加班”成为大多数受访者提到的主要加班原因。 其次，弹性工作制度打破了知识劳工工作和生活的边界，使得工作对知识劳工的生活形成挤压侵占态势。大多数互联网公司并不执行严格的上下班打卡制度，而是遵循弹性的工作制度，即知识劳工可以在完成项目任务的前提下自由安排自己的工作时间。如受访者 F5 所述，这似乎是一个悖论，表面上，公司给予了员工足够的自由，但在高压的项目任务中往往没有自由，还要搭上休息时间。具体来说，弹性工作制度似乎给予了他们足够的自由与自主性，可以自己掌控上下班时间、工作进度等。但在现实的工作中，受访的员工们的工作任务和时间期限都十分紧张，很难实现所谓的自主性，这里的弹性与自主性显然是片面的、难以实现的。在 F11 的陈述中，公司领导并不会公开提倡加班，主要提倡自由自主，更提倡尽责、高产，然而，其潜台词便是如果没完成项目，就意味着没有尽责，所带来的结果就是要加班完成。可见，公司管理层将“不加班”作为口号，但在具体操作中难以实现。 这背后是项目制的量化设置问题。资本的目标是最大限度地获取剩余价值，尤其当互联网企业被资本投资，其预期收益会推动着企业高速发展，员工不得不被要求承担起更为紧迫的劳动产出任务，援引受访者 F6 的描述，“项目任务永远饱和”，在受访的 11 位 UI 设计师讲述中，不加班的状况少之又少。当 F6 提到一段短暂的不加班经历时，也指出部门总不加班时直属领导直接被叫去谈话询问任务是否饱和，随即项目任务便压了下来，开始常态化加班。可见，“调整项目任务量以达到饱和”成为资本更为隐蔽的管控手段，而标准被潜在地界定为“是否需要加班”，于是项目任务与工作时间形成了一定的必然联系，使知识劳工不得不面对长时间、超负荷的脑力劳动。 再则，项目制中的沟通与开会协调，也成为知识劳动中的重要时间支出，而如此的时间支出并不能直接体现在任务完成量中，造成留给知识劳工具体做任务的时间少之又少。项目制的运作中不仅涉及知识劳工技术任务的完成，还需要跨部门的合作以提供解决方案，沟通就成为项目完成的必要基础。与编程、设计等硬技术不同，沟通这一软技术也成为知识劳工的必备要件。F5提到，每天开会和沟通的时间至少占到工作时间的三分之一，很多项目事宜需要不断开会讨论。在项目制的运作中，开会与沟通占去了UI设计师大量的时间与精力，但开会又是项目运作中不可或缺的环节，故而受访的设计师们不得不牺牲休息时间，以补充做任务的时间以完成目标。 可见，项目制与灵活工作制度成为互联网知识劳工免费加班与同意加班的制度基础，对知识劳工形成了更为隐蔽的剥削与控制。在项目制的目标导向之下，知识劳工卷入到努力完成项目任务的“赶工游戏”之中，使知识劳工的自主性被压制，从而为加班形成同意机制。 (二)绩效考核 在互联网企业中，针对员工的工作评估主要依托绩效考核制度，即 KPI(Key PerformanceIndicator)。运用这一考核制度，公司将总目标分解至各部门、各个劳动者，通过可量化的测量指标进行评估，以此来决定知识劳工的职级升降、薪资浮动甚至去留问题。企业通常一年会进行2~4 次的绩效考核，而评估工作主要由员工的直属上级完成。 首先，知识劳动与传统工业的劳动在劳动性质上存在较大区别，例如 UI 设计因其偏向智慧技能而非经验技能，很难以类似车间工人“计件”的量化标准来衡量，那么绩效很大程度上与直属上级的认同相关，其主观判断占据较大比重。正如 F2 所述，智慧技能即他们的工作产出是一个个用户使用页面，每张页面设计所付出的时间、效果都存在着较大差异，衡量标准涉及美感、用户的好感等抽象化判断，很难客观性地量化，因此直属上级的主观打分就成为重要的一项评估内容。在这其中加班虽然不会被写入考核指标中，但在受访者的反馈中，“加班”的确会成为同等情况下重要的加分项。 其次，一些企业虽然执行弹性工作时间制度，但在实际操作中还是会将“工时”作为绩效考核的评估项。F4 提到其公司年底绩效包含工作时间这一栏，如果长期不加班，那么在这一项中便会失去竞争力，故而不得不选择为了绩效主动加班的策略。可见，在以项目完成情况为评估核心的绩效考核机制中，并未完全将工作时间的考量排除在外，其甚至仍隐形地处于重要地位。由于绩效考核直接关系到劳动者的晋升、奖惩甚至去留，绩效与加班机制的潜在关联让劳动者不得不倾向对于加班的屈从，甚至主动构筑起加班的怪圈。 图源：Apple Watch 广告 (三)末位淘汰与隐性裁员的“恐慌” 在互联网企业中，绩效考核不仅对于薪资、晋升形成影响，而且与淘汰制、隐形裁员直接挂钩，形成了对于知识劳工的残酷筛选机制。受访者提到，“2+7+1”是大部分互联网公司执行的人才管理计划，即对团队中 20% 超出预期完成工作的员工奖励和加薪；对 70% 仅达预期工作效果的员工给予一般加薪或正常奖励，对 10% 低于预期工作效果的员工进行淘汰。对于知识劳工来说，10% 是每个人都不愿触碰的底线。故而，对末位淘汰制的恐惧使其不得不在日常工作中更加努力，这样的考核压力几乎出现在每一个互联网知识劳工的身上。正如 F9 所讲，不想掉队的唯一选择就是加班拼命工作，因为这关系到去留，就难以考虑是否受到剥削。在这一方面，互联网公司与工厂形成了相似的方法，通过持续施压的手段来促使员工积极合作，即通过解雇那些不能达成给定配额的劳动者，使劳动者服从于规则。 同时，竞争激烈的互联网就业市场加剧了劳动者从业的不安全性，使企业在劳资关系中处于更加优势的地位，劳动者的权益受到威胁，使其呈现出无产化(Precariat)倾向，不安全感、不确定性成为主旋律，劳动者在如此失衡的关系中只得为谋生而被动地接受长期的高压环境，选择加班。F8 用“垫脚效应”为加班的机制做了形象的注解，正如剧场看剧，一人站起来获得了更好的视野，其他人也纷纷跟着站起来，如果有人更过分，不仅站起来，还踮起脚尖，就逼着后面的人也踮起脚尖。结果就是谁的视野也没更好，每个人都更累了，但是让谁坐下来谁也不干，看不到就意味着要被淘汰，逐渐就形成了怪圈。在以上描述中，将“站起来”“踮起脚”等比作同事间暗自较劲的加班比拼，这与布洛维所描写的工厂中形成的自愿性服从(voluntaryservitude)生产秩序十分相似，知识劳工也上演着类似的“赶工游戏”，但不同的是其背后驱使的不再是超额完成任务的获益，而是不能完成任务可能面临的淘汰，如此的恐慌动力替代了工业时代的获利动力。公司制度制造的恐慌使工人形成内化的自我控制与服从。他们严重透支着身体进行“赶工游戏”，甚至连自己的生活时间也受到严重的挤压，不安全感、恐慌焦虑感某种程度上远超过去的劳工。 那么，针对考核最后的 10% 员工，企业会直接选择开除吗？通常企业会给此类员工一定的时间进行调整与改进，但现实的情况并不如此乐观。很多企业会选择隐性裁员的策略，如 F5 的经验，公司一般并不会直接选择公然裁员，而是会采用边缘化的策略来迫使知识劳工主动提出辞职。无独有偶，F10 也提到公司的隐性裁员策略，例如不给晋升空间、开会不叫、项目不给、外派等，最后只能选择离开。上述受访者提到的公司边缘化隐性裁员策略并不少见。产业的高速发展，带来了资本的迅速涌入，但当行业逐渐冷却，资本回归理性，互联网企业面临着压力，在此情境下，企业随时可能以不负责任的方式缩减规模，尽管法律有不得随意裁员的规定，但是公司仍会使用不同的策略进行“隐性裁员”，这其中包括边缘化、关闭晋升渠道、外派等方式，从而倒逼劳动者主动提出辞职。这样的信息经由他人经历、新闻报道等途径为知识劳工所熟知，更加剧了知识劳工对于自身处境的恐慌与担忧，从而助推着对于加班的配合状态。 (四)全员加班文化 在互联网公司中，加班并不是以强制性的体制予以贯彻，而是以文化策略逐渐发展形成，在盛行的加班文化中，多数领导层都参与其中，形成了全员加班的文化氛围。如 F1 所提到，当周围同事和领导都在加班时，为了不显得另类，只得留下一起加班。此时“加班”成为员工是否合群的标准，加班文化使得员工无法完全按照个人意志选择加班与否，而是在领导同事都加班的氛围中，被迫选择融入集体一起加班，这种文化未被制度化写在纸上却深入每个员工内心。其中，知识劳工的自主性显然受到抑制，其不能自主地根据自身情况选择加班与否。 此外，在加班文化的营造中，公司虽然不会根据加班时长给予加班费用，但却会给出一些相关的加班福利，比如免费加班餐、加班打车费报销、免费班车等。在受访者的讲述中，几乎每个公司都有相关的加班福利，形式多样，种类繁多。这背后往往暗含着对于加班的支持，强化了企业对于加班的认可。笔者对 F1 所在公司进行探访时，免费零食角就曾引起我们的兴趣，一个货架上三分之二的空间里摆满了桶装的泡面和火腿肠，这也被公司员工戏称为“加班必备良品”。如此的加班文化以加班福利等形式深入知识劳工的内心，以期使员工形成自愿加班氛围。 为了使员工的加班更为积极，互联网公司还将“狼性文化”作为企业核心文化加以推崇。所谓的“狼性文化”指的是一种带有野、残、贪、暴的拼搏精神，对工作、对事业要有“贪性”，永无止境地去拼搏、探索。此前，不少互联网企业管理者都在公开场合表达了对狼性文化的推崇。这样的文化不仅铺垫了企业中优胜劣汰的机制，而且在现实操作中管理层也会将目标导向融入公司的文化叙事中，通过公司的团队建设、年会讲演等活动予以强化，从而努力使员工与企业的发展捆绑起来，激发员工对于加班的情感认同。但现实不然，F2 就表达了对于企业“空喊口号”的不满，因其工作生态与收入并无改善而无法形成对企业文化的认同。可见，互联网企业的文化策略并未被知识劳工全然接受，狼性文化大大压缩了知识劳工所拥有的自主空间，如此文化策略显然在落实中出现了名实不副的态势。只是在竞争激烈的就业市场中，知识劳工又不得不为谋生而选择继续留在公司，承受着不断加班的状态。 “弱者的武器”：互联网知识劳工的有限自主性 在互联网知识劳动中，赶工式加班的常态化使知识劳工的自主性受到压制，难以形成专业认同，并且创造性与体力的下降强化了劳动者的身心压力。虽然部分知识劳工选择主动学习、跳槽或转行等应对策略，但实质上并未改变加班机制中劳动者自主性式微的状态。 (一)“加班认同”：流水线上的“加班狗” 对于加班的劳动状态，知识劳工并未形成情感与专业认同。受访的 F6 形容自己为流水线上的“加班狗”，F4 自嘲为技术民工，背后都隐含着对知识劳动状态的评价，即和车间工人类似，重复性较高，工作时间过长，职业地位不高。这样的评价背后，既是受访设计师们的自嘲，亦是对于重复性工作的忧虑。随着互联网生态的变迁，资本对公司的效率要求越来越高，对个体和组织产出速度的要求也水涨船高。在这种情况下，互联网劳工很容易陷入劳动密集型的实质中，知识劳工也因此承受着更为紧迫的产出压力。然而，与传统工业时代的技术工人不同，互联网知识劳工除了完成生产任务之外，还必须保持不断更新的知识与技术，如果日常的工作时间全部用来完成项目任务，那么就意味着他们缺少了学习新知识技术的时间，就可能被技术迭代所淘汰，正如 F8 所述，当加班无法带来成长空间时，就无法对加班产生专业的认同。 此外，长期的加班状态也加深了受访者的身体与生活焦虑，加班使劳动者不得不长期处于超负荷的工作状态，对身体健康状况的负面影响十分明显。虽然不是纯体力劳动，知识劳工却可能因体力的下降，无法适应当下的知识劳动强度。大部分受访者都提到了腰椎、颈椎问题，加班的久坐对设计师的腰椎颈椎等产生较大的负担，有些甚至需要定期的理疗等方法予以缓解。同时，加班对于生活时间的侵蚀也使得知识劳工的生活与工作边界模糊。已婚受访者如 F8 提到了加班对于家庭生活的负面影响，长期的加班使家庭关系紧张，对家庭生活产生严重的负面影响，使劳动者承担了更重的身心压力，这与以往研究结果一致，加班产生的溢出效应使工作对家庭与休闲生活形成了明显的渗透，限制了已婚劳动者参与家庭生活的能力与时间，从而导致劳动者生活的失衡。对未婚劳动者而言，加班使休闲与社会参与时间严重减缩。受访的劳动者 F8 坦言，加班成为无奈之举，为了应对生活经济的压力，不得不继续选择硬撑。可见，在自主性与谋生之间，知识劳工不得不将天平更多地倾向于谋生，从而弱化了自身的自主性。 (二)“主动加班”：构筑职业“护城河” 当然，在众多被动接受加班的情形中，也存在部分知识劳工主动加班的情况，主动利用加班时间学习成为知识劳工加班的自主性体现。从劳工的角度来看，由于技术与劳动力市场的瞬息万变，知识与技能的更新对于他们获得更大范围的自主性至关重要。F1 与 F9 都表示在技术迭代如此之快的背景下，主动学习是必由之路，需要付出时间学习先进理念、技术，一部分的加班主要是在学习。可见，知识劳工有着区别于传统劳工的学习意识与动力，由此形成了部分积极的主动加班。F1 提到，由于知识与工具的迭代飞速，故而需要保持每天的学习状态，提升业务能力，了解用户的需求变化，指出了知识劳工对于知识更新的迫切需求。F9 则举例说明，过去无法想到外卖、共享单车的崛起，互联网的发展不断会冲破想象力，只有保持学习，拥有专业能力跟得上发展，才能构筑起自己的职业护城河。 可见，以互联网为依托的技术自我迭代速率加快，使得知识劳工需要主动更新知识，学习更为先进的知识技术，因此受访的设计师们在加班中也会主动去学习、调整自己的能力结构，以便适应技术、审美与知识的更新，从而跟上互联网的发展。用于主动学习的加班显然是知识劳工发挥其自主性的重要表现，这里的加班不再是企业的压力驱使，而是自身保持学习的内在动力使然，这甚至被一些知识劳工视为休闲、充实的时光，会在自主学习中感知自己的进步与成长，从而在一定程度上正面提升了知识劳工的生产力。当然，大多数受访者提到，赶项目仍然是加班的主要内容，尽管知识劳工对自主学习有着较为迫切的内生需求，但限于企业的繁重任务较难实现，超负荷的劳动控制使知识劳工难以发挥其主动学习的能动性。 (三)跳槽或转行 在互联网行业中，知识劳工的跳槽率仍然保持在较高的水平。一些知识劳工会在难以承受现公司的加班情况时，主动地选择跳槽，以寻找新的工作环境，跳槽成为知识劳工发挥自主性的途径。然而如 F8 所述，互联网行业存在着普遍的加班现象，几乎没有完全不加班的企业，因此只能在选择上倾向于加班较少的公司，完全拒绝加班在互联网行业基本难以达成。此时知识劳工的自主性发挥就受限于行业状态，在行业普遍加班的情境中，知识劳工的自主性呈现式微的态势。 这样的情况对于很多已婚已育的女性来说，更是难以平衡的抉择，任何程度的加班对于家庭、孩子都难以兼顾，故而受访的女性 UI 设计师提到不得不考虑选择转行。F7 提到，在行业中女性UI 设计师达到一定年龄转行是普遍现象，比如去广告公司做设计、开设工作室等实属无奈之举，当加班的工作与家庭的照顾难以兼顾时，需要作出牺牲与抉择，这凸显了已婚女性在知识劳动中的职业困境。很多已婚已育的女性在平衡家庭生活与工作之间，不得不作出转行的选择。而当跳槽难以解决加班问题时，知识劳工不得不选择跳出互联网行业以谋求新的职业发展路径，这对于大多数劳动者来说，都类似重新归零的选择。所以表面似充满自主性的跳槽或转行背后，也是知识劳工难以继续适应高强度劳动的权宜之策，甚至是无奈选择。 平衡家庭生活与工作的女性；图源：搜狐网 对互联网知识劳动体制的反思 在布洛维关于“制造同意”的讨论中，劳动控制与劳动自主性处于关键位置，因为正是劳动控制与劳动自主性共同形塑出“赶工游戏”这种劳动生态。但问题是，在信息时代背景下，不同的技术环境与劳动类别，却形成了“常态化加班”这种与“赶工游戏”类似的劳动生态，其中的运作机制有何不同？我们认为，在互联网时代中资本对知识劳动的控制本质并未改变，改变的仅是劳动控制的形式与运作机制。而对这一劳动体制的认识，需要置于互联网产业的金融化、知识技术的迭代化和工作的弹性化的三重脉络之中进行理解和认识。 互联网企业的发展与全球金融资本紧密连接，资本的力量已经通过全球化的浪潮深入到互联网的整个行业中，资本的逻辑加之全球化的推进不断型构着全球市场的格局，使互联网领域的知识劳动形成高度竞争性与流动性之态势，也使互联网知识劳工面临着全新的脆弱性。资本的逻辑即资本必须不断革新其产品与生产方式，通过节省劳动力、降低成本等以快速创造利润，资本逻辑挂帅的必然产物便是效率为先，公司作为经济增长的推动者，其中目标必然是提高竞争力、增加获利率，高度的逐利性与竞争性决定了企业将压力转嫁劳动者的生产过程，从而形成对于劳动者的赶工式加班控制机制。企业在项目制与弹性工作制中的“效率本位”取向，使其过分关注于“量”的完成而忽视了知识劳工的核心竞争力——主体性与创新性，表面上知识劳工似乎可以决定每日的工作，但是在效率化项目的执行逻辑中，劳工不得不进行常态化的加班以实现任务目标的达成，而这带来的后果是劳动产出“质”的方面难以形成创新性的突破以及劳工权益的缺失。卡斯特将这一状态下的互联网知识劳工定义为自我程控劳工(self-programmable labor)，“程控劳工”听来似乎磨灭了知识劳工的创造属性，成为科学管理监控下的机器，但这也正好印证了互联网知识劳动中的控制机制。与此同时，全球化的进程带来了更为灵活的劳动关系，不断增长的劳动力市场灵活性加剧了劳动者从业的不安全性。在严密的绩效考核制、末位淘汰与隐性裁员制度下，知识劳工必须在追求自主性与维持生计之间取得平衡，由此我们看到了在高度竞争化的劳动市场面前，知识劳工的自主性不断式微而脆弱。 全球化的时代中，互联网的发展与知识技术的高速迭代对互联网企业的创新提出了更高的要求，而作为互联网企业发展的核心动力，要求无疑最终下沉至知识劳工身上。技术的高速迭代不断重新界定着劳动过程和知识劳工，并带来劳动适应性与弹性需求的不断增加，知识劳工必须保持新技能的不断习得，形成劳动的“再技能化”。虽然大学教育提供了相关技术的基础，但实际上技术的更新与提升需要互联网知识劳工在工作中主动学习，这样的过程伴随技术迭代不断推进而永无休止。同时，一部分技术的迭代会造成现有技术的彻底无用，这意味着原有劳动技术积累的清零，其对于知识劳工来说更是巨大的挑战。而在常规的赶工式加班中，大多都是原有技术的重复使用，如此更是加剧了劳工对现有加班状态的焦虑。尽管研究中我们也看到了学习互联网劳工通过主动学习等形成主动的应对策略，但是赶工式的加班状态无疑成为主要阻碍。 受互联网文化的影响，平等、公平与弹性工作理念的倡导成为国内外互联网公司的特点，为适应此变化，企业提出了弹性工作制以期更好地调动知识劳工的主体性与能动性。但在现实中，我们看到弹性工作制下，工作时间的弹性化掩盖的是知识劳工为完成项目任务而不得不付出的额外无酬劳动时间，这也是资本从劳动者身上榨取剩余价值的过程。企业的项目制与弹性工作制以任务目标为导向，在表面上尊重知识劳工对于劳动时间等方面自主性的同时，以超额的项目任务为要求。尽管劳动者具有一定的工作自由，但在任务压力下，不得不付出额外的时间以完成目标。与此同时，弹性工作制使得加班成为免费的劳动付出，帮助资本降低了工资付出。需要厘清的是，弹性工制中不仅包括工作时间的弹性化，还包括劳动收入与去留的多向度弹性化，就此传统的以清晰职务分派和可预期职业生涯为特征的工作被取代，取而代之的是弹性的、不稳定的工作。这给知识劳工带来的是经济与生活的不安全感，也是知识劳工在如此高强度工作任务与压力之下选择服从的重要原因。虽然其间也会有跳槽、转行等应对策略，但总体而言，知识劳工的主体性依然十分受限。 由于基于互联网的产业有着强劲的发展空间，因此必须要思考建立以人的发展为中心的劳动体制。这一体制不应仅仅关注“劳动”及其“绩效”本身，而且要关注人的发展和创新潜能，强调知识劳工的自主性与能动性，重视工作与家庭和生活的平衡，建立员工友好的组织氛围。尤其是，知识劳工作为“活生生的个体”与冷冰冰的管理制度之间的张力，阻碍了创新的可能，过分的管控取向必然会使劳动趋于僵化，从而遏制知识劳工作为个人的创新发展。这就需要企业内部管理观念的转变与制度的革新，将组织的人力资本的提升置入更长的时间脉络中予以考量，从长远角度来为知识劳工提供专业成长、知识更新的空间。当然，在这一过程中，更需要让企业背后的资本回归理性，让整个行业呈现更为健康的发展态势，建立起更加完善的行业监督与保护体系。与此同时，政府也需要建立起相关的从业资格认证机制以及明确的知识劳工权益保障体系，从而在根本上保护知识劳工的主体性。 用劳动控制与劳动自主性的互构视角来检视互联网产业的劳动体制，亦有助于我们在互联网快速发展的今天深刻理解技术、资本对劳动的改变。事实上，互联网知识劳工的劳动过程及自主性需要放置在更长的时间与空间脉络中予以讨论，未来对于互联网知识劳动进一步深入的研究，将助于我们思考如何重构知识劳工的自主性以及如何形成良性的劳动生态，而这也是关系中国社会经济长期良性发展的重要环节。","categories":[],"tags":[]},{"title":"初探 http-streaming","slug":"http-straming-in-js","date":"2021-04-06T18:22:37.000Z","updated":"2021-04-11T02:33:53.108Z","comments":true,"path":"2021/04/06/http-straming-in-js/","link":"","permalink":"https://rovast.github.io/2021/04/06/http-straming-in-js/","excerpt":"","text":"基础概念HTTP 流简单的理解为：服务端维持一个 HTTP 连接，通过这个 HTTP 连接源源不断、持续的输出内容至客户端。相较于我们常见的 HTTP 请求(一次返回)，流处理的特点在于持续返回。 我们举个简单的应用场景：股票网站的股价更新。你可以使用轮询的方式，前端设置定时器周期性的请求股价接口来刷新股价。除此之外，可以使用 HTTP Streaming 的方式，只需要维持一个 HTTP 链接，就可以由后端自行将最新的股价信息 Push 到客户端来完成实时刷新。 同时需要注意，为了实现这种持续返回的效果，服务端需要在客户端返回的 Header 中设置 Transfer Encoding: chunked [2]。 To achieve an indefinite response, the server must respond to client requests by specifying Transfer Encoding: chunked in the header. This sets up a persistent connection from server to client and allows the server to send response data in chunks of newline-delimited strings. These chunks of data can then be received and processed on-the-fly by the client. 服务端初体验我们使用 php fpm + nginx，来完成服务端的 http 流输出。PHP 代码如下 1234567891011121314if (ob_get_level() == 0) ob_start();for ($i = 0; $i&lt;10; $i++)&#123; echo \"&lt;br&gt; Line to show. At\".date('Y-m-d H:i:s'); echo str_pad('',4096).\"\\n\"; ob_flush(); flush(); sleep(2);&#125;echo \"Done.\";ob_end_flush(); 我们看到其中有 str_pad(&#39;&#39;,4096)，为填充输出缓冲区，进而保障每次 flush 都有数据能输出到客户端。因为我们的服务经过 Nginx，而 Nginx 的 proxy_buffer_size [3] 默认是 4k，所以我们需要填充完缓冲区后，才能保证每次的 Server 端输出可以直接打到客户端。（当然了，你也可以关闭 Nginx 的缓冲区设置） 其输出为12345678910Line to show. At2021-04-11 01:54:52Line to show. At2021-04-11 01:54:54Line to show. At2021-04-11 01:54:56Line to show. At2021-04-11 01:54:58Line to show. At2021-04-11 01:55:00Line to show. At2021-04-11 01:55:02Line to show. At2021-04-11 01:55:04Line to show. At2021-04-11 01:55:06Line to show. At2021-04-11 01:55:08Line to show. At2021-04-11 01:55:10 Done. 对于客户端，我们也有简单的代码验证，关注浏览器开发者工具即可12345678910111213141516171819function watchResource(url, callback) &#123; const xhr = new XMLHttpRequest(); xhr.open(\"GET\", url, true); xhr.onreadystatechange = () =&gt; &#123; if (xhr.readyState &gt;= 3 &amp;&amp; xhr.status === 200) &#123; callback(xhr.responseText); &#125; &#125;; xhr.send(); return xhr;&#125;watchResource(\"/streaming.php\", function (res) &#123; console.log(res);&#125;); 在这种情况下，每次后端有新的数据推送过来时，都会触发 xhr.onreadystatechange 事件，进而进入回调函数。 关于 xhr.onreadystatechange 的 readState 状态值含义如下[1]： 123450 The request is not initialized.1 The request has been set up.2 The request has been sent.3 The request is in process.4 The request is completed. 应用场景HTTP Streaming VS WebSocket两者的模式和使用场景不同，最明显的区别 HTTP Streaming 是 Server Push，数据流向是单向的，由服务器推送给客户端。 WebSocket 是双向通信，客户端可以和服务端进行交互通信。 以容器云为例的应用场景以容器云平台为例，我们需要在平台上对容器进行简单的管理，其管理包括： 场景1：持续获取容器的运行日志，即容器终端持续输出的日志(view container logs) 场景2：远程登录至容器终端(exec container terminal) 场景1情况下，我们需要持续获取终端的日志输出，并且数据的流向是单向的：即服务端有新的日志输出就推送至客户端在这种情况下，我们可以采用 HTTP Streaming 的方式来完成需求，其前端的代码简化如下 12345678910111213141516171819// 监听 url 的输出，每次触发后进入 callback 回调function watchResource(url, callback) &#123; const xhr = new XMLHttpRequest() xhr.open('GET', url, true) xhr.onreadystatechange = () =&gt; &#123; if (xhr.readyState &gt;= 3 &amp;&amp; xhr.status === 200) &#123; callback(xhr.responseText) &#125; &#125; xhr.send() return xhr&#125;// 持续获取日志用于显示this.logText = ''watchResource('/logs', res =&gt; &#123; this.logText += res&#125;) 场景2情况下，数据是双向交互的，我们选择使用 Websocket此场景下，用户输入 command 后，服务端响应后返回至前端，是典型的双向通信场景，使用 websocket 来完成需求。 注意点在实际操作过程中，还是有些注意点需要提及。 服务端的数据如果经过 Nginx 转发，需要注意 proxy_buffer 配置。不然会出现服务端服务有持续输出，经过 Nginx 后不一定有输出的情况。 客户端在处理完流数据后，记得在合适的析构时期断开连接。如在 unmount 组件时进行 xhr.abort() 参考资料 [1] XMLHttpRequest WIKI https://www.wikiwand.com/en/XMLHttpRequest [2] What is HTTP Streaming? https://www.pubnub.com/learn/glossary/what-is-http-streaming/ [3] proxy_buffer_size http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_buffer_size","categories":[],"tags":[]},{"title":"使用 github action 自动发布 hexo blog","slug":"hexo-github-action","date":"2021-03-20T06:16:03.000Z","updated":"2021-03-20T14:48:45.268Z","comments":true,"path":"2021/03/20/hexo-github-action/","link":"","permalink":"https://rovast.github.io/2021/03/20/hexo-github-action/","excerpt":"","text":"背景用 Hexo 来生成 Github Pages 有一段时间了，之前一直是在本地写完 Blog 然后执行下述指令来发博客script12rm -rf publicnpx hexo deploy 今天想想，不是有 github acion 嘛，能不能使用自动化 CI 流程来发布，当我的 Hexo Repo 发布时，自动进行 deply 动作，进而部署到 rovast.github.io。当然是可以的！本文就其中的步骤进行记录，也算是 github action 的初体验了。 步骤首先我们要确认一个前提，就是 github pages 和 hexo 源码是两个东西，那我的来说，我有两个仓 仓库1，hexo source 仓库，存放 hexo 博客源码。https://github.com/rovast/hexo-config 仓库2，和自己用户名同样的仓库，你只要放了静态文件 index.html，github 自动帮你生成 github pages。https://github.com/rovast/rovast.github.io 整体的步骤如下 正确配置 hexo-config 的配置文件 _config.yaml 正确 https://github.com/rovast/hexo-config 仓库配置，尤其是 git 的 ssh 私钥和 github action 正确配置 https://github.com/rovast/rovast.github.io 的 deploy key 接下来依次配置 1、配置 hexo-config 项目的 _config.yaml1234deploy: type: git repo: git@github.com:rovast/rovast.github.io.git branch: master 注意其中的 repo 一定要是用 ssh 的协议，一因为后面我们要借助 ssh-key。 2、配置 https://github.com/rovast/hexo-config 的 github 配置1. 配置 github action 的 yaml 参考的 https://github.com/sma11black/hexo-action，我们新建文件 .github/workflows/deploy.yaml 1234567891011121314151617181920212223242526272829303132333435363738name: Deployon: [push]jobs: build: runs-on: ubuntu-latest name: A job to deploy blog. steps: - name: Checkout uses: actions/checkout@v1 with: submodules: true # Checkout private submodules(themes or something else). # Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.) - name: Cache node modules uses: actions/cache@v1 id: cache with: path: node_modules key: $&#123;&#123; runner.os &#125;&#125;-node-$&#123;&#123; hashFiles('**/package-lock.json') &#125;&#125; restore-keys: | $&#123;&#123; runner.os &#125;&#125;-node- - name: Install Dependencies if: steps.cache.outputs.cache-hit != 'true' run: npm ci # Deploy hexo blog website. - name: Deploy id: deploy uses: sma11black/hexo-action@v1.0.3 with: deploy_key: $&#123;&#123; secrets.DEPLOY_KEY &#125;&#125; commit_msg: $&#123;&#123; github.event.head_commit.message &#125;&#125; # (or delete this input setting to use hexo default settings) # Use the output from the `deploy` step(use for test action) - name: Get the output run: | echo \"$&#123;&#123; steps.deploy.outputs.notify &#125;&#125;\" 2. 配置 secrect.DEPLOY_KEY 我们看到 github action 里读取了 $，这个需要在 github 里正确配置。 注意这里应该填写的是私钥(cat ~/.ssh/id_rsa)，而不是 pub 公钥 3、在 https://github.com/rovast/rovast.github.io 配置 deploy keycat ~/.ssh/id_rsa.pub，配置到仓库的 deploy key 里面 4、结束正常保存 https://github.com/rovast/hexo-config 仓库，push 后自动触发 github action 进行发布。 使用感受有以下几点在使用过程中不得不提 丰富的 github action 模板，你甚至可以在编写的工程中在线搜索他的 Market Place！对新手而言可以快速入门，对于老手而言可以快速找到适合你的速成方案。 自定义的 secrect.VAR，并且这个 secrect 编写后，居然是不可以查看的，只能更改，简直太赞！对于一些敏感内容而言，简直完美！ 执行 action 过程中的 UI 提示，很丝滑，执行到哪步，就显示哪个步骤。 另外，通过查看 https://github.com/sma11black/hexo-action 源码，我们知道，是可以对 Dockerfile 进行操作的，这个想象的空间就无限大了。 让你感觉这个流程本该如此的操作，一定是好操作！ 参考文章 《GitHub Actions 入门教程》http://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html https://github.com/sma11black/hexo-action","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[]},{"title":"【转】npx 使用教程","slug":"use-npx","date":"2021-03-17T18:32:46.000Z","updated":"2021-03-18T02:38:17.617Z","comments":true,"path":"2021/03/17/use-npx/","link":"","permalink":"https://rovast.github.io/2021/03/17/use-npx/","excerpt":"","text":"原文 https://www.ruanyifeng.com/blog/2019/02/npx.html npm 从5.2版开始，增加了 npx 命令。它有很多用处，本文介绍该命令的主要使用场景。 Node 自带 npm 模块，所以可以直接使用 npx 命令。万一不能用，就要手动安装一下。 1$ npm install -g npx 调用项目安装的模块npx 想要解决的主要问题，就是调用项目内部安装的模块。比如，项目内部安装了测试工具 Mocha。 1$ npm install -D mocha 一般来说，调用 Mocha ，只能在项目脚本和 package.json 的scripts字段里面， 如果想在命令行下调用，必须像下面这样。 12# 项目的根目录下执行$ node-modules/.bin/mocha --version npx 就是想解决这个问题，让项目内部安装的模块用起来更方便，只要像下面这样调用就行了。 1$ npx mocha --version npx 的原理很简单，就是运行的时候，会到node_modules/.bin路径和环境变量$PATH里面，检查命令是否存在。 由于 npx 会检查环境变量$PATH，所以系统命令也可以调用。 12# 等同于 ls$ npx ls 注意，Bash 内置的命令不在$PATH里面，所以不能用。比如，cd是 Bash 命令，因此就不能用npx cd。 避免全局安装模块除了调用项目内部模块，npx 还能避免全局安装的模块。比如，create-react-app这个模块是全局安装，npx 可以运行它，而且不进行全局安装。 1$ npx create-react-app my-react-app 上面代码运行时，npx 将create-react-app下载到一个临时目录，使用以后再删除。所以，以后再次执行上面的命令，会重新下载create-react-app。 下载全局模块时，npx 允许指定版本。 1$ npx uglify-js@3.1.0 main.js -o ./dist/main.js 上面代码指定使用 3.1.0 版本的uglify-js压缩脚本。 注意，只要 npx 后面的模块无法在本地发现，就会下载同名模块。比如，本地没有安装http-server模块，下面的命令会自动下载该模块，在当前目录启动一个 Web 服务。 1$ npx http-server --no-install 参数和--ignore-existing 参数如果想让 npx 强制使用本地模块，不下载远程模块，可以使用--no-install参数。如果本地不存在该模块，就会报错。 1$ npx --no-install http-server 反过来，如果忽略本地的同名模块，强制安装使用远程模块，可以使用--ignore-existing参数。比如，本地已经全局安装了create-react-app，但还是想使用远程模块，就用这个参数。 1$ npx --ignore-existing create-react-app my-react-app 使用不同版本的 node利用 npx 可以下载模块这个特点，可以指定某个版本的 Node 运行脚本。它的窍门就是使用 npm 的 node 模块。 12$ npx node@0.12.8 -vv0.12.8 上面命令会使用 0.12.8 版本的 Node 执行脚本。原理是从 npm 下载这个版本的 node，使用后再删掉。 某些场景下，这个方法用来切换 Node 版本，要比 nvm 那样的版本管理器方便一些。 -p 参数-p参数用于指定 npx 所要安装的模块，所以上一节的命令可以写成下面这样。 12$ npx -p node@0.12.8 node -v v0.12.8 上面命令先指定安装`node@0.12.8，然后再执行node -v`命令。 -p参数对于需要安装多个模块的场景很有用。 1$ npx -p lolcatjs -p cowsay [command] -c 参数如果 npx 安装多个模块，默认情况下，所执行的命令之中，只有第一个可执行项会使用 npx 安装的模块，后面的可执行项还是会交给 Shell 解释。 12$ npx -p lolcatjs -p cowsay 'cowsay hello | lolcatjs'# 报错 上面代码中，cowsay hello | lolcatjs执行时会报错，原因是第一项cowsay由 npx 解释，而第二项命令localcatjs由 Shell 解释，但是lolcatjs并没有全局安装，所以报错。 -c参数可以将所有命令都用 npx 解释。有了它，下面代码就可以正常执行了。 1$ npx -p lolcatjs -p cowsay -c 'cowsay hello | lolcatjs' -c参数的另一个作用，是将环境变量带入所要执行的命令。举例来说，npm 提供当前项目的一些环境变量，可以用下面的命令查看。 1$ npm run env | grep npm_ -c参数可以把这些 npm 的环境变量带入 npx 命令。 1$ npx -c 'echo \"$npm_package_name\"' 上面代码会输出当前项目的项目名。 执行 GitHub 源码npx 还可以执行 GitHub 上面的模块源码。 12345# 执行 Gist 代码$ npx https://gist.github.com/zkat/4bc19503fe9e9309e2bfaa2c58074d32# 执行仓库代码$ npx github:piuccio/cowsay hello 注意，远程代码必须是一个模块，即必须包含package.json和入口脚本。 参考链接 npx Speed Up Your npm Workflow With npx Introducing npx: an npm package runner （完）","categories":[],"tags":[]},{"title":"Linux客户端设置 socks5+kcptun","slug":"server-set-proxy-use-socks5","date":"2021-03-13T07:08:40.000Z","updated":"2021-03-13T15:22:19.881Z","comments":true,"path":"2021/03/13/server-set-proxy-use-socks5/","link":"","permalink":"https://rovast.github.io/2021/03/13/server-set-proxy-use-socks5/","excerpt":"","text":"之前更多使用 Linux 服务器作为服务器来提供代理服务，这里使用 Linux 机器作为客户端，链接远端代理服务器，使用纯终端来设置代理，加速访问。 同时，参考 《pm2 简明使用教程》来配合进行守护进程使用 安软件12345678# shadowsockspip3 install shadowsocks# kcptunwget https://github.com/xtaci/kcptun/releases/download/v20210103/kcptun-linux-amd64-20210103.tar.gz# cow，用于转换 socks5 协议至 http 和 httpswget https://github.com/cyfdecyf/cow/releases/download/0.9.8/cow-linux64-0.9.8.gz 配置文件 kcptun.json 1234567891011121314151617181920212223&#123; \"localaddr\": \":1080\", \"remoteaddr\": \"REMOTE_SERVER:29900\", \"key\": \"111111\", \"crypt\": \"aes\", \"mode\": \"fast\", \"conn\": 1, \"autoexpire\": 60, \"mtu\": 1350, \"sndwnd\": 512, \"rcvwnd\": 512, \"datashard\": 70, \"parityshard\": 3, \"dscp\": 46, \"nocomp\": false, \"acknodelay\": false, \"nodelay\": 0, \"interval\": 40, \"resend\": 0, \"nc\": 0, \"sockbuf\": 4194304, \"keepalive\": 10&#125; ss.json 123456789&#123; \"server\":\"127.0.0.1\", \"server_port\":1080, \"local_address\": \"127.0.0.1\", \"local_port\":1087, \"password\":\"9SehN7C3GQ9h9Cyt\", \"timeout\":300, \"method\":\"chacha20\"&#125; ~/.cow/rc 12listen = http://127.0.0.1:4411proxy = socks5://127.0.0.1:1087 启动12345678# socks5 协议转为 http 和 https/home/rovast/applications/cow-linux64-0.9.8# 开启 kcptun/home/rovast/applications/kcptun/client_linux_amd64 -c /home/rovast/applications/kcptun/kcptun.json# 开启 ss/usr/bin/ss-local -c /home/rovast/applications/shadowsocks/ss.json 附录 https://github.com/xtaci/kcptun","categories":[],"tags":[]},{"title":"pm2 简明使用教程","slug":"pm2-usage","date":"2021-03-13T07:04:30.000Z","updated":"2021-03-20T07:20:13.845Z","comments":true,"path":"2021/03/13/pm2-usage/","link":"","permalink":"https://rovast.github.io/2021/03/13/pm2-usage/","excerpt":"","text":"安装npm install pm2@latest -g 书写配置文件使用配置文件来启动，便于统一管理 ~/.config/pm2/ecosystem.config.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142apps: - script : /home/luohao/applications/code-server-3.9.1-linux-amd64/bin/code-server interpreter: none max_memory_restart: 500M name : 'code-server' instances : 1 exec_mode : fork env: http_proxy : http://127.0.0.1:4411 https_proxy: http://127.0.0.1:4411 - script : /home/luohao/applications/cow-linux64-0.9.8 interpreter: none name : 'cow' instances : 1 exec_mode : fork env: version: 0.9.8 - script : /home/luohao/applications/kcptun/client_linux_amd64 -c /home/luohao/applications/kcptun/kcptun.json interpreter: none name : 'kcptun-client' instances : 1 exec_mode : fork - script : /usr/bin/ss-local -c /home/luohao/applications/shadowsocks/ss.json interpreter: none name : 'shadowsocks-client' instances : 1 exec_mode : fork - script : /home/luohao/.local/bin/projector run Goland interpreter: none name : 'Goland-server' instances : 1 exec_mode : fork - script : /home/luohao/.local/bin/projector run Webstorm interpreter: none name : 'Webstorm-server' instances : 1 exec_mode : fork - script : /home/luohao/.local/bin/projector run Clion interpreter: none name : 'Clion-server' instances : 1 exec_mode : fork interpreter 设置为 none，用默认行为启动二进制文件。以上是服务器设置客户端代理的脚本，供参考 启动1pm2 start ~/.config/pm2/ecosystem.config.yaml 常用的操作还有下面的系列操作，可以在后面加上 jobId(通过 pm2 list查看)，或者加上 echosystem 文件script123456789pm2 delete JOBID_OR_FILEpm2 stop JOBID_OR_FILEpm2 reload JOBID_OR_FILEpm2 restart JOBID_OR_FILEpm2 descibe JOBID_OR_FILE# 监控类pm2 monitpm2 list 监控https://app.pm2.io/ 设置为开机自启动1234567pm2 startup# 输入完 之后有如下提示# sudo env PATH=$PATH:/home/luohao/.nvm/versions/node/v15.11.0/bin /home/luohao/.nvm/versions/node/v15.11.0/lib/node_modules/pm2/bin/pm2 startup systemd -u luohao --hp /home/luohao# 更改完配置后更新最新配置pm2 save","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[]},{"title":"【转】人人都有认知障","slug":"renrendouyourenzhizhangai","date":"2021-02-19T21:16:50.000Z","updated":"2021-02-20T05:21:49.235Z","comments":true,"path":"2021/02/19/renrendouyourenzhizhangai/","link":"","permalink":"https://rovast.github.io/2021/02/19/renrendouyourenzhizhangai/","excerpt":"","text":"原文链接：https://mp.weixin.qq.com/s/eO7mVliAl8CwYnGV1FwtJg 原文标题：《人人都有认知障》 原文公众号：caoz的梦呓 以前记得看过这么一个段子，当然我是没办法求证真伪的，说大清后期有个皇上，有一天跟大臣聊天，问大臣，你早上上朝之前吃的什么啊，大臣如实回复，早上吃了俩鸡子（也就是鸡蛋），皇上就很惊讶，这么奢侈啊，你的俸禄够花么，为什么皇上很惊讶呢，因为内务府的太监跟皇上报账一个鸡蛋要好几两银子，而实际上一个鸡蛋也就几文钱。大臣心知肚明但也不便点破，就说我们吃的是寻常鸡蛋，比不上皇家特供的高级，所以没那么贵。 故事真假不知，但我觉得这比各种清宫戏反而真实一些，其实这种情况并不罕见，正如晋惠帝那句流传千古的话，何不食肉糜。生在深宫大院，帝王人家，不知柴米油盐，是很寻常的，一个太监就能蒙蔽圣听。其实当今社会，对于富裕的年轻一代或者富裕国家的国民，去理解挣扎在温饱线的时代或者贫困国家的人民生活，何不食肉糜这种认知还真不是段子，一直一直一直都有，只是换个说法而已。包括现在很多年轻人开始怀念几十年前所谓没有内卷的年代，真是都没挨饿过。 类似的故事还有，说辛亥革命后，旗人贵族没落了，需要出来自己讨生计，有个贵族遗少也出来自己想办法赚钱养活自己，走在街上饿了，花几个钱买了街边现烤的烧饼，一吃之下大惊，原来新出炉的烧饼这么脆这么好吃，以前都是让仆人出去买，每次吃到的都是冷冰冰硬梆梆的。深宫大院说起来要啥有啥，吃穿不愁，但恰恰远离了烟火气。一些寻常百姓唾手可得的东西，他们反而是难以理解。 贵族不懂百姓，当然百姓也不懂贵族，这才有相声里提到的吕剧唱词，”东宫的娘娘烙大饼，西宫的娘娘卷大葱。” 旧社会普通百姓对富贵人家的想象，也就局限于此了。 说的这些，其实不同阶层，不同社会地位，不同地域，乃至不同行业的人，对彼此的认知都会有很大的误区，不同地域也是，一个地区约定俗成的东西，在另一个地区可能就是闻所未闻。 经常有一种观点，认为高认知碾压低认知，说你如果达到某个阶层，掌握某个认知，就可以碾压那些阶层之下的人，可以任意收割或者利用他们。 但我发现，其实并不是，高学历，高智商人群被低学历，低背景人群诈骗收割的案例也很多。最近爆出来的阿里女员工被诈骗的新闻，其实真的不是孤例。很多人认为这些人认知不够，但扪心自问，我们自己又高明到哪里去，在投资领域我犯过的错误也数不胜数，认知不足交过的学费算下来也是挺大的数字了。 现在业内都知道，所谓下沉市场价值巨大，我在星球里说过，对如何挖掘下沉市场，我是没任何感知的。因为我从小就没在农村住过一天，虽然小时候家里也很穷，但属于城市平民，所以对所谓乡村生活，乡村人际，乡村的过年气氛，就完全无感，我看到有读者说，现在年味越来越淡，只有小时候乡下过年那才叫过年，这话我就不爱听，我城里长大的就不配过年是怎么的。 另外，我还说过一点，我没有故乡的概念，我虽然是天津出生的，但是随着父亲工作单位调动，6岁之前在山东德州，是出扒鸡的德州，不是出牛仔的德州。那么6岁之前是没任何印象的，6岁后父母迁回天津，事业单位，属于水利部下的勘测设计院，当时还叫水电部，那么住的小区是单位家属区，整个设计院的人分别来自山东德州和河南三门峡，换句话说，家属院里就没有本土的天津人。当然，我们家祖籍也不是天津，是河北，解放前我爷爷迁居到天津的，可是河北老家我也一次都没去过。所以不好意思，我小时候在天津的时候，就没觉得自己是天津人，天津人也没拿我当本地人，但我也没觉得自己是河北人，是山东人。所以所谓叶落归根，荣归故里，很惭愧，我也是完全没感觉的。 没有故土概念，也没有乡村生活经历，城里亲戚关系也没那么深厚，对很多这方面的感知基本没有，所以我知道很多人会用这样的认知感来做营销，做市场运营，做低成本获客，但这种我就不会碰，因为我的认知跟不上。 以前草根创业者，很多是本色的认知感，比如李兴平，做的非常成功；后来精英们做下沉，靠数据反馈迭代，我是很佩服张一鸣和黄峥这种，我是做不来。但确实，跨越阶层，跨越群体的认知，是产生很多商业机会，以及个人价值增长的所在。 这句话我加粗一下，希望读者仔细想想。 比如说，为什么我常说，技术人员懂一点商业，会非常有价值，看看中国和美国的福布斯榜单，多少大佬是程序员出身。懂草根的精英，和懂精英的草根，也都是非常容易创建商业奇迹的人。 比如说，出海企业，能够理解海外市场，并掌握中国研发资源的人，就会非常有优势。 跨越不同族群，不同阶层的时候，你会发现，A群体中非常渴望的诉求，认为非常难以实现的事情，在B群体里其实是非常简单，容易获取的资源，但B群体并不知道A群体存在这样的诉求，如果有一个人，比如他是A群体的人，突然有机会接触了B群体，掌握了B群体的认知，发现存在非常简单，容易获取这样的资源，他拿到资源转过头来，回到A群体贩售，这就是很多商业成功案例的本质逻辑。 我看到包括生财有术，包括我自己星球里很多读者分享的赚钱案例，相当高的比例都可以用这个逻辑来套用，几乎都能符合。 很多草根创业者小有成就后，都愿意花钱读个emba，试图让自己融入另一个阶层，也是存在这样的一种理念。 但这里存在一个问题，最近我发现很多创业者，或者一些还不错的草根创业者，存在这样一个问题，他们脱胎于A群体，开始接触B群体，靠B群体的认知，转过头来，在A群体解决了一些关键诉求，实现了很好的商业转化，这不挺成功的么，然后他们就开始觉得，A群体太low了，什么都不懂，自己要怎样，脱胎换骨，成为B群体中的一员，但是这里问题来了，彻底脱离了A群体后，他们其实就失去了自己的价值了。 这就是今天要说的主题，能够纵横跨越阶层，跨越族群的认知，充分利用起来，可以具有极大的商业价值，但如果你彻底放弃了某个群体和阶层的认知，你以为你脱胎换骨，其实你是自废武功。你说增进认知，学习更多难道有错么？当然没错。但究竟什么才是你的价值，既懂A，又懂B才是你的价值。放弃A，追求B，你什么都不是。 底层逆袭的人，往往会忽视底层认知的价值，当你脱离了所谓低级趣味的时候，你可能已经失去了很重要的价值资源。而这样的人，还真挺多的。 类似的案例还有很多，中国改革开放，第一批睁眼看世界的人，既懂中国，又懂西方，就很容易抓住时代的机遇，抓住很多稀缺的机会，成就一番事业，这些人慢慢成为中年人，觉得自己孩子早点接受西方教育，不是比自己更有优势么？结果问题来了，下一代人确实很懂西方，但不懂中国，反而失去了独特的价值。 认知障无处不在，所谓高阶人士，其实也存在很多认知障，就好比说，一路开挂的学霸是教不了学渣的，因为他们无法理解学渣的困境和苦恼，反而是从学渣逆袭诚学霸的，拥有跨越阶层的思维，才能更有针对性的辅导学渣。就好比说，纯粹大公司成长起来的技术高手很难去早期创业公司带团队，因为他们很难理解资源极为苛刻，人力极为平庸的情况下，如何做好产品，但反而是那些从巨头草创早期就加入，一路成长的高手，更能理解从创业到成长为巨头的挑战，这些都可以认为是跨越阶层的认知，具有独特的价值。 但切记，同时拥有多个阶层的认知才是你的价值所在，不要顾此失彼，为了追求所谓阶层上升，阶层融入，轻易放弃曾经的认知能力。最近发现有不少创业者，在做这样自废武功的事情，遂有感慨成此文。 一定要找到自己的独特价值，无论面对什么阶层，什么样的人，你总会在某个细分领域的认知具有优势，你找到这个点，然后再通过学习和领悟对方阶层的认知，从中挖掘匹配的需求点，就是你的独特价值。 我的知识星球，年终免费福利课，复盘人生关键决策，有效期只剩不到10天，最后提醒，3月1日凌晨准时下架。 懒得发链接了，星球用户去看置顶帖，其他读者忽略即可。","categories":[{"name":"随想","slug":"随想","permalink":"https://rovast.github.io/categories/随想/"}],"tags":[]},{"title":"理解 shell 脚本中的常见用法2>&1","slug":"understanding-shell-script-idiom-redirect","date":"2021-02-08T01:39:02.000Z","updated":"2021-02-08T09:50:07.143Z","comments":true,"path":"2021/02/08/understanding-shell-script-idiom-redirect/","link":"","permalink":"https://rovast.github.io/2021/02/08/understanding-shell-script-idiom-redirect/","excerpt":"","text":"原文：https://www.brianstorti.com/understanding-shell-script-idiom-redirect/ 在我们接触的 shell 脚本中，对 2&gt;&amp;1 一定不陌生，比如 ls foo &gt; /dev/null 2&gt;&amp;1。 本文就来解释下 2&gt;&amp;1 究竟做了什么，并且是如何起作用的。 一、I/O 重定向简介「重定向」是计算机用来把命令的输出从一个地方，输出到另一个地方。举个例子，默认情况下，我们使用 cat 指令可以把一个文件的内容打印到终端： 1234$ cat foo.txtfoobarbaz 但是，我们可以把输出重定向到另外地方。此例中，我们可以把输出重定向到 output.txt 中： 123456$ cat foo.txt &gt; output.txt$ cat output.txtfoobarbaz 注意，在执行第一行命令 cat foo.txt &gt; output.txt 时，我们在屏幕上看不到任何输出。我们把原来应该打印到屏幕的内容，重定向到 output.txt 了，所以屏幕上不会有任何输出了。 这里，「本来应该打印到屏幕的内容」，就是标准输出，即 stdout(standard output)。 除了标准输出可以接收程序的输出之外，还有一个地方可以，叫 标准错误输出，即 stderr(standard error)。stderr 用来接收程序的错误消息。例如，我们 cat 了一个不存在的文件： 12$ cat nop.txt &gt; output.txtcat: nop.txt: No such file or directory 我们看到，虽然我们要求程序把输出重定向到 output.txt，但是我们还是在屏幕上看到了错误消息输出。这是因为我们只是重定向了 standard output，而不是 standard error。 二、文件描述符(fd)简介文件描述符（file descriptor）简单来说，就是一个正整数，用来代表一个打开的文件。比如当前我们有 100 各打开的文件，那么就有 100 个文件描述符。 唯一需要补充的是，在 Unix 系统中，「一切皆文件」。 同时我们还应该知道，对于标准输出(stdout)和标准错误输出(stderr)，也有对应的文件描述符。我们使用 1 和 2 来分别表示 stdout 和 stderr 所在的位置。 三、融合上述知识回到我们的第一个示例，我们还可以有另外一种写法 12345# 写法一$ cat foo.txt &gt; output.txt# 等价写法二$ cat foo.txt 1&gt; output.txt 这里的 1 就是用来代表 stdout 的文件描述符。语法是 [FILE_DESCRIPTOR]&gt;。我们看到把 1 省略的写法 &gt;只是 1&gt; 的快捷写法而已。 对于重定向到 stderr 的场景，我们只需要在右边的文件前面加上文件描述符即可 1234$ cat nop.txt 2&gt; error.txt$ cat error.txtcat: nop.txt: No such file or directory 你看，这样就生效了。这会儿，你大概知道 2&gt;&amp;1 是怎样工作的，让我们来总结总结。 我们使用 &amp;1 来表示文件描述符1(stdout)的地址。当你使用 2&gt;&amp;1 时，其实就是在说：把 stderr 的输出重定向到 stdout 的地方。这样，我们就可以把程序的标准输出和错误输出都输出到同一个地方了。 1234567891011$ cat foo.txt &gt; output.txt 2&gt;&amp;1$ cat output.txtfoobarbaz$ cat nop.txt &gt; output.txt 2&gt;&amp;1$ cat output.txtcat: nop.txt: No such file or directory 四、总结 程序可以把输出发送到两个地方：标准输出(stdout，standard output)和标准错误输出(stderr，standard error)。 你可以把输出重定向到另一个地方（比如文件） 文件描述符1和2 可以分别用来表示 stdout 和 stderr command &gt; output 是 command 1&gt; output 的缩写 可以使用 &amp;[FILE_DESCRIPTOR] 来引用文件描述符的值（或者叫指向文件描述符的地址） 使用 2&gt;&amp;1 来重定向 stderr 的输出至 stdout 的地方（你可以用 1&gt;&amp;2 来进行反向操作） 另，在 Linux 系统中 0、1、2 分别表示不同的设备类型，其中 0 标准输入设备，指键盘1 标准正确输出设备2 标准错误输出设备","categories":[],"tags":[]},{"title":"MacOS非安全模式打开Chrome","slug":"cors-on-mac","date":"2021-02-01T00:02:18.000Z","updated":"2021-02-01T08:04:07.298Z","comments":true,"path":"2021/02/01/cors-on-mac/","link":"","permalink":"https://rovast.github.io/2021/02/01/cors-on-mac/","excerpt":"","text":"使用允许跨域（不安全）模式打开，便于调试，设定一个 Alias 即可 1alias openChromeNoCORS=\"open -na Google\\ Chrome --args --user-data-dir=/tmp/temporary-chrome-profile-dir --disable-web-security --disable-site-isolation-trials\"","categories":[],"tags":[]},{"title":"Antv G2 修改 Brush 默认行为为返回时间戳范围","slug":"ant-g2-brush-timerange","date":"2021-01-29T01:12:46.000Z","updated":"2021-01-29T09:20:39.962Z","comments":true,"path":"2021/01/29/ant-g2-brush-timerange/","link":"","permalink":"https://rovast.github.io/2021/01/29/ant-g2-brush-timerange/","excerpt":"","text":"G2 brush 时间轴，而不是筛选数据点一、背景目前 G2 使用 brush-x 筛选后的是对应的点，而不是 X 轴的时间范围。在实际使用过程中，我们需要场景如下 鼠标筛选一个区域 获取这个区域的开始时间和结束时间 以第2步获取到的时间范围作为结果来重新获取数据 二、核心代码一览2.1 注册 Action src/index.ts，中枚举出了可以使用的 Action 123registerAction('brush', DataRangeFilter);registerAction('brush-x', DataRangeFilter, &#123; dims: ['x'] &#125;);registerAction('brush-y', DataRangeFilter, &#123; dims: ['y'] &#125;); 2.2 filter 处理逻辑 看下 filter 流程src/interaction/action/data/range-filter.ts 获取到用户当前选择的视觉点 转换视觉点，获取到实际选择的 min value 和 max value，并且生成 filter 根据 filter 进行数据筛选 123456789101112131415161718192021222324252627public filter() &#123; let startPoint; let currentPoint; // ... codes // 进行一些列处理，得到 startPoint 和 currentPoint 的值 const view = this.context.view; // 获取到归一化坐标 const coord = view.getCoordinate(); const normalCurrent = coord.invert(currentPoint); const normalStart = coord.invert(startPoint); // 设置 x 方向的 filter if (this.hasDim('x')) &#123; const xScale = view.getXScale(); // filter 其实就是一个函数 (value: any, datum: Datum, idx?: number) =&gt; boolean; const filter = getFilter(xScale, 'x', normalCurrent, normalStart); // 核心！根据 filter 进行筛选 this.filterView(view, xScale.field, filter); &#125; // 设置 y 方向的 filter // ... codes this.reRender(view);&#125; 看下如何获取到 min value 和 max value src/interaction/action/data/range-filter.ts 获取到的 minValue 和 maxValue 取整后就是时间戳了 123456789101112131415161718192021222324252627282930313233343536function getFilter(scale: Scale, dim: string, point1: Point, point2: Point): FilterCondition &#123; let min = Math.min(point1[dim], point2[dim]); let max = Math.max(point1[dim], point2[dim]); const [rangeMin, rangeMax] = scale.range; // 约束值在 scale 的 range 之间 if (min &lt; rangeMin) &#123; min = rangeMin; &#125; if (max &gt; rangeMax) &#123; max = rangeMax; &#125; // 范围大于整个 view 的范围，则返回 null if (min === rangeMax &amp;&amp; max === rangeMax) &#123; return null; &#125; const minValue = scale.invert(min); const maxValue = scale.invert(max); /** * 这里获取到的 minValue 和 maxValue，就是对应的 x 轴选择的时间范围 * 类似 minValue 1611724258188.5186 Wed Jan 27 2021 13:10:58 GMT+0800 * maxValue 1611724586405.7407 Wed Jan 27 2021 13:16:26 GMT+0800 */ if (scale.isCategory) &#123; const minIndex = scale.values.indexOf(minValue); const maxIndex = scale.values.indexOf(maxValue); const arr = scale.values.slice(minIndex, maxIndex + 1); return (value) =&gt; &#123; return arr.includes(value); &#125;; &#125; else &#123; return (value) =&gt; &#123; return value &gt;= minValue &amp;&amp; value &lt;= maxValue; &#125;; &#125;&#125; 我们可以在用户定义的 action 上下文里拿到对应的 rangefilter 实例 1ctx.actions.find(v =&gt; v.name === 'brush-x') 但同时我们也看到，我们需要的 minValue 和 maxValue 都是作为临时计算的产物，并没有挂在对象实例上，所以我们有以下三条路 获取到 ctx 后，自己重新计算 修改源码，把这个临时状态挂在对象上。不过需要重新发包，或者把代码纳入版本库？侵入性强，不便于后期升级，还是算了吧 再去看看其他方案吧 不需要在选择上浪费太多时间，干就完了。我们先选择方案一，要是后面有更好的，再更换嘛。 2.3 根据获取到的 ctx 来计算 Min 和 Max 123456789101112131415161718192021222324252627282930313233343536/** * 1、获取到可视区域 view 的宽度 * 2、获取到可视区域的时间戳分布 * 3、算出 brush 的起始点 * * @param ctx */export function getBrushedTimeRange(ctx) &#123; // action 本身实例 const self = ctx.actions.find(v =&gt; v.name === 'brush-x') const view = self.context.view // 获取到两个选择的点 const startPoint = self.startPoint const currentPoint = ctx.getCurrentPoint() // 画布两侧的 padding const paddingLeft = view.padding[3] // 获取主体的实际宽度 const totalWith = view.width - view.padding[1] - view.padding[3] // 获取选择点的开始结束坐标 const startX = startPoint.x - paddingLeft const endX = currentPoint.x - paddingLeft // range 范围的才会落点 const timestampsCount = (view.getXScale().max - view.getXScale().min) / (view.getXScale().range[1] - view.getXScale().range[0]) // 获取到每一个时间占用的宽度 const perTimestampWidth = timestampsCount / totalWith // 开始需要补偿的时间范围 const startXTimestamp = view.getXScale().min - view.getXScale().range[0] * totalWith * perTimestampWidth const startTime = startXTimestamp + startX * perTimestampWidth const endTime = startXTimestamp + endX * perTimestampWidth return startTime &lt; endTime ? [startTime, endTime] : [endTime, startTime]&#125; 在brush回调的地方，执行下面的动作即可，着重关注 callback 地方 1234567891011121314151617181920212223242526272829303132333435registerInteraction('brushX', &#123; showEnable: [ &#123; trigger: 'plot:mouseenter', action: 'cursor:crosshair' &#125;, &#123; trigger: 'plot:mouseleave', action: 'cursor:default' &#125; ], start: [ &#123; trigger: 'mousedown', action: ['brush-x:start', 'x-rect-mask:start', 'x-rect-mask:show'] &#125; ], processing: [ &#123; trigger: 'mousemove', action: ['x-rect-mask:resize'] &#125; ], end: [ &#123; trigger: 'mouseup', action: ['brush-x:end', 'x-rect-mask:end', 'x-rect-mask:hide'], callback: ctx =&gt; &#123; // 重点再这里 const [startTime, endTime] = getBrushedTimeRange(ctx) this.$emit('on-brushed', [startTime, endTime]) this.resetBrushAction = ctx.actions.find(v =&gt; v.name === 'brush-x') &#125; &#125; ], rollback: [ &#123; trigger: 'dblclick', action: ['brush-x:reset', 'reset-button:hide'] &#125;, &#123; trigger: 'reset-button:click', action: ['brush-x:reset', 'reset-button:hide'] &#125; ]&#125;) 三、踩坑方案3.1 直接使用 brush-filter 导致的 scalex 上下文传递不一致问题123456789101112131415161718192021222324252627282930313233/** * hack 原来的 getFilter() 方法，直接返回我们需要的数据 * * @param scale Scale * @param dim * @param point1 Point * @param point2 * @returns &#123;null|&#123;minValue, maxValue&#125;&#125; */function hackGetFilterReturnMinMax(scale, dim, point1, point2) &#123; let min = Math.min(point1[dim], point2[dim]) let max = Math.max(point1[dim], point2[dim]) const [rangeMin, rangeMax] = scale.range // 约束值在 scale 的 range 之间 if (min &lt; rangeMin) &#123; min = rangeMin &#125; if (max &gt; rangeMax) &#123; max = rangeMax &#125; // 范围大于整个 view 的范围，则返回 null if (min === rangeMax &amp;&amp; max === rangeMax) &#123; return null &#125; const minValue = scale.invert(min) const maxValue = scale.invert(max) // console.log('start', minValue, 'end', maxValue) return &#123; minValue, maxValue &#125;&#125; 3.2 区分 view 的几个视角 四、一些链接4.1 tooltip 联动https://antv-g2.gitee.io/zh/examples/interaction/others#views-tooltip","categories":[],"tags":[]},{"title":"SkyWalking PHP 内核代码剖析","slug":"skywalking-php-kernel-flow","date":"2021-01-29T01:04:15.000Z","updated":"2021-01-29T09:11:23.061Z","comments":true,"path":"2021/01/29/skywalking-php-kernel-flow/","link":"","permalink":"https://rovast.github.io/2021/01/29/skywalking-php-kernel-flow/","excerpt":"","text":"一、总体流程PHP 重要几个生命周期说明，先后顺序为 PHP_MI、PHP_RI、PHP_EXECUTE、PHP_RS、PHP_MS，每个模块的作用如下 PHP_MI，模块初始化阶段，主要进行 PHP 框架、Zend 引擎的初始化工作。重要的几个工作如下： 全局状态信息的初始化，如 SG、CG、EG等 启动 Zend 引擎，内存池启动、注册虚拟机的各项执行句柄 解析 php.ini 配置文件 注册拓展，包括静态编译拓展和动态编译拓展 回调拓展定义的 MI 函数，即 PHP_MINIT_FUNCTION PHP_RI，请求初始化阶段，CLI 模式下，该函数执行一次。如果是 php-fpm 模式下，会在 PHP_RI 和 PHP_RS 之间循环。该阶段需要关注的有如下事宜： 激活 zend 引擎，包括：重置垃圾回收器、初始化编译器、初始化执行器、初始化词法扫描器 回调各拓展定义的 RI 函数，即 PHP_RINIT_FUNCTION PHP_EXECUTE，脚本执行阶段。通过拦截 zend 引擎的 execute 函数，我们可以捕获用户执行的每一条语句，我们可以在此阶段，进行 MySQL、Redis、CURL等代码的捕获，从而生成对应的 span，进而构建 trace。 PHP_RS，请求关闭阶段。该阶段主要进行请求资源的释放动作，同时这个是 fpm 请求的最后一个阶段，我们可以在此阶段，把本次请求获取的 segment 信息上报至 sidecar PHP_MS，模块关闭阶段。各项资源的释放 SkyWalking PHP 内核的主要处理流程整理如下： 二、PHP_MI 阶段，自定义函数执行器替换Zend内核执行器 该阶段的入口函数 PHP_MINIT_FUNCTION (skywalking) 2.1 代码命名约定该阶段主要是进行 Zend 执行器的 assign 动作，变量的命名有如下规则： ori_ 打头的，是 Zend 引擎的原函数，这里做备份，便于 hack 后，恢复原来的执行 zend_ 打头的，就是 Zend 引擎的内置函数 sky_ 打头的，是我们计划在对应阶段进行的自定义动作。一般在自定义动作的最后，都会使用 ori_ 来交还函数控制权，恢复原来正常流程函数的执行动作 部分代码如下： 12345678910111213PHP_MINIT_FUNCTION (skywalking) &#123; // ..... // 用户自定义函数执行器(php脚本定义的类、函数) ori_execute_ex = zend_execute_ex; zend_execute_ex = sky_execute_ex; // 内部函数执行器(c语言定义的类、函数) ori_execute_internal = zend_execute_internal; zend_execute_internal = sky_execute_internal; // ......&#125; 2.2 拦截的函数分类和意义其拦截的函数主要分三类： zend_execute_ex，拦截用户态函数，即我们平时写的 .php 文件里面的代码。这里可以捕获到 class name 类名、function name 函数名 zend_execute_internal，拦截 PHP 内置的函数和类等，比如 PDO、mysqli 等 CURL相关的函数句柄，这样我们就可以捕获函数的上下游 http 调用信息。其拦截的函数包括：curl_exec、curl_setopt、curl_setopt_array、curl_close 三、PHP_RI 阶段，请求初始化，注册 sky-agent，构造原始 segment入口函数 PHP_RINIT_FUNCTION(skywalking) 3.1 主要流程PHP_RI 阶段在每一个 fpm 请求时都会触发一次，在此阶段，主要进行以下两件事 static int sky_register()，通过 unix sock 通信，注册 agent，同时根据返回的握手信息来确定 app、service、instance信息 static void request_init() ，构造 segement 信息，这里包含了以下重要信息 生成 traceId 根据 header 的 sw8 字段来解析上游信息，进而构造 span 信心，refs 信息 3.2 traceId 生成规则，三段格式 instance.pid.second其核心代码如下 12345678910111213static void generate_context() &#123; int sys_pid = getpid(); long second = get_second(); second = second * 10000 + sky_increment_id; //创建traceid的因子 char *makeTraceId; makeTraceId = (char *) emalloc(sizeof(char) * 180); //分配traceId所需要的内存 bzero(makeTraceId, sizeof(char) * 180); sprintf(makeTraceId, \"%d.%d.%ld\", application_instance, sys_pid, second); // .....&#125; 其中 sky_increment_id 是 0~9999。MSP 平台中显示的 TraceId 信息，类似如下： 我们来简短分析下，按点「.」分割 1。因为在 sky_register 阶段，application_instance 固定为 1 393，即 pid 16109522148050 这个就是时间戳 + sky_increment_id 构成的了 3.3 header 里的 HTTP_SW8 数据含义123456789101112131415161718192021static void generate_context() &#123; // ....... // 获取 header HTTP_SW8 信息 sw = zend_hash_str_find(Z_ARRVAL_P(carrier), \"HTTP_SW8\", sizeof(\"HTTP_SW8\") - 1); //$SERVER['HTTP_SW8']; // ....... // 按中横线（-）分割为 sw8_N 数组 php_explode(zend_string_init(ZEND_STRL(\"-\"), 0), Z_STR_P(sw), &amp;temp, 10); // ...... // 对分割后的数组，进行解码，其 index 为 1,2,4,5,6,7 zval_b64_decode(&amp;sw8_1decode, Z_STRVAL_P(sw8_1)); zval_b64_decode(&amp;sw8_2decode, Z_STRVAL_P(sw8_2)); zval_b64_decode(&amp;sw8_4decode, Z_STRVAL_P(sw8_4)); zval_b64_decode(&amp;sw8_5decode, Z_STRVAL_P(sw8_5)); zval_b64_decode(&amp;sw8_6decode, Z_STRVAL_P(sw8_6)); zval_b64_decode(&amp;sw8_7decode, Z_STRVAL_P(sw8_7)); // .......&#125; 我们去网关日志里，取一个样本分析，得到的原始 header 信息如下 11-QzBBODNDMzEtMTYxMDk1MzUyODM0MC0xMTc3OTctQS0xMjcw-QzBBODNDMzEtMTYxMDk1MzUyODM0MC0xMTc3OTctQS0xMjcw-1-xxxxxxxxxxxx-YjcyOWU0MzUtNjA5Zi00YzMwLWI4MjctNjZmMmUyYWZjNmM2-xxxxxxxxxx==-xxxxx.service 我们按中横线(-)分割，得到 123456781QzBBODNDMzEtMTYxMDk1MzUyODM0MC0xMTc3OTctQS0xMjcw // Trace Id base64QzBBODNDMzEtMTYxMDk1MzUyODM0MC0xMTc3OTctQS0xMjcw // Parent trace segment Id1 // Parent span Idxxxxxxxxxxxx // Parent serviceYjcyOWU0MzUtNjA5Zi00YzMwLWI4MjctNjZmMmUyYWZjNmM2 // Parent service instancexxxxxxxxxx== // Parent endpointxxxxx.service // Target address used at client side of this request 我们对其中 1,2,4,5,6,7 进行 base64 解码，得到 123456781C0A83C31-1610953528340-117797-A-1270 // Trace Id base64C0A83C31-1610953528340-117797-A-1270 // Parent trace segment Id1 // Parent span Idxxxxxxxxxxxxx // Parent serviceb729e435-609f-4c30-b827-66f2e2afc6c6 // Parent service instancexxxxxxxxxxxxxxxxxxxxxxxxx // Parent endpointxxxxxxxxxx.service // Target address used at client side of this request 3.4 RI 周期主要流程如下 四、PHP_EXECUTE 阶段，拦截代码执行语句，分析后恢复执行 在 MI 阶段，我们替换了 zend 引擎的函数执行指向，所以所有语句的执行会被我们接管。我们在执行完自己需要的动作后，还原原来的执行即可。 需要注意的是，我们接管的函数会被多次触发，每执行一条 opline，就会被触发一次(存疑，待指正)。 4.1 ZEND_API void sky_execute_ex(zend_execute_data *execute_data)核心的流程如下 获取当前代码执行的信息，包括：类名、函数名 对类名和函数名进行判断，看是否需要拦截。目前拦截的是 Predis SDK 如果需要拦截，根据拦截信息构造 span 把构造好的 span 插入到当前 segment 的 spans 数组里 恢复函数原来的执行，调用 ori_ 即可 4.2 ZEND_API void sky_execute_internal(zend_execute_data execute_data, zval return_value)其核心流程和上面 4.1 分析的类似，其不同就在于这里拦截的是 PHP 内置的一些类，即编译时就安装的类。流程主要包括 获取类名和函数名 根据类名判断是否需要拦截，目前需要拦截：PDO、PDOStatement、mysqli、Yar_Client、Reids、Memecached 构造 span，插入到当前 segment 的 spans 数组里 恢复函数执行 4.3 CURL HOOK这里主要是调用链的传递，如果发现有 curl 请求，则根据规则生成当前的 sw8 信息，塞到 http header 的 sw8 字段里，传递给下游。 更多的流程，以后补充。 五、PHP_RS 请求结束阶段，发送 segment 信息至 sidecarPHP_RS 阶段主要做两件事儿： 通过 unix sock 发送本请求构建的 segment 信息至 sidecar 释放当前请求里的全局状态存储。由于其他的 int、char、boolean 类型的不涉及到内存管理，所以就是四个 zval 的释放 1234567891011ZEND_BEGIN_MODULE_GLOBALS(skywalking) char *sock_path; char *app_code; //app_name eg:skywalking.app_code = MyProjectName char *app_code_env_key; //app_name 环境变量地址：环境变量-&gt;默认KEY：APM_APP_CODE zend_bool enable; zval UpstreamSegment; //全局上报数据段 zval context; zval curl_header; //curl header数据 zval curl_header_send; //记录当前R周期 是否已经send过curl_header int version;ZEND_END_MODULE_GLOBALS(skywalking) 六、PHP_MS 模块结束阶段这个阶段没啥好说的，没啥特殊操作 七、全景，整个大脑图","categories":[],"tags":[]},{"title":"在 Mac 上使用 Clion 调试 PHP 源码","slug":"debug-php-src-on-mac","date":"2020-12-26T19:39:39.000Z","updated":"2020-12-27T07:04:34.038Z","comments":true,"path":"2020/12/26/debug-php-src-on-mac/","link":"","permalink":"https://rovast.github.io/2020/12/26/debug-php-src-on-mac/","excerpt":"","text":"参考 https://www.jianshu.com/p/f6af567b25a7 一、编译安装 debug 版本的 PHP configure php 123456./configure --enable-fpm --enable-debug --with-openssl=/usr/local/Cellar/openssl@1.1/1.1.1i/ \\--enable-bcmath --with-curl --enable-exif --with-mysqli --with-pdo-mysql \\--enable-zip --with-zlib=/usr/local/Cellar/zlib/1.2.11/ --enable-intl --enable-pcntl --enable-mbstring --enable-soap \\--with-icu-dir=/usr/local/Cellar/icu4c/67.1 \\--with-iconv=/usr/local/Cellar/libiconv/1.16 \\--with-libxml-dir=/usr/local/Cellar/libxml2/2.9.10_2 修改 makefile 查找关键字 EXTRA_LIBS = 我的在 line 108，删除所有的 -liconv，末尾加上 /usr/local/opt/libiconv/lib/libiconv.dylib12345# 修改前EXTRA_LIBS = -lcrypto -lssl -lcrypto -lz -lresolv -lstdc++ -liconv -liconv -lz -lcrypto -lssl -lcrypto -lm -lxml2 -lz -liconv -lm -lcurl -lxml2 -lz -liconv -lm -licui18n -licuuc -licudata -licuio -lxml2 -lz -liconv -lm -lxml2 -lz -liconv -lm -lxml2 -lz -liconv -lm -lxml2 -lz -liconv -lm -lxml2 -lz -liconv -lm# 修改后EXTRA_LIBS = -lcrypto -lssl -lcrypto -lz -lresolv -lstdc++ -lz -lcrypto -lssl -lcrypto -lm -lxml2 -lz -lm -lcurl -lxml2 -lz -lm -licui18n -licuuc -licudata -licuio -lxml2 -lz -lm -lxml2 -lz -lm -lxml2 -lz -lm -lxml2 -lz -lm -lxml2 -lz -lm /usr/local/opt/libiconv/lib/libiconv.dylib make 1make sudo make install 1sudo make install 二、设定一些目录的权限，不然 Clion 不能正常调试1sudo chown -R rovast:wheel /usr/local/lib/php/ makefile1234567891011121314151617181920cmake_minimum_required(VERSION 3.13)project(php_7_2_27)set(CMAKE_CXX_STANDARD 14)set(PHP_SOURCE /Users/rovast/Software/tmp/php-7.2.27)include_directories($&#123;PHP_SOURCE&#125;/main)include_directories($&#123;PHP_SOURCE&#125;/Zend)include_directories($&#123;PHP_SOURCE&#125;/sapi)include_directories($&#123;PHP_SOURCE&#125;/pear)include_directories($&#123;PHP_SOURCE&#125;/TSRM)include_directories($&#123;PHP_SOURCE&#125;)add_custom_target(makefile COMMAND make &amp;&amp; make install WORKING_DIRECTORY $&#123;PROJECT_SOURCE_DIR&#125;) debug on ubuntu12sudo apt install libxml2-dev./configure --enable-debug --enable-fpm","categories":[],"tags":[]},{"title":"grafana iframe 接入备忘录","slug":"grafana-iframe","date":"2020-12-22T18:46:30.000Z","updated":"2021-06-04T03:44:37.029Z","comments":true,"path":"2020/12/22/grafana-iframe/","link":"","permalink":"https://rovast.github.io/2020/12/22/grafana-iframe/","excerpt":"","text":"iframe 引入部分配置修改后才能进行 iframe 嵌入，默认是不支持的 123allow_embedding: true # 默认是 false， 为了防止 Clickjacking，如果不设置，浏览器会拒绝显示 iframecookie_samesite: none # 如果不设置，无法使用登录功能cookie_secure: true # if you're using https and let us know how that works out. 配置说明 https://grafana.com/docs/grafana/latest/administration/configuration/ 1234567891011121314cookie_secureSet to true if you host Grafana behind HTTPS. Default is false.cookie_samesiteSets the SameSite cookie attribute and prevents the browser from sending this cookie along with cross-site requests. The main goal is to mitigate the risk of cross-origin information leakage. This setting also provides some protection against cross-site request forgery attacks (CSRF), read more about SameSite here. Valid values are lax, strict, none, and disabled. Default is lax. Using value disabled does not add any SameSite attribute to cookies.allow_embeddingWhen false, the HTTP header X-Frame-Options: deny will be set in Grafana HTTP responses which will instruct browsers to not allow rendering Grafana in a &lt;frame&gt;, &lt;iframe&gt;, &lt;embed&gt; or &lt;object&gt;. The main goal is to mitigate the risk of Clickjacking. Default is false. tips隐藏左侧菜单和增加时间范围 ?kiosk=tv 隐藏左侧的菜单 ?from=now-1h&amp;to=now 显示最近一小时的内容 免登陆访问 dashboard结论暂时不支持设定指定的 dashboard 为 public，即：免认证访问。如果开启了只读权限，则所有人皆可以访问 相关调研1、《Making selected dashboards public》 There is no way to do this and there is a big reason why.If you make one dashboard public you will have to make your data source public(ie anyone can query against it).So any possible query for that data source can be issued not just the queries used in the dashboard you made public. 根据初步的调研，得到的答复是不能指定 dashboard 开放 public 权限。同时，官方的 issue 里也有关于此问题的回复 2、《[FeatureRequest] Dashboards: Add real time share instead of snapshot》 目前依旧是处于 Open 状态。 折衷方案《How to make one live dashboard public》","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[]},{"title":"makefile 简明教程","slug":"makefile-tutorials","date":"2020-11-28T13:39:18.000Z","updated":"2020-11-28T13:41:13.439Z","comments":true,"path":"2020/11/28/makefile-tutorials/","link":"","permalink":"https://rovast.github.io/2020/11/28/makefile-tutorials/","excerpt":"","text":"Makefile 简明教程 英文原文地址：https://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/ Makefiles 是组织代码编译的一种方式。通过这篇简明教程，虽然你不能完整学会 make 指令，但是你可以使用 makefile 来组织小到中型的项目啦。 一个 简单的例子我们来从下面的三个文件开始吧：hellomake.c，hellofunc.c，hellomake.h。这是一个经典 C 语言程序，代码根据功能组织在不同的文件中。 hellomake.c 12345678#include &lt;hellomake.h&gt;int main() &#123; // 调用另一个文件里的函数 myPrintHelloMake(); return (0);&#125; hellofunc.c 12345678#include &lt;stdio.h&gt;#include &lt;hellomake.h&gt;void myPrintHelloMake() &#123; printf(\"Hello makefiles!\\n\"); return;&#125; hellomake.h 12/* example include file */void myPrintHelloMake(void); 一般情况下，我们通过下面的指令来编译代码： 1gcc -o hellomake hellomake.c hellofunc.c -I. 我们来说明下这个指令： 我们编译两个 .c 文件 命名了编译后的可执行文件为 hellomake -I. 告诉 gcc 在当前目录中寻找 hellomake.h 如果没有使用 makefile，我们在调试开发的时候，可以在终端上输入 向上方向键 来快速显示上次的指令（尤其是你有多个 .c 文件需要编译的时候）。 然而，通过上面的直接输入编译指令的方式存在两个弊端： 弊端一：不方便呀！当你换了电脑之后，你要重新再输入上面的指令。 弊端二：编译效率低下！即使你只是修改了项目中的一个 .c 文件，每次编译时，还是需要编译所有的文件，这无疑是效率低下，浪费时间。 所以接下来，请出本文的主角 —— makefile。 Makefile112hellomake: hellomake.c hellofunc.c gcc -o hellomake hellomake.c hellofunc.c -I. 把上述的内容，放入到 Makefile 或者 makefile 文件，然后在命令行输入 make 命令，就能够直接执行编译了。有以下几点我们需要关注下： 如果 make 后面没有跟任何参数，那么他就会执行 makefile 的第一条规则。 把命令依赖的文件放在第一行的 : 后面，这样 make 就能知道，当依赖文件变化时， hellomake 规则需要重新执行。 注意，第二行 gcc 前面，是一个 tab 制表符！不要使用空格！ 通过这样简单的 Makefile，我们已经解决了弊端一的问题，即：我们不需要每次都输入编译指令了。 然而，现在还不够高效，即使只修改了一个文件，还是需要全量编译（即编译所有的源文件）。为了使编译更加高效，让我们继续往下看。 Makefile212345CC=gccCFLAGS=-I.hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o 我们定义了两个常量 CC、 CFLAGS，这两个常量告诉 make 怎么去编译 hellomake.c 和 hellofunc.c。其中 CC 告诉 make 使用哪个 C 编译器，CFLAGS 说明了编译指令的参数列表。通过把 hellomake.o 和 hellofunc.o 放到依赖列表中， make 指令就知道每次需要分别编译 .c 文件，然后再把他们编译为可行性文件 hellomake。 终端执行效果如下： 12345➜ makefile-tourial git:(master) ✗ makegcc -I. -c -o hellomake.o hellomake.cgcc -I. -c -o hellofunc.o hellofunc.cgcc -o hellomake hellomake.o hellofunc.o➜ makefile-tourial git:(master) ✗ 这种形式的 makefile 对小型的项目还是比较方便的。然而，还是有个问题，那就是依赖文件的更新。设想下，即使你修改了hellomake.h 文件，make 指令不会重新编译文件。 为了解决这个问题，我们需要告诉 make 一件事情：即.c 文件和 .h 文件间的依赖关系。好，我们继续往下看。 Makefile3123456789CC=gccCFLAGS=-I.DEPS = hellomake.h%.o: %.c $(DEPS) $(CC) -c -o $@ $&lt; $(CFLAGS)hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o 相较于上个版本，我们先是增加了一个 DEPS：这里列出了 .c 文件所依赖的 .h 文件集合。 接着，我们定义了一个了规则 %.o: %.c $(DEPS)：它说明了 .o 文件是取决于 .c 文件和 DEPS 里的 .h 文件。 接下来我们看下规则 $(CC) -c -o $@ $&lt; $(CFLAGS)，意思是说，为了生成这些 .o 文件，make 指令使用了 CC 定义的编译器来编译 .c 文件： -c 说明了是为了生成目标文件（object files） $@ 代表 : 左边的内容，即：%.o $&lt; 是依赖列表里的第一项，即：%.c CFLAGS 和之前的说明一样，就是编译的指令参数了(flag） 执行效果如下： 12345➜ makefile-tourial git:(master) ✗ makegcc -c -o hellomake.o hellomake.c -I.gcc -c -o hellofunc.o hellofunc.c -I.gcc -o hellomake hellomake.o hellofunc.o➜ makefile-tourial git:(master) ✗ 最后，我们再来做下简化，使编译更具通用性。我们使用 $@ 和 $^ 来分别表示 : 的左侧和右侧。在下面的例子里，所有 include 文件会作为 DEPS 的一部分，所有目标文件（object files）会作为 OBJ 的一部分。 Makefile412345678910CC=gccCFLAGS=-I.DEPS = hellomake.hOBJ = hellomake.o hellofunc.o%.o: %.c $(DEPS) $(CC) -c -o $@ $&lt; $(CFLAGS) hellomake: $(OBJ) $(CC) -o $@ $^ $(CFLAGS) 执行效果如下： 1234➜ makefile-tourial git:(master) ✗ makegcc -c -o hellomake.o hellomake.c -I.gcc -c -o hellofunc.o hellofunc.c -I.gcc -o hellomake hellomake.o hellofunc.o -I. 让我们来进一步思考下： 我们能不能把 .h 的文件都放到一个专门的 inlcude 目录，把 .c 文件都放到一个专门的 src目录？ 我们能不能把这些烦人的 .o 文件都隐藏起来？ 当然是可以的！我们会在下一个 makefile 中把对应的文件放到 include 和 lib文件夹中，并且把生成的目标文件都放到 src 的 obj 子目录中。除此之外，我们还可以定义任何我们想包含的库文件，比如常用的 math library -lm。这个 makefile 放在 src 目录里。 需要注意的是，我们还定义了一个 clean 规则，用来把生成的目标文件清除（使用 make clean 命令）。.PHONY 防止 make 清除名为 clean 的文件。 文件路径为 1234567891011➜ src git:(master) ✗ tree .├── hellofunc.c├── hellomake├── hellomake.c├── makefile└── obj ├── hellofunc.o └── hellomake.o1 directory, 6 files Makefile512345678910111213141516171819202122232425IDIR = ../includeCC=gccCFLAGS=-I$(DIR)ODIR=objLDIR=../libLIBS=-lm_DEPS = hellomake.hDEPS=$(patsubst %,$(IDIR)/%,$(_DEPS))_OBJ = hellomake.o hellofunc.oOBJ=$(patsubst %,$(ODIR)/%,$(_OBJ))$(ODIR)/%.o: %.c $(DEPS)( $(CC) -c -o $@ $&lt; $(CFLAGS) hellomake: $(OBJ) $(CC) -o $@ $^ $(CFLAGS) $(LIBS) .PHONY: cleanclean: rm -f $(ODIR)/*.o *~ core $(INCDIR)/*~ 运行结果 1234➜ src git:(master) ✗ makegcc -c -o obj/hellomake.o hellomake.c -I../includegcc -c -o obj/hellofunc.o hellofunc.c -I../includegcc -o hellomake obj/hellomake.o obj/hellofunc.o -I../include 注意要在 src 目录下运行，并且要把 .h 文件放到 include 目录里 好了，到目前为止，你已经有了一个不错的 makefile 了，现在你能 hold 住一个中型的项目了。你也可以增加更多的规则到 makefile 里，你甚至可以在一个规则中调用另一个规则。 想知道更多关于 makefile 和 make 的信息，就去查阅 GNU Make Manual 吧！","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[]},{"title":"借助 skywalking 搭建自己的 APM 数据展示平台","slug":"build-your-own-ui-for-skywalking","date":"2020-11-28T09:27:41.000Z","updated":"2020-11-28T11:10:56.931Z","comments":true,"path":"2020/11/28/build-your-own-ui-for-skywalking/","link":"","permalink":"https://rovast.github.io/2020/11/28/build-your-own-ui-for-skywalking/","excerpt":"","text":"SkyWalking: an APM(application performance monitor) system, especially designed for microservices, cloud native and container-based (Docker, Kubernetes, Mesos) architectures. README.mdgithub.com/apache/skywalking skywaking(本文后续简称 SW) 在如今的 APM 体系建设中逐渐展露头角，国内几乎所有的一线大厂都借助 skywaling 进行了自己的 APM 体系建设。大厂的建设方案在诸多的大会中都有提及，尤其在刚过去的 《Apache SkyWalking DevCon 2020》，更是带来了诸多的精彩分享。 本文不会就 APM 架构或理论进行详细阐述，更多聚焦在实战环节，围绕下述几点展开： 分析 SW 架构，确定接入方案 如何在本地调式官方的 UI 项目 快速了解 SW 查询协议 GraphQL Skywalking 架构简介，寻找接入点几个官方库在正式分析之前，我们来看下 SW 比较重要的三个官方项目 主库 https://github.com/apache/skywalking UI 库 https://github.com/apache/skywalking-rocketbot-ui 查询协议库 https://github.com/apache/skywalking-query-protocol SW 查询协议 —— 获取数据的桥梁接下来，我们看下主库的架构图，即 SW 体系的整体架构图： 我们关注的 UI 接入部分，在图的左上角，其中 UI 和 CLI 通过查询协议来和 SW 的后端服务进行交互。正如查询协议库所说： Query Protocol defines the communication protocol in query stage.SkyWalking native UI and CLI use this protocol to fetch data from the backend consistently, don’t need to worry about the backend update. README.mdgithub.com/apache/skywalking-query-protocol 其中重点我们加粗表示了，即：SW 的官方 UI 和 CLI 工具都是通过查询协议和后端服务进行数据交互。 SW 的查询协议通俗简单的理解：定义了一系列 GraphQL 查询定义。甚至可以进一步粗暴的理解，就是一堆定义好的 HTTP API。所以只要了解官方的 API 定义，即可发挥 SW 的数据宝藏威力，打造属于自己的 APM 展示平台。 快速搭建的第一步，就是参考官方的 UI 项目，一方面我们可以参考它的 UI 组件实现。另一方面，我们可以抓包，参考它的 GraphQL 请求。 官网项目本地调试本地运行一览12345# 设置后端的请求地址为 SW 官方的北京机房演示地址➜ skywalking-rocketbot-ui git:(master) export SW_PROXY_TARGET=http://122.112.182.72:8080/# 启动服务，之后访问 8080 端口➜ skywalking-rocketbot-ui git:(master) npm run serve 访问 http://localhost:8080/topology 我们看到，服务已成功在本地运行，且可以通过 VueDev Tools 来查看对应的组件实现和传值。对我们自己去实现对应的显示组件，提供了极高的参考意义。 关于如何这个环境变量的设置，大家可以顺着 packages.json 去捋一下 run server 的整个流程 服务抓包格式化我们还是以这个拓扑为例，抓一个包，简单看下 GraphQL 请求 requestPayload1234567891011&#123; \"query\": \"query queryTopo($duration: Duration!) &#123;\\n topo: getGlobalTopology(duration: $duration) &#123;\\n nodes &#123;\\n id\\n name\\n type\\n isReal\\n &#125;\\n calls &#123;\\n id\\n source\\n detectPoints\\n target\\n &#125;\\n &#125;&#125;\", \"variables\": &#123; \"serviceId\": 0, \"duration\": &#123; \"start\": \"2020-11-27 0912\", \"end\": \"2020-11-27 0927\", \"step\": \"MINUTE\" &#125; &#125;&#125; 我们进一步格式化 graphQL 的 query 请求12345678910111213141516query queryTopo($duration: Duration!) &#123; topo: getGlobalTopology(duration: $duration) &#123; nodes &#123; id name type isReal &#125; calls &#123; id source detectPoints target &#125; &#125;&#125; 格式化过后，更方便我们进行对应分析。 分析查询协议快速了解查询语句含义GraphQL 的更多用法，本文不提及。文本就上述抓到的协议进行简单说明，便于之前不了解 GraphQL 的同学能够快速了解 SW 查询协议。 查看 Query，确定查询语句，其中 $ 开头的就是形参，在 variables 里会具体传值 那上述例子，$duration 的具体值，就是 12345&#123; \"start\": \"2020-11-27 0912\", \"end\": \"2020-11-27 0927\", \"step\": \"MINUTE\"&#125; 那问题来了，我怎么知道 $duration 是由 start end step 组成？他们的值类型是什么？在哪里定义？这就要看之前我们提到的 SW 查询协议。 查询协议接着上面的分析，我们去查看 SW 的 Query Protocol. 到这里大家看到，其实 Query Protocol 就是查询的定义，标准。就像我们平时开发中接触的后端标准接口一样。大家在接触这些看似高大上的 Query Protocol 时，不要被唬到，其实就是相同技术在不同场合的不同叫法罢了。 本例中的拓扑，我们可以查看 https://github.com/apache/skywalking-query-protocol/blob/master/topology.graphqls 定义： 123456789101112131415extend type Query &#123; # Query the global topology getGlobalTopology(duration: Duration!): Topology # Query the topology, based on the given service getServiceTopology(serviceId: ID!, duration: Duration!): Topology # Query the topology, based on the given services. # `#getServiceTopology` could be replaced by this. getServicesTopology(serviceIds: [ID!]!, duration: Duration!): Topology # Query the instance topology, based on the given clientServiceId and serverServiceId getServiceInstanceTopology(clientServiceId: ID!, serverServiceId: ID!, duration: Duration!): ServiceInstanceTopology # Query the topology, based on the given endpoint getEndpointTopology(endpointId: ID!, duration: Duration!): Topology # v2 of getEndpointTopology getEndpointDependencies(endpointId: ID!, duration: Duration!): EndpointTopology&#125; 我们看到其中就有 getGlobalTopology，再看看我们之前的抓包，我能看下第二行： 12345678910111213141516query queryTopo($duration: Duration!) &#123; topo: getGlobalTopology(duration: $duration) &#123; nodes &#123; id name type isReal &#125; calls &#123; id source detectPoints target &#125; &#125;&#125; 第二行内容 topo: getGlobalTopology(duration: $duration) { topo 是查询结果的别名，查询到 response 会放到 topo 字段下 getGlobalTopology 的定义就是 getGlobalTopology(duration: Duration!): Topology 其中 Duration 定义，我们在 https://github.com/apache/skywalking-query-protocol/blob/master/common.graphqls 得到 12345input Duration &#123; start: String! end: String! step: Step!&#125; 就像套娃一样，你也可以找到 Step 的定义 总结本文聊了我们如何找到自定义 UI 的切入点，同时就如何参考官方的一些开发细节进行了阐述。希望能给大家自定义数据展示平台一些参考。","categories":[{"name":"云原生","slug":"云原生","permalink":"https://rovast.github.io/categories/云原生/"}],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2020-11-28T08:49:18.064Z","updated":"2020-11-28T08:49:18.064Z","comments":true,"path":"2020/11/28/hello-world/","link":"","permalink":"https://rovast.github.io/2020/11/28/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Install php7.2 on Ubuntu 18.04 LTS","slug":"install-php72-ubuntu","date":"2019-12-02T01:54:24.000Z","updated":"2020-11-28T08:49:18.065Z","comments":true,"path":"2019/12/02/install-php72-ubuntu/","link":"","permalink":"https://rovast.github.io/2019/12/02/install-php72-ubuntu/","excerpt":"","text":"12345678# 安装 php7.2sudo apt-get install php7.2 php7.2-fpm \\php7.2-mysql php7.2-curl php7.2-mbstring php7.2-gd php7.2-xml php7.2-soap# 安装 mcryptsudo apt install php-dev libmcrypt-dev php-pearsudo pecl channel-update pecl.php.netsudo pecl install mcrypt-1.0.1 123sudo vi /etc/php/7.2/cli/php.inisudo vi /etc/php/7.2/fpm/php.ini# 最后加上 `extension=mcrypt.so` 12sudo vi /etc/php/7.2/fpm/pool.d/www.conf# 修改 listen 为 127.0.0.1:9000 测试 nginx 是否可用1sudo nginx -c /etc/nginx/nginx.conf","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/tags/Linux/"}]},{"title":"docker 安装","slug":"install-docker","date":"2019-11-28T09:06:18.000Z","updated":"2020-11-28T08:49:18.065Z","comments":true,"path":"2019/11/28/install-docker/","link":"","permalink":"https://rovast.github.io/2019/11/28/install-docker/","excerpt":"","text":"安装12345// 安装 dockercurl -sSL https://get.daocloud.io/docker | sh// 注意更改所属用户组sudo usermod -aG docker YOUR_GROUP 注销用户后重新登录 12// 启动 dockersudo systemctl start docker 12345// 安装 docker-composesudo pip install -U docker-compose// 如果没有 pipsudo apt-get install python-pi","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://rovast.github.io/tags/docker/"}]},{"title":"时间复杂度","slug":"time-complexity","date":"2019-11-06T01:35:45.000Z","updated":"2020-11-28T08:49:18.085Z","comments":true,"path":"2019/11/06/time-complexity/","link":"","permalink":"https://rovast.github.io/2019/11/06/time-complexity/","excerpt":"","text":"写在前面技术人员的内功修炼：操作系统、计算机网络、编译原理、数据结构与算法。 时间复杂度时间复杂度分下面几个维度： 最好时间复杂度（Best Case Time Complexity） 最坏时间复杂度（Worst Case Time Complexity） 平均时间复杂度（Average Case Time Complexity） 均摊时间复杂度（Amortized Time Complexity）","categories":[{"name":"基础","slug":"基础","permalink":"https://rovast.github.io/categories/基础/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rovast.github.io/tags/数据结构与算法/"}]},{"title":"使用 www-data 用户运行定时任务（cron）","slug":"run-cron-with-www-data","date":"2019-11-04T07:03:07.000Z","updated":"2020-11-28T08:49:18.081Z","comments":true,"path":"2019/11/04/run-cron-with-www-data/","link":"","permalink":"https://rovast.github.io/2019/11/04/run-cron-with-www-data/","excerpt":"","text":"其实这个没啥好说的，就是记录下解决的过程（说得好像跟一篇水文似的…）。或者给遇到这类问题的小伙伴提供个思路。 痛点我们在部署 web 服务时，经常用到定时任务。正常的流程就是直接执行下面的指令来配置定时任务 1crontab -e 问题来了，正常情况下，这个指令在哪个用户下面执行，这个权限就是谁的（如果你听不懂我在说啥，那基本就是属于 root的）。 定时任务本身的配置也是个精细活，你可以阅读下 https://learnku.com/articles/25177 看看你之前用的姿势是不是还能优化。 常见问题之日志权限 这怕是最常见的问题了。定时任务出错了，记录日志到 storage/logs 里了，一般就是 laravel.log 文件。 此时 laravel.log 所属者就是 root 了。 用户通过浏览器访问我们网站，如果出错，以 www-data 身份尝试记录到 storage/logs/laravel.log，然后写不进去，一直报错，真香！ 解决打开谷歌搜索 run cron job as www-data。找到了文章 https://askubuntu.com/questions/189189/how-to-run-crontab-as-userwww-data 谷歌真香！ 具体的意思，就是直接在 /etc/crontab 中编辑定时任务即可，加上用户名。 1234567891011121314151617181920212223242526# /etc/crontab: system-wide crontab# Unlike any other crontab you don't have to run the `crontab'# command to install the new version when you edit this file# and files in /etc/cron.d. These files also have username fields,# that none of the other crontabs do.SHELL=/bin/shPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed17 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly )## cron* * * * * www-data flock /tmp/flock1.lock -c 'timeout 200 /usr/local/bin/php /var/www/html/laravel/artisan command &gt;&gt; /home/log/laravel.log 2&gt;&amp;1' 啰嗦下： flock 用来防止重复执行，起到原子锁作用 timeout 表示这个脚本执行过长，咱就干死它，可以有效避免各种循环或长时间占用问题 &gt;&gt; 表示向文件中追加内容 2&gt;&amp;1 表示将标准错误输出重定向到正确输出（这样你万一有程序出错，也能记录下） 真香后传（更新于 2019年11月06日19:38:27）如果你按照上述的进行，你会发现还是执行不了定时任务。因为 www-data 默认是不能执行 bash 相关操作的。 使用真香的谷歌搜索 www-data run cron error，我们发现了宝藏 https://ubuntuforums.org/showthread.php?t=2334330 The www-data user is not able to invoke a shell by default. In /etc/passwd you’ll see Code: www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin If you want to be able to run scripts as that user, you’ll need to change “/usr/sbin/nologin” to “/bin/bash”. 好了，咱们把 /etc/passwd 里面 www-data 对应的那一行改下就可以了。 另外 其实你还可以用 crontab -u www-data CRON_FILE 来指定用户运行指定的定时任务。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/tags/Linux/"}]},{"title":"macos 莫名失去焦点","slug":"macos-lost-focus","date":"2019-10-15T15:05:22.000Z","updated":"2020-11-28T08:49:18.067Z","comments":true,"path":"2019/10/15/macos-lost-focus/","link":"","permalink":"https://rovast.github.io/2019/10/15/macos-lost-focus/","excerpt":"","text":"执行下述 python 代码，观测除了当前应用程序外，还有谁占用了焦点 123456789#!/usr/bin/pythonfrom AppKit import NSWorkspaceimport timet = range(1,100)for i in t: time.sleep(3) activeAppName = NSWorkspace.sharedWorkspace().activeApplication()['NSApplicationName'] print activeAppName 查看输出即可","categories":[],"tags":[]},{"title":"git diff between {working dir, staged area, last commit}","slug":"git-diff","date":"2019-09-24T08:48:59.000Z","updated":"2020-11-28T08:49:18.052Z","comments":true,"path":"2019/09/24/git-diff/","link":"","permalink":"https://rovast.github.io/2019/09/24/git-diff/","excerpt":"","text":"参考链接： http://xahlee.info/linux/git_diff.html 本文阐述 git diff 的不同用法。 git 中有三个主要区域 Working Directory 工作区。当前用户正在工作的区域 Staging Area（也被叫做 cache，index）。使用 git add 后存放的临时位置 HEAD 指向一个 commit 位置。通常情况下，是指上一次提交 上面的三个区域，都是在你本地的。每个 commit 都会有一个特定的标识（id），我们称之为 commit id。 如何查看 commit12# 显示最近的三次 commitgit log -3 diff between {working dir, staging area}12345# diff working dir, staging areagit diff --color# diff working dir, staging area, 1 filegit diff --color filename diff between {staging area, last commit}12# diff satging area, last commit. 其中 staged 参数也可用 cached 替代git diff --color --staged &lt;commitID&gt; diff between {last commit, working dir}1git diff --color &lt;commitID&gt; 对同一分支的两个 commit 进行 diff git log file_name git diff commit_ID_1 commit_ID_2 file_name 查看哪些文件被 staged 了12345# 获取当前的状态git status .# 推荐使用下面的，简洁明了git status -s","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[{"name":"git","slug":"git","permalink":"https://rovast.github.io/tags/git/"}]},{"title":"view-ascii-on-linux","slug":"view-ascii-on-linux","date":"2019-08-22T01:39:33.000Z","updated":"2020-11-28T08:49:18.090Z","comments":true,"path":"2019/08/22/view-ascii-on-linux/","link":"","permalink":"https://rovast.github.io/2019/08/22/view-ascii-on-linux/","excerpt":"","text":"开发中会经常查看 ascii 表，没想到在 linux 上可以直接查看，记录下。 1man ascii 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121ASCII(7) Linux Programmer's Manual ASCII(7)NAME ascii - ASCII character set encoded in octal, decimal, and hexadecimalDESCRIPTION ASCII is the American Standard Code for Information Interchange. It is a 7-bit code. Many 8-bit codes (e.g., ISO 8859-1) contain ASCII as their lower half. The international counterpart of ASCII is known as ISO 646-IRV. The following table contains the 128 ASCII characters. C program '\\X' escapes are noted. Oct Dec Hex Char Oct Dec Hex Char ──────────────────────────────────────────────────────────────────────── 000 0 00 NUL '\\0' (null character) 100 64 40 @ 001 1 01 SOH (start of heading) 101 65 41 A 002 2 02 STX (start of text) 102 66 42 B 003 3 03 ETX (end of text) 103 67 43 C 004 4 04 EOT (end of transmission) 104 68 44 D 005 5 05 ENQ (enquiry) 105 69 45 E 006 6 06 ACK (acknowledge) 106 70 46 F 007 7 07 BEL '\\a' (bell) 107 71 47 G 010 8 08 BS '\\b' (backspace) 110 72 48 H 011 9 09 HT '\\t' (horizontal tab) 111 73 49 I 012 10 0A LF '\\n' (new line) 112 74 4A J 013 11 0B VT '\\v' (vertical tab) 113 75 4B K 014 12 0C FF '\\f' (form feed) 114 76 4C L 015 13 0D CR '\\r' (carriage ret) 115 77 4D M 016 14 0E SO (shift out) 116 78 4E N 017 15 0F SI (shift in) 117 79 4F O 020 16 10 DLE (data link escape) 120 80 50 P 021 17 11 DC1 (device control 1) 121 81 51 Q 022 18 12 DC2 (device control 2) 122 82 52 R 023 19 13 DC3 (device control 3) 123 83 53 S 024 20 14 DC4 (device control 4) 124 84 54 T 025 21 15 NAK (negative ack.) 125 85 55 U 026 22 16 SYN (synchronous idle) 126 86 56 V 027 23 17 ETB (end of trans. blk) 127 87 57 W 030 24 18 CAN (cancel) 130 88 58 X 031 25 19 EM (end of medium) 131 89 59 Y 032 26 1A SUB (substitute) 132 90 5A Z 033 27 1B ESC (escape) 133 91 5B [ 034 28 1C FS (file separator) 134 92 5C \\ '\\\\' 035 29 1D GS (group separator) 135 93 5D ] 036 30 1E RS (record separator) 136 94 5E ^ 037 31 1F US (unit separator) 137 95 5F _ 040 32 20 SPACE 140 96 60 ` 041 33 21 ! 141 97 61 a 042 34 22 \" 142 98 62 b 043 35 23 # 143 99 63 c 044 36 24 $ 144 100 64 d 045 37 25 % 145 101 65 e 046 38 26 &amp; 146 102 66 f 047 39 27 ' 147 103 67 g 050 40 28 ( 150 104 68 h 051 41 29 ) 151 105 69 i 052 42 2A * 152 106 6A j 053 43 2B + 153 107 6B k 054 44 2C , 154 108 6C l 055 45 2D - 155 109 6D m 056 46 2E . 156 110 6E n 057 47 2F / 157 111 6F o 060 48 30 0 160 112 70 p 061 49 31 1 161 113 71 q 062 50 32 2 162 114 72 r 063 51 33 3 163 115 73 s 064 52 34 4 164 116 74 t 065 53 35 5 165 117 75 u 066 54 36 6 166 118 76 v 067 55 37 7 167 119 77 w 070 56 38 8 170 120 78 x 071 57 39 9 171 121 79 y 072 58 3A : 172 122 7A z 073 59 3B ; 173 123 7B &#123; 074 60 3C &lt; 174 124 7C | 075 61 3D = 175 125 7D &#125; 076 62 3E &gt; 176 126 7E ~ 077 63 3F ? 177 127 7F DEL Tables For convenience, below are more compact tables in hex and decimal. 2 3 4 5 6 7 30 40 50 60 70 80 90 100 110 120 ------------- --------------------------------- 0: 0 @ P ` p 0: ( 2 &lt; F P Z d n x 1: ! 1 A Q a q 1: ) 3 = G Q [ e o y 2: \" 2 B R b r 2: * 4 &gt; H R \\ f p z 3: # 3 C S c s 3: ! + 5 ? I S ] g q &#123; 4: $ 4 D T d t 4: \" , 6 @ J T ^ h r | 5: % 5 E U e u 5: # - 7 A K U _ i s &#125; 6: &amp; 6 F V f v 6: $ . 8 B L V ` j t ~ 7: ' 7 G W g w 7: % / 9 C M W a k u DEL 8: ( 8 H X h x 8: &amp; 0 : D N X b l v 9: ) 9 I Y i y 9: ' 1 ; E O Y c m w A: * : J Z j z B: + ; K [ k &#123; C: , &lt; L \\ l | D: - = M ] m &#125; E: . &gt; N ^ n ~ F: / ? O _ o DELNOTES History An ascii manual page appeared in Version 7 of AT&amp;T UNIX. On older terminals, the underscore code is displayed as a left arrow, called backarrow, the caret is displayed as an up-arrow and the vertical bar has a hole in the middle. Uppercase and lowercase characters differ by just one bit and the ASCII character 2 differs from the double quote by just one bit, too. That made it much easier to encode characters mechanically or with a non-microcontroller-based electronic key‐ board and that pairing was found on old teletypes. The ASCII standard was published by the United States of America Standards Institute (USASI) in 1968.SEE ALSO charsets(7), iso_8859-1(7), iso_8859-10(7), iso_8859-11(7), iso_8859-13(7), iso_8859-14(7), iso_8859-15(7), iso_8859-16(7), iso_8859-2(7), iso_8859-3(7), iso_8859-4(7), iso_8859-5(7), iso_8859-6(7), iso_8859-7(7), iso_8859-8(7), iso_8859-9(7), utf-8(7)COLOPHON This page is part of release 4.15 of the Linux man-pages project. A description of the project, information about reporting bugs, and the latest version of this page, can be found at https://www.kernel.org/doc/man-pages/.Linux 2016-10-08 ASCII(7)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/tags/Linux/"}]},{"title":"记录一个 ab 工具使用的小坑","slug":"some-tricks-in-ab-benchmark","date":"2019-08-15T03:17:35.000Z","updated":"2020-11-28T08:49:18.083Z","comments":true,"path":"2019/08/15/some-tricks-in-ab-benchmark/","link":"","permalink":"https://rovast.github.io/2019/08/15/some-tricks-in-ab-benchmark/","excerpt":"","text":"最近在使用 ab 进行压测时，出现一个小问题： 每次请求返回的状态码都是 200，但是有大量的 failed！ 排查问题首先，查询 nginx 的 access log，我们发现压测的请求返回的都是 200。这说明我们请求没有问题 怀疑是 ab 工具问题 使用 jmeter 压测使用 jmeter 进行压测，发现请求居然都是正确的。验证是 ab 问题 网上查询相应问题https://stackoverflow.com/questions/6475692/investigating-apache-benchmark-failed-request 查询得到上述答案 验证使用 man ab 查看 ab 文档，发现果然有 -l 参数 1-l Do not report errors if the length of the responses is not constant. This can be useful for dynamic pages. Available in 2.4.7 and later. 意思就是说， ab 默认情况下认为返回的长度不一致就记录为 error，通过 -l 参数可以取消这种设定 1ab -l -n 50000 -c 50 xxxxxxxxxx 加上参数后，可以正常压测了。","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/tags/杂项/"}]},{"title":"phpstorm 集成 phpCodeSniffer","slug":"phpstorm-load-phpCodeSniffer","date":"2019-08-14T10:14:02.000Z","updated":"2020-11-28T08:49:18.079Z","comments":true,"path":"2019/08/14/phpstorm-load-phpCodeSniffer/","link":"","permalink":"https://rovast.github.io/2019/08/14/phpstorm-load-phpCodeSniffer/","excerpt":"","text":"本文主要指导如何在 phpstorm 中集成 phpCodeSniffer（简称：phpCS） 安装 phpCS 如何在 phpStorm 中加载 phpCS 如何加载自定义的 phpCS 的 xml 规则文件 如何在 php 文件中实时提示 如何根据规则实时修正 phpStorm 官方指导文档：https://www.jetbrains.com/help/phpstorm/using-php-code-sniffer.html 安装 phpCS安装 phpCS 有多种途径，可以参考 https://github.com/squizlabs/PHP_CodeSniffer#installation 我们使用 composer 方式安装，为了便于在所有项目中使用 phpCS，我们使用全局方式安装。 1composer global require \"squizlabs/php_codesniffer=*\" -vvv 安装完成后，会多出两个指令 phpcs 和 phpcbf 在 phpStorm 中加载 phpCS 按照截图的路径 File &gt; Settings &gt; Language &amp; Framework &gt; PHP &gt; Quality Tools &gt; Code Sniffer，选择 Local 后选择刚才的安装路径。 如果不清楚刚才安装的全局路径，Linux 下可使用 whereis phpcs 查看路径。其他系统可自行搜索 “composer 全局 bin 目录” 获取更多帮助。 或者，你也可以用 composer global config bin-dir --absolute 来查看 composer 的 bin 目录` 加载自定义 xml 规则文件 首先，需要开启 phpCodeSniffer 的验证提示，如截图所示。其次，在截图右下角，选择 custom 来加载自定义的 xml 文件。 加载完毕后，即可正常对打开的 PHP 文件进行实时检测。 实时验证 PHP 文件进行上述配置后，对打开的 PHP 文件会进行实时检测。 如图所示，对于不符合规范的代码，会进行波浪线显示，鼠标悬浮后可以看到详细说明。 自动修正光标放置在波浪线处，按下组合键 alt + enter，选择 PHP Code Beautifier and Fixer 即可修正。 修正后 总结结合 phpCS，我们可以在开发时实时检测团队代码规范，便于在提交前进行规范统一。 集成在 IDE 中的 phpCS 可以对打开的文件进行实时检测，如果需要对整个项目或者是指定的文件夹进行检测，可以直接使用 phpcs 命令进行检测，使用 phpcbf 进行修正。","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://rovast.github.io/tags/PHP/"}]},{"title":"sonar 初探","slug":"start-sonar","date":"2019-08-13T07:50:16.000Z","updated":"2020-11-28T08:49:18.083Z","comments":true,"path":"2019/08/13/start-sonar/","link":"","permalink":"https://rovast.github.io/2019/08/13/start-sonar/","excerpt":"","text":"安装 参考文档 https://docs.sonarqube.org/latest/setup/get-started-2-minutes/ sonar 由两部分组成：sonarqube 和 sonar-scanner-cli。前者是 web 端，后者是 CLI 端。下载地址如下： https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-7.9.1.zip https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.0.0.1744-linux.zip 另外，运行 sonar 需要 jvm 环境，自行安装。ubuntu 可执行 apt install openjdk-11-jdk 运行 web 端启动服务解压 sonarqube-7.9.1.zip 后，进入 sonarqube-7.9.1 目录，执行下述指令启动，之后访问 http://localhost:9000 1./bin/linux-x86-64/sonar.sh console 另外，如果需要修改配置，修改 conf/sonar.properties 文件即可，其中 92 行附近可以修改运行内存 1sonar.web.javaOpts=-Xmx5000m -Xms5000m -XX:+HeapDumpOnOutOfMemoryError 登录系统访问 http://localhost:9000，登录信息 用户名 admin 密码 admin 创建项目点击右上角加号，创建项目，输入项目名称、token 信息后，会显示一个指令，用户 进行代码扫描之前我们安装了 sonar-scanner-cli-4.0.0.1744-linux.zip，解压后，增加 bin 到环境变量 1export PATH=$PATH:/home/rovast/Software/sonar-scanner-4.0.0.1744-linux/bin 然后使其生效 source ~/.bashrc 或者 source ~/.zshrc 根据上一步的提示，进入到需要扫描的项目录，执行 12345sonar-scanner \\ -Dsonar.projectKey=laravel-framework \\ -Dsonar.sources=. \\ -Dsonar.host.url=http://localhost:9000 \\ -Dsonar.login=0273f96b7dd12e0790ab2350b4c497fcedff6b36 等待运行结束后，web 端会自动加载对应报告进行分析 查看分析报告 自定义检测规则参考 https://docs.sonarqube.org/latest/analysis/languages/php/ 总结总结起来，sonar 的特点就是功能强大。 支持的语言丰富，主流的开发语言基本都支持了 web 界面友好，可以很清晰地查看报告和分析 分析的指标丰富：安全性、技术负债、覆盖度、主流规则等等 marketplace 除了上述有点外，sonar 也有一些其他方面待考量的地方 sonar 是基于 java 开发，如果需要拓展其中的规则，需要了解 java 体系 sonar 本身是一个成熟的产品，如果基于这个来自定义工作流，难度较大 sonar 资源占用较大 所以如果需要一套成熟的代码检测相关工具，sonar 是个不错的选择。 sonar 和 phpCodeSinffer 对比 https://github.com/SonarSource/sonarqube https://github.com/squizlabs/PHP_CodeSniffer 最大的区别 sonar 是一个产品提供了完善的解决方案 phpCodeSniffer 是一个工具，专注于 php 语法检查 拓展性 sonar 是成套的解决方案，可定制化程序较低。需要在 sonar 现有的 rules 中组合自己的 rule，或者在 marketPlace 中找到合适的组件。 如果需要开发完全自定义的规则，可参考 https://docs.sonarqube.org/latest/analysis/languages/php/ ，使用 java 开发对应的规则 如果基于 sonar 来构建自己的工作流，可行性较低。因为他本身是个产品，所有功能都集成了，有自己的一套思想 phpCodeSniffer 是基于 PHP 的一套语法检测工具 phpCodeSniffer 预留了语法检查的接口和类。如果需要自定义规则，实现对应的接口或类即可，较为简单 如果基于 phpCS 来构建自己工作流，较为现实。毕竟它只是个工具 另外，phpCS 有基于 IDE 的一些插件，可以集成到编辑器中实时检查 总结 如果只是做语法检查，并且希望高度自定义，推荐使用 phpCodeSniffer 如果对定制化程度没有要求，希望有个工具开箱即用，并且也无后续定制需求，可使用 sonar 【推荐】使用 phpCS，这样便于后期和也无框架高度集成，便于做更多贴合框架和业务的检测。比如业务级别调用规范等","categories":[],"tags":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/tags/杂项/"}]},{"title":"记一次 C# aes 加密转 php","slug":"c-sharp-aes-to-php-note","date":"2019-06-28T03:35:53.000Z","updated":"2020-11-28T08:49:18.044Z","comments":true,"path":"2019/06/28/c-sharp-aes-to-php-note/","link":"","permalink":"https://rovast.github.io/2019/06/28/c-sharp-aes-to-php-note/","excerpt":"","text":"记录一次 C# 转 PHP 中遇到的一个问题。 描述：aes-128-cbc 的 c# 转 php c# 代码1234567891011121314151617181920212223242526using System;using System.Security.Cryptography;using System.Text;namespace Rextester &#123; class Program &#123; public static string EncryptAES (string key, string content) &#123; // 关键代码 using (var aes = new RijndaelManaged ()) &#123; aes.BlockSize = 128; aes.IV = iv; aes.Key = key; aes.Mode = CipherMode.CBC; aes.Padding = PaddingMode.PKCS7; var cryptoTransform = aes.CreateEncryptor (); var resultArray = cryptoTransform.TransformFinalBlock (content, 0, content.Length); aes.Clear (); return Convert.ToBase64String (result, 0, result.Length); &#125; &#125; public static void Main (string[] args) &#123; Console.Write (EncryptAES (&quot;abcd&quot;, &quot;1234&quot;)); Console.Read (); &#125; &#125;&#125; PHP 代码1234567function myEncrypt($key, $content)&#123; // AES-128-CBC AES-192-CBC AES-256-CBC return base64_encode(openssl_encrypt($content,'AES-128-CBC', base64_encode(md5($key,true)), OPENSSL_RAW_DATA, $iv));&#125;myEncrypt('abcd', 'efg'); 注意点说明 OPENSSL_RAW_DATA 对应的是 PKCS7 AES-128-CBC 两个语言处理不一致 对于 PHP 而言，因为所使用的是 aes-128-cbc，所以 key length 需要是 128bits 才行。所以 php 会自动截取 $key，即 substr($key, 0, 16); 对于刚才的 C# 而言，可不一样了，如果 key length 大于 128bits，他会自动填充0，最后变为 aes-cbc-192，此时，php对应的方法也要改。","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[]},{"title":"composer 私有化备忘录","slug":"make-composer-private","date":"2019-06-20T01:41:18.000Z","updated":"2020-11-28T08:49:18.067Z","comments":true,"path":"2019/06/20/make-composer-private/","link":"","permalink":"https://rovast.github.io/2019/06/20/make-composer-private/","excerpt":"","text":"我们知道，正常情况下，我们使用 composer install 时，是从 https://packagist.org/ 拉取的 package.如果设置了 中国镜像，那么就会从你的镜像地址拉取。 处于一些需要，我们往往需要引用自己开发的 composer package。如果是公用还好，我们直接结合 github 和 packagist 发布共有的镜像就好了。 那如果我们使用的是自建的 git 服务（如： gitlab 或者 gogs）开发的 composer package，并且是私有，咋办？ 本文描述的是 不搭建私有 composer服务器 的方式来使用私有包。 全局包比如我们开发了全局的脚手架 12345678# 允许 http 源composer config --global secure-http false# 添加本项目的源composer config --global repositories.package vcs http://gitlab.yourhost.com/package.git# 全局安装composer global require vendor/package -vvv 非全局包修改调用方的 composer.json 即可，关键字段设置如下： 1234567891011121314&#123; \"repositories\": [ &#123; \"type\": \"vcs\", \"url\": \"http://gitlab.yourhost.com/package.git\" &#125; ], \"require\": &#123; \"vendor/name\": \"dev-master\" &#125;, \"config\": &#123; \"secure-http\": false &#125;&#125; 然后执行下述指令即可安装 1composer install -vvv 说明： secure-http 允许使用 http 协议的源 vendor/name 对应的是自己开发的 composer 包中的 composer.json 中定义的 name 字段 dev-master 表示和 master 分支保持一致。正常情况下，我们应该打 tag（或者又叫 release）","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://rovast.github.io/tags/PHP/"}]},{"title":"WDCP 和 Yapi 配置问题小记","slug":"yapi-deploy-note","date":"2019-06-18T09:39:25.000Z","updated":"2020-11-28T08:49:18.090Z","comments":true,"path":"2019/06/18/yapi-deploy-note/","link":"","permalink":"https://rovast.github.io/2019/06/18/yapi-deploy-note/","excerpt":"","text":"Nginx 反响代理配置1234567891011121314151617181920212223server &#123; listen 80; server_name api.wugee.vip; location / &#123; proxy_pass http://127.0.0.1:3000; &#125;&#125;server &#123; listen 443; server_name api.wugee.vip; ssl on; ssl_certificate cert/api.wugee.vip.pem; ssl_certificate_key cert/api.wugee.vip.key; ssl_prefer_server_ciphers on; ssl_session_timeout 10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; location / &#123; proxy_pass http://127.0.0.1:3000; &#125;&#125; yapi 服务启动1pm2 start yapi-app/server/app.js 系统自启动的 mongo 服务替换为自己原来的 mongo12345ps -ax | grep mongod # 查老服务kill -9 ID # 杀mongod -f /etc/mongod.conf # 启动新的 可以用下述命令看下 mongo 数据对不对123show dbs;use yapi;db.user.find() 重启 pm2 服务12pm2 list # 查看任务 idpm2 restart 0","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[]},{"title":"fix-ios-keyboard-in-webpage","slug":"fix-ios-keyboard-in-webpage","date":"2019-06-14T01:59:07.000Z","updated":"2020-11-28T08:49:18.051Z","comments":true,"path":"2019/06/14/fix-ios-keyboard-in-webpage/","link":"","permalink":"https://rovast.github.io/2019/06/14/fix-ios-keyboard-in-webpage/","excerpt":"","text":"123456789101112131415161718192021// 修复 IOS 键盘弹出空白的问题let ua = window.navigator.userAgent;let app = window.navigator.appVersion;//$alert('浏览器版本: ' + app + '\\n' + '用户代理: ' + ua);if (!!ua.match(/\\(i[^;]+;( U;)? CPU.+Mac OS X/)) &#123; //$alert('ios端'); $(\"input,textarea\").on(\"blur\", function () &#123; var currentPosition, timer; var speed = 1; timer = setInterval(function () &#123; currentPosition = document.documentElement.scrollTop || document.body.scrollTop; currentPosition -= speed; window.scrollTo(0, currentPosition);//页面向上滚动 currentPosition += speed; window.scrollTo(0, currentPosition);//页面向下滚动 clearInterval(timer); &#125;, 100); &#125;)&#125; else if (ua.indexOf('Android') &gt; -1 || ua.indexOf('Adr') &gt; -1) &#123; //$alert('android端');&#125;","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"移动端","slug":"移动端","permalink":"https://rovast.github.io/tags/移动端/"}]},{"title":"ubuntu 桌面版使用备忘","slug":"getting-star-with-ubuntu-desktop","date":"2019-06-13T01:53:06.000Z","updated":"2020-11-28T08:49:18.051Z","comments":true,"path":"2019/06/13/getting-star-with-ubuntu-desktop/","link":"","permalink":"https://rovast.github.io/2019/06/13/getting-star-with-ubuntu-desktop/","excerpt":"","text":"本文记录了使用 ubuntu 桌面版过程中的一些常见问题和初始化步骤。 桌面美化挪动关闭按钮至左侧首先安装 gnome-tweak-tool 1sudo apt install gnome-tweak-tool 安装完成后，打开软件： 选择“窗口”菜单 更改“标题栏按钮 - 放置”，设置为“左”即可 更改顶部 bar 显示方式为 unity 风格安装 unite gnome 拓展（怎么安装，参考 gnome 章节），然后启用即可。 使用思源宋体进入 https://github.com/adobe-fonts/source-han-serif/tree/release ，下载 OTF/SimplifiedChinese/SourceHanSerifSC-Regular.otf 下载完成后双击打开安装即可。 安装完成后，可以在 gnome-tweak 中设置字体。 gnome 相关安装 gnome shell extension12sudo apt install gnome-shell-extensionssudo apt install chrome-gnome-shell 然后安装 chrome 拓展 GNOME Shell integration 我一般使用 chromium-browser 安装拓展，貌似之前用 chrome 有问题 1sudo apt install chromium-browser 之后在 https://extensions.gnome.org/ 就能愉快的安装拓展了。 常用应用albert（类似 MacOS 的 alfred） 参考文章 《安装软件包 albert》 执行的操作为：123sudo sh -c \"echo 'deb http://download.opensuse.org/repositories/home:/manuelschneid3r/xUbuntu_18.04/ /' &gt; /etc/apt/sources.list.d/home:manuelschneid3r.list\"sudo apt-get updatesudo apt-get install albert 设置 hotkey 设置为 alt + ‘space’ extensions 打开 applications calculator 微信、企业微信、微信开发者工具主要参考 wszqkzqk/deepin-wine-ubuntu 安装一些依赖环境 1wget -qO- https://raw.githubusercontent.com/wszqkzqk/deepin-wine-ubuntu/master/online_install.sh | bash -e 去 阿里云镜像 下载所需安装包 使用 dpkg 指令安装 12345# 安装软件sudo dpkg -i package.deb# 出现软件安装依赖问题，使用此指令 fixsudo apt-get install -f 托盘通知 需要安装 Gnome Shell 插件：TopIcons Plus，参考 gnome 章节 钉钉钉钉使用的是 nashaofu/dingtalk 的包。 去 release 页面 下载对应 deb 包 dkpg -i 安装即可 注意 正确选择符合自己操作系统版本的 deb 包。 Typora（跨平台 markdown 编辑器）官方安装说明 一些使用小窍门 你可以在网页上复制你喜欢的文章，然后到编辑器第 view 模式下粘贴，在切换到 source 模式下，就能看到转义好的 markdown 了 而且， 图片路径 会自动加上 开发环境nginx安装我们采取编译安装的方式安装 nginx。先去官网下载压缩包，解压。 在执行 configure 前，需要安装一些依赖 1sudo apt-get install libpcre3 libpcre3-dev zlib1g zlib1g-dev libssl-dev 紧接着，正常安装即可，我安装的时候没有增加额外的配置，直接用的默认配置 123./configuremakesudo make install 安装完，相关路径如下 可执行文件目录 /usr/local/nginx/sbin 配置目录 /usr/local/nginx/conf 为了方便使用 nginx 指令，我们可以在 /usr/local/bin 下创建软连接。 配置为了方便使用，我们进行一下小配置。 我们在 /usr/local/nginx/conf/nginx.conf 的结尾处增加 include servers/*; 123456789101112131415161718192021222324 # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; include servers/*;&#125; 这样，我们只需要在 /usr/local/nginx/conf/servers 目录下配置站点信息即可。 我们新建下 /usr/local/nginx/conf/servers 1sudo mkdir /usr/local/nginx/conf/servers 开发工具phpstorm正常的操作是直接在官方上下载压缩包，解压即可。有意思的是，直接使用浏览器下载速度反而一般，这里我们获取到下载地址，使用 wget 下载，速度反而快。 1wget https://download.jetbrains.8686c.com/webide/PhpStorm-2019.1.2.tar.gz 下载完成后，正常解压，在 bin 目录下执行脚本即可。 webstorm同 phpstorm 的操作，只是下载地址不同罢了。 1wget https://download.jetbrains.8686c.com/webstorm/WebStorm-2019.1.3.tar.gz git emoji花里胡哨的提交你的 git 代码 github 地址 carloscuesta/gitmoji-cli 安装 1npm i -g gitmoji-cli 配置 emoji 展示方式 12345$ gitmoji -g? Enable automatic \"git add .\" No? Choose Issue Format github? Select how emojis should be used in commits 😄? Enable signed commits No 设定 alias 1alias gmc=\"gitmoji -c\"","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://rovast.github.io/tags/ubuntu/"}]},{"title":"使用 KCP 来加速流量","slug":"use-kcp","date":"2019-06-11T02:55:10.000Z","updated":"2021-01-12T05:29:42.077Z","comments":true,"path":"2019/06/11/use-kcp/","link":"","permalink":"https://rovast.github.io/2019/06/11/use-kcp/","excerpt":"","text":"前言使用 KCP 可以加速 SS 的流量，所以在安装 kcp 对应服务前，请先确定已经正常安装了 shadowsocket，可以参考 《科学上网之 Shadowsocks 安装及优化加速》 我们假设 ss 的对应配置如下 IP 1.1.1.1 port 12984 password 112233 加密方式 chacha20 安装 kcp server 端软件我们使用一键脚本安装 12345wget https://raw.githubusercontent.com/kuoruan/kcptun_installer/master/kcptun.shchmod +x ./kcptun.sh./kcptun.sh 基本上一路回车就好了，最后会输出一个成功的信息，记得保存为单独的文件，后面用到。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950恭喜! Kcptun 服务端安装成功。服务器IP: 1.1.1.1端口: 29900加速地址: 127.0.0.1:12984key: 111111crypt: aesmode: fastmtu: 1350sndwnd: 512rcvwnd: 512datashard: 10parityshard: 3dscp: 0nocomp: falsequiet: false当前安装的 Kcptun 版本为: 20190515请自行前往: https://github.com/xtaci/kcptun/releases/tag/v20190515手动下载客户端文件可使用的客户端配置文件为:&#123; &quot;localaddr&quot;: &quot;:12984&quot;, &quot;remoteaddr&quot;: &quot;1.1.1.1:29900&quot;, &quot;key&quot;: &quot;111111&quot;, &quot;crypt&quot;: &quot;aes&quot;, &quot;mode&quot;: &quot;fast&quot;, &quot;mtu&quot;: 1350, &quot;sndwnd&quot;: 512, &quot;rcvwnd&quot;: 512, &quot;datashard&quot;: 10, &quot;parityshard&quot;: 3, &quot;dscp&quot;: 0, &quot;nocomp&quot;: false, &quot;quiet&quot;: false&#125;手机端参数可以使用: key=111111;crypt=aes;mode=fast;mtu=1350;sndwnd=512;rcvwnd=512;datashard=10;parityshard=3;dscp=0Kcptun 安装目录: /usr/local/kcptun已将 Supervisor 加入开机自启,Kcptun 服务端会随 Supervisor 的启动而启动更多使用说明: ./kcptun.sh help如果这个脚本帮到了你，你可以请作者喝瓶可乐: https://blog.kuoruan.com/donate kcp 服务使用 supervisor 来管理，用于守护进程。安装完成后，可用的命令为 启动 kcptun supervisorctl start kcptun 重启 kcptun supervisorctl restart kcptun 关闭 kcptun supervisorctl stop kcptun 查看 kcptun 日志 ./kcptun.sh log 安装 kcptun 的客户端软件kcptun 支持丰富的客户端支持 Linux下载安装包https://github.com/xtaci/kcptun/releases 地址下载对应的 Linux 版本，解压后有可执行文件。 我下载的是 kcptun-linux-386-20190515.tar.gz 新建配置文件config.json，这个文件就是安装 kcptun 成功后的提示文件 1234567891011121314151617181920212223&#123; \"localaddr\": \"127.0.0.1:2080\", \"remoteaddr\": \"1.1.1.1:29900\", \"key\": \"111111\", \"crypt\": \"aes\", \"mode\": \"fast\", \"conn\": 1, \"autoexpire\": 60, \"mtu\": 1350, \"sndwnd\": 512, \"rcvwnd\": 512, \"datashard\": 70, \"parityshard\": 3, \"dscp\": 46, \"nocomp\": false, \"acknodelay\": false, \"nodelay\": 0, \"interval\": 40, \"resend\": 0, \"nc\": 0, \"sockbuf\": 4194304, \"keepalive\": 10&#125; 建立客户端服务执行以下指令建立链接，同时在服务器端，使用 ./kcptun.sh log 可以看到日志输出 1./client_linux_386 -c config.json --quiet 配置客户端 shadowsocket 服务器地址 127.0.0.1 服务器端口 2080 密钥 112233 本地地址 127.0.0.1 本地端口 1080 本地服务器类型 socket5 加密方式 chacha20 MacOSMacOS 的 shadowsockets-NG 软件的最新版已经内嵌了 kcptun 插件，比较简单 下载软件下载最新版的软件，在下面的链接中，下载 ShadowsocksX-NG.app.1.8.2.zip，解压后有个 app 文件，挪动到「应用程序」 https://github.com/shadowsocks/ShadowsocksX-NG/releases 配置正常配置 shadowsockets 的链接即可，需要配置插件和插件配置如下 服务器 1.1.1.1 端口 29900 加密方式 chacha20 密码 112233 插件 kcptun 配置 key=111111;crypt=aes;mode=fast;mtu=1350;sndwnd=512;rcvwnd=512;datashard=10;parityshard=3;dscp=0 Android下载客户端需要下载两个软件，小飞机和 kcptun shadowsocks-android https://github.com/shadowsocks/shadowsocks-android/releases 我的是 shadowsocks-arm64-v8a-4.8.0.apk kcptun android https://github.com/shadowsocks/kcptun-android/releases 安装完 kcptun 是没有图标的，这是 shadowsockets 的关联启动华为手机需要在手机管家中设置 kcptun 允许关联启动，不然会提示链接不上服务器 配置安卓小飞机的配置 服务器 1.1.1.1 远程端口 29900 密码 112233 加密方式 chacha20 插件 kcptun 配置 key=111111;crypt=aes;mode=fast;mtu=1350;sndwnd=512;rcvwnd=512;datashard=10;parityshard=3;dscp=0 参考文章 《一步一步教你用Kcptun给Shadowsocks加速！看YouTube1080P一点都不卡！》 《Shadowsocks-Android客户端上的KCP配置说明》 更新于：2021年01月12日13:28:49 更新内容：服务器配置 1、安装 SS加密算法组件 chacha20 12345678yum groupinstall \"Development Tools\"wget https://download.libsodium.org/libsodium/releases/LATEST.tar.gztar zxvf LATEST.tar.gz &amp;&amp; cd libsodium-stable./configure &amp;&amp; make -j4 &amp;&amp; make installecho /usr/local/lib &gt; /etc/ld.so.conf.d/usr_local_lib.confldconfig 2、安装 Server1234567# debainapt-get install python-pippip install shadowsocks# centosyum install python-setuptools &amp;&amp; easy_install pippip install shadowsocks 3、安装 kcptun1234567wget https://raw.githubusercontent.com/kuoruan/kcptun_installer/master/kcptun.shchmod +x ./kcptun.sh./kcptun.sh# 一路回车 4、配置文件修改/root/ss.json 123456789&#123; \"server\":\"0.0.0.0\", \"server_port\":12984, \"local_address\": \"127.0.0.1\", \"local_port\":1080, \"password\":\"9SehN7C3GQ9h9Cyt\", \"timeout\":300, \"method\":\"chacha20\"&#125; /usr/local/kcptun/server-config.json 12345678910111213141516&#123; \"listen\": \":29900\", \"target\": \"127.0.0.1:12984\", \"key\": \"111111\", \"crypt\": \"aes\", \"mode\": \"fast\", \"mtu\": 1350, \"sndwnd\": 4096, \"rcvwnd\": 4096, \"datashard\": 10, \"parityshard\": 3, \"dscp\": 0, \"nocomp\": false, \"quiet\": true, \"pprof\": false&#125; 5、启动增加开机自启动 /etc/supervisor/conf.d/ss.conf 12345678910[program:ssserver]user=rootdirectory=/rootcommand=/usr/bin/ssserver -c \"/root/ss.json\"process_name=%(program_name)sautostart=trueredirect_stderr=truestdout_logfile=/var/log/ss.logstdout_logfile_maxbytes=1MBstdout_logfile_backups=0 12345# start ssssserver -c /root/ss.json -d start# reload kcptun to apply new configurationsupervisorctl restart all","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[]},{"title":"RFC793 TCP 协议","slug":"rfc793-transmission-control-protocol","date":"2019-05-17T01:51:05.000Z","updated":"2020-11-28T08:49:18.081Z","comments":true,"path":"2019/05/17/rfc793-transmission-control-protocol/","link":"","permalink":"https://rovast.github.io/2019/05/17/rfc793-transmission-control-protocol/","excerpt":"","text":"PREFACE（引言） INTRODUCTION （简介） 1.1 Motivation （动机）1.2 Scope （范围）1.3 About This Document （关于此文档）1.4 Interfaces （接口）1.5 Operation （操作） PHILOSOPHY （设计理念） 2.1 Elements of the Internetwork System （网络系统要素）2.2 Model of Operation （操作模型）2.3 The Host Environment （HOST 环境）2.4 Interfaces （接口）2.5 Relation to Other Protocols （和其他协议的关系）2.6 Reliable Communication （可靠通信）2.7 Connection Establishment and Clearing （链接的建立和清除）2.8 Data Communication （数据通信）2.9 Precedence and Security （优先权和安全性）2.10 Robustness Principle （健壮性原则） FUNCTIONAL SPECIFICATION （功能规范） 3.1 Header Format （Header 格式）3.2 Terminology （专业术语）3.3 Sequence Numbers （序号说明）3.4 Establishing a connection （建立一个链接）3.5 Closing a Connection （断开一个链接）3.6 Precedence and Security （优先级和安全性）3.7 Data Communication （数据通信）3.8 Interfaces （接口）3.9 Event Processing （事件处理） GLOSSARY （术语表） REFERENCES （引用） 123456789101112131415 PREFACEThis document describes the DoD Standard Transmission Control Protocol(TCP). There have been nine earlier editions of the ARPA TCPspecification on which this standard is based, and the present textdraws heavily from them. There have been many contributors to this workboth in terms of concepts and in terms of text. This edition clarifiesseveral details and removes the end-of-letter buffer-size adjustments,and redescribes the letter mechanism as a push function. Jon Postel Editor INTRODUCTIONThe Transmission Control Protocol (TCP) is intended for use as a highlyreliable host-to-host protocol between hosts in packet-switched computercommunication networks, and in interconnected systems of such networks. 传输控制协议(TCP)的目的，是在 包交换计算机通信网络 和 此类网络的互连系统中，为主机间的通信提供可靠的协议。 This document describes the functions to be performed by theTransmission Control Protocol, the program that implements it, and itsinterface to programs or users that require its services. 本文档描述传输控制协议要执行的功能、实现该协议的程序、以及需要其服务的程序或用户的接口。 MotivationComputer communication systems are playing an increasingly importantrole in military, government, and civilian environments. Thisdocument focuses its attention primarily on military computercommunication requirements, especially robustness in the presence ofcommunication unreliability and availability in the presence ofcongestion, but many of these problems are found in the civilian andgovernment sector as well. 计算机通信系统在军事、政府和民用环境中发挥着越来越重要的作用。本文件主要关注军用计算机通信需求，特别是在通信不可靠和存在拥塞时的健壮性和可用性，但其中许多问题也存在于民用和政府部门。 As strategic and tactical computer communication networks aredeveloped and deployed, it is essential to provide means ofinterconnecting them and to provide standard interprocesscommunication protocols which can support a broad range ofapplications. In anticipation of the need for such standards, theDeputy Undersecretary of Defense for Research and Engineering hasdeclared the Transmission Control Protocol (TCP) described herein tobe a basis for DoD-wide inter-process communication protocolstandardization. 随着战略和战术计算机通信网络的发展和部署，提供相互连接的手段和支持广泛应用的标准进程间通信协议至关重要。考虑到需要这样的标准，负责研究和工程的国防部副部长声明了本文描述的传输控制协议(TCP)，这份协议将作为全局性进程间通信协议标准化的基础。 TCP is a connection-oriented, end-to-end reliable protocol designed tofit into a layered hierarchy of protocols which support multi-networkapplications. The TCP provides for reliable inter-processcommunication between pairs of processes in host computers attached todistinct but interconnected computer communication networks. Very fewassumptions are made as to the reliability of the communicationprotocols below the TCP layer. TCP assumes it can obtain a simple,potentially unreliable datagram service from the lower levelprotocols. In principle, the TCP should be able to operate above awide spectrum of communication systems ranging from hard-wiredconnections to packet-switched or circuit-switched networks. TCP 是一种面向连接的端到端可靠协议，它被设计成适合于支持多网络应用程序的分层协议层次结构。有一些计算机链接到不同的网络，但是这些网络之间是互通的。TCP 给这些计算机提供了可靠的内部进程通信。TCP 下层通信的可靠性是未知的，TCP 假定它可以提供一个简单的，可能不可靠的数据报文服务。原则上，TCP应该能够在从硬线连接到分组交换或电路交换网络的广泛通信系统频谱之上运行。（大概的意思就是 TCP 应该可以各种硬件之上运行，和运行无关）。 TCP is based on concepts first described by Cerf and Kahn in [1]. TheTCP fits into a layered protocol architecture just above a basicInternet Protocol [2] which provides a way for the TCP to send andreceive variable-length segments of information enclosed in internetdatagram “envelopes”. The internet datagram provides a means foraddressing source and destination TCPs in different networks. Theinternet protocol also deals with any fragmentation or reassembly ofthe TCP segments required to achieve transport and delivery throughmultiple networks and interconnecting gateways. The internet protocolalso carries information on the precedence, security classificationand compartmentation of the TCP segments, so this information can becommunicated end-to-end across multiple networks. TCP 是基于 Cerf 和 Kahn 在 [1] 中第一次描述的概念。TCP 协议是适合分层控制协议的架构的，就在基础的 IP 协议之上（IP 协议为 TCP 提供了一种发送和接收不定长数据的方式。）internet数据报提供了一种在不同网络中寻址源 tcp 和目标 tcp 的方法。","categories":[{"name":"翻译","slug":"翻译","permalink":"https://rovast.github.io/categories/翻译/"}],"tags":[{"name":"RFC","slug":"RFC","permalink":"https://rovast.github.io/tags/RFC/"}]},{"title":"php-class","slug":"php-class","date":"2019-05-03T08:28:51.000Z","updated":"2020-11-28T08:49:18.067Z","comments":true,"path":"2019/05/03/php-class/","link":"","permalink":"https://rovast.github.io/2019/05/03/php-class/","excerpt":"","text":"PHP 面向对象的类型 普通类 class 抽象类 abstract class 抽象类不能被实例化 抽象方法不能有具体实现 接口 interface 普通类继承接口，必须实现接口所有方法 接口类中定义的方法都是共有。同时，实现方也都是共有 特性 trait 如果有冲突，通过 instead of 定义优先级，或者使用 as 定义别名 也可以使用 as 修改访问级别 12345678910class A&#123; use TraitA &#123; function1 as private; &#125;; use TraitB &#123; TraitB-&gt;function1 as functionB; &#125;;&#125; final类 final 使用 final 修饰类或者方法，则类不能再被继承，方法不能再被覆盖 匿名类 new class{} 快速创建匿名类，不能有类名","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"php","slug":"php","permalink":"https://rovast.github.io/tags/php/"}]},{"title":"docker+gdb 调试 PHP 源码，看 strval 函数 C 实现","slug":"php-strval-in-c","date":"2019-04-18T10:49:43.000Z","updated":"2020-11-28T08:49:18.067Z","comments":true,"path":"2019/04/18/php-strval-in-c/","link":"","permalink":"https://rovast.github.io/2019/04/18/php-strval-in-c/","excerpt":"","text":"php strval 函数的作用很简单，就是你给他一个值，他给你返回字符串类型。 算是一个比较简单的函数了，我们来通过 gdb 来一探究竟。 通过本文，你可以窥探下 gdb 的简单使用 gdb gui 模式初探 看看平时写的 PHP 代码在 C 语言里的样子 对使用 gdb 调试 php 代码有个初步了解 对了，文末有一些截图，不要错过 采购食材 电脑一台 docker 和 docker-compose gdb 也好， PHP 也好，都打包成 docker 镜像啦，开袋即食，甚好。 备菜环节1、使用 docker 拉取环境12345678# 拉取准备好的环境git clone https://github.com/rovast/docker-examples.git# 进入项目cd docker-examples/gdb-php-src/# 启动，会经历一个漫长又不太漫长的等待，看你网速docker-compose up -d 关于容器内的环境，大家可以看看 dockerfile 其实很简单，就是基于 gcc 官方镜像构建，然后增加了 vim gdb，并且下载了 php7.0.0 的源码，按照 debug 参数进行编译 显示如下 12Creating network &quot;gdb-php-src_default&quot; with the default driverCreating gdb-php-src ... done 2、进入容器1234docker exec -it gdb-php-src bash### 显示下面的东西，表示你已经进入到容器内了 ####root@71a98d1bc1a6:/home# 我们看看容器内的环境（php 以及 gdb） 1234567891011121314151617181920212223242526### 我们在容器内看看环境root@71a98d1bc1a6:/home# lsphp-7.0.0 start.mdroot@71a98d1bc1a6:/home# gdb -vGNU gdb (Debian 7.12-6) 7.12.0.20161007-gitCopyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type \"show copying\"and \"show warranty\" for details.This GDB was configured as \"x86_64-linux-gnu\".Type \"show configuration\" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type \"help\".Type \"apropos word\" to search for commands related to \"word\".root@71a98d1bc1a6:/home# php -vPHP 7.0.0 (cli) (built: Apr 17 2019 13:33:30) ( NTS DEBUG )Copyright (c) 1997-2015 The PHP GroupZend Engine v3.0.0, Copyright (c) 1998-2015 Zend Technologiesroot@71a98d1bc1a6:/home# 开火（请在容器内操作）1、新建测试文件1root@71a98d1bc1a6:/home# vi test.php 输入以下内容123&lt;?phpstrval(1234); 这个文件干的事情就比较简单了，就是把 -1234[整形] 转换为 -1234[字符串] 2、开始调试，进入 gdb接下来车速较快，各位按步骤跟上 输入 gdb php，开始调试 1234567891011121314151617root@71a98d1bc1a6:/home# gdb phpGNU gdb (Debian 7.12-6) 7.12.0.20161007-gitCopyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type \"show copying\"and \"show warranty\" for details.This GDB was configured as \"x86_64-linux-gnu\".Type \"show configuration\" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type \"help\".Type \"apropos word\" to search for commands related to \"word\"...Reading symbols from php...done.(gdb) 3、打一些断点（敲命令时可以用 tab 补全）12345(gdb) b zend_long_to_strBreakpoint 1 at 0x810423: file /home/php-7.0.0/Zend/zend_operators.c, line 2743.(gdb) b zend_print_ulong_to_bufBreakpoint 2 at 0x5f387b: zend_print_ulong_to_buf. (13 locations)(gdb) 这里在关键函数 zend_long_to_str 和 zend_print_ulong_to_buf 打了断点。 b 在 gdb 中是 breakpoint 缩写，后面可以加函数名，或者当前文件的行号都是可以的 4、执行，查看断点值123456789101112131415161718(gdb) r test.php # 执行我们刚才的那个 PHP 文件Starting program: /usr/local/bin/php test.php[Thread debugging using libthread_db enabled]Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".warning: File \"/usr/local/lib64/libstdc++.so.6.0.25-gdb.py\" auto-loading has been declined by your `auto-load safe-path' set to \"$debugdir:$datadir/auto-load\".To enable execution of this file add add-auto-load-safe-path /usr/local/lib64/libstdc++.so.6.0.25-gdb.pyline to your configuration file \"/root/.gdbinit\".To completely disable this security protection add set auto-load safe-path /line to your configuration file \"/root/.gdbinit\".For more information about this security protection see the\"Auto-loading safe path\" section in the GDB manual. E.g., run from the shell: info \"(gdb)Auto-loading safe path\"Breakpoint 1, zend_long_to_str (num=-1234) at /home/php-7.0.0/Zend/zend_operators.c:27432743 char *res = zend_print_long_to_buf(buf + sizeof(buf) - 1, num);(gdb) 看的好像不明了嘛， ctrl + x 后再按 a 进入 gui 模式看看 123456789101112131415161718192021222324252627282930313233 ┌──/home/php-7.0.0/Zend/zend_operators.c────────────────────────────────────────────────────────────────────────────────────────────────┐ │2731 ZEND_API void ZEND_FASTCALL zend_locale_sprintf_double(zval *op ZEND_FILE_LINE_DC) /* &#123;&#123;&#123; */ │ │2732 &#123; │ │2733 zend_string *str; │ │2734 │ │2735 str = zend_strpprintf(0, \"%.*G\", (int) EG(precision), (double)Z_DVAL_P(op)); │ │2736 ZVAL_NEW_STR(op, str); │ │2737 &#125; │ │2738 /* &#125;&#125;&#125; */ │ │2739 │ │2740 ZEND_API zend_string* ZEND_FASTCALL zend_long_to_str(zend_long num) /* &#123;&#123;&#123; */ │ │2741 &#123; │ │2742 char buf[MAX_LENGTH_OF_LONG + 1]; │B+&gt;│2743 char *res = zend_print_long_to_buf(buf + sizeof(buf) - 1, num); │ │2744 return zend_string_init(res, buf + sizeof(buf) - 1 - res, 0); │ │2745 &#125; │ │2746 /* &#125;&#125;&#125; */ │ │2747 │ │2748 ZEND_API zend_uchar ZEND_FASTCALL is_numeric_str_function(const zend_string *str, zend_long *lval, double *dval) /* &#123;&#123;&#123; */ &#123; │ │2749 return is_numeric_string_ex(ZSTR_VAL(str), ZSTR_LEN(str), lval, dval, -1, NULL); │ │2750 &#125; │ │2751 /* &#125;&#125;&#125; */ │ │2752 │ │2753 ZEND_API zend_uchar ZEND_FASTCALL _is_numeric_string_ex(const char *str, size_t length, zend_long *lval, double *dval, int allo│ │2754 &#123; │ │2755 const char *ptr; │ │2756 int digits = 0, dp_or_e = 0; │ │2757 double local_dval = 0.0; │ └───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘multi-thre Thread 0x7ffff7fe37 In: zend_long_to_str L2743 PC: 0x810423(gdb) 有点意思了，函数在 2743 行断住了，我们来看看 num 的值 123(gdb) p num$1 = -1234(gdb) 对嘛，这个就是我们要处理的值，我们全速运行到 zend_print_long_to_buf 里看看 12(gdb) cContinuing. 显示如下 12345678910111213141516171819202122232425262728293031(gdb) c ┌──/home/php-7.0.0/Zend/zend_operators.h────────────────────────────────────────────────────────────────────────────────────────────────┐ │781 else \\ │ │782 ZEND_TRY_BINARY_OP2_OBJECT_OPERATION(opcode) │ │783 │ │784 #define ZEND_TRY_UNARY_OBJECT_OPERATION(opcode) \\ │ │785 if (UNEXPECTED(Z_TYPE_P(op1) == IS_OBJECT) \\ │ │786 &amp;&amp; UNEXPECTED(Z_OBJ_HANDLER_P(op1, do_operation)) \\ │ │787 &amp;&amp; EXPECTED(SUCCESS == Z_OBJ_HANDLER_P(op1, do_operation)(opcode, result, op1, NULL))) &#123; \\ │ │788 return SUCCESS; \\ │ │789 &#125; │ │790 │ │791 /* buf points to the END of the buffer */ │ │792 static zend_always_inline char *zend_print_ulong_to_buf(char *buf, zend_ulong num) &#123; │B+&gt;│793 *buf = '\\0'; │ │794 do &#123; │ │795 *--buf = (char) (num % 10) + '0'; │ │796 num /= 10; │ │797 &#125; while (num &gt; 0); │ │798 return buf; │ │799 &#125; │ │800 │ │801 /* buf points to the END of the buffer */ │ │802 static zend_always_inline char *zend_print_long_to_buf(char *buf, zend_long num) &#123; │ │803 if (num &lt; 0) &#123; │ │804 char *result = zend_print_ulong_to_buf(buf, ~((zend_ulong) num) + 1); │ │805 *--result = '-'; │ │806 return result; │ │807 &#125; else &#123; │ └───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘multi-thre Thread 0x7ffff7fe37 In: zend_print_ulong_to_buf L793 PC: 0x8041fd 接下来，我们来进行一些单步调试，看看内存里的值 1234567891011121314151617Breakpoint 1, zend_long_to_str (num=-1234) at /home/php-7.0.0/Zend/zend_operators.c:2743(gdb) c #-------------&gt; 表示继续执行Continuing.Breakpoint 2, zend_print_ulong_to_buf (buf=0x7fffffffafe4 \"\", num=1234) at /home/php-7.0.0/Zend/zend_operators.h:793(gdb) b 798 #-------------&gt; 798行打个断点Breakpoint 6 at 0x5f38e2: /home/php-7.0.0/Zend/zend_operators.h:798. (13 locations)(gdb) c Continuing.Breakpoint 6, zend_print_ulong_to_buf (buf=0x7fffffffafe0 \"1234\", num=0) at /home/php-7.0.0/Zend/zend_operators.h:798(gdb) p buf #-------------&gt; 查看 buf 的值$2 = 0x7fffffffafe0 \"1234\"(gdb) x/10c buf #-------------&gt; 查看 buf 位置开始，连续 10 个以 char 为单位的内存值0x7fffffffafe0: 49 '1' 50 '2' 51 '3' 52 '4' 0 '\\000' 0 '\\000' 0 '\\000' 0 '\\000'0x7fffffffafe8: 0 '\\000' 65 'A'(gdb) 我们看到，函数返回的 buf 是字符串类型的 ‘1234’ 我们看看函数 zend_print_ulong_to_buf，其实就是从高位到低位，按个取模（除以10，取整数部分），然后塞到 buf 缓冲区。 比较有意思的是，buf 初始化的时候指向的是缓冲区的末尾，所以填充的时候高位在最后，然后逐步往前填充低位。 最后结束的时候，buf 就是我们需要的字符串类容了 消化其实，本文就是使用 gdb 调试了 PHP 代码，仅此而已。 更多的是给大家提供了一个直接上手玩玩的机会，你所需要的只是个 docker，然后动动手调试，很有意思。 动手试试吧，甚至，去看 C 源码吧！ 附录放图的时间到了","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://rovast.github.io/tags/PHP/"}]},{"title":"【转】写入时复制","slug":"Copy-on-write","date":"2019-04-08T07:29:17.000Z","updated":"2020-11-28T08:49:18.042Z","comments":true,"path":"2019/04/08/Copy-on-write/","link":"","permalink":"https://rovast.github.io/2019/04/08/Copy-on-write/","excerpt":"","text":"写入时复制（英语：Copy-on-write，简称COW）是一种计算机程式设计领域的优化策略。其核心思想是，如果有多个呼叫者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同取得相同的指标指向相同的资源，直到某个呼叫者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该呼叫者，而其他呼叫者所见到的最初的资源仍然保持不变。这过程对其他的呼叫者都是透明的（transparently）。此作法主要的优点是如果呼叫者没有修改该资源，就不会有副本（private copy）被建立，因此多个呼叫者只是读取操作时可以共享同一份资源。 应用虚拟内存管理中的写时复制一般把这种被共享访问的页面标记为只读。当一个task试图向内存中写入数据时，内存管理单元（MMU）抛出一个异常，内核处理该异常时为该task分配一份物理内存并复制数据到此内存，重新向MMU发出执行该task的写操作。 数据存储中的写时复制Linux等的文件管理系统使用了写时复制策略。 数据库服务器也一般采用了写时复制策略，为用户提供一份snapshot。 软件应用中的写时复制C++标准程序库中的std::string)类，在C++98/C++03标准中是允许写时复制策略。但在C++11标准中为了提高并行性取消了这一策略。[1] GCC从版本5开始，std::string不再采用COW策略。 参考文献 ^ Concurrency Modifications to Basic String. Open Standards. [2015-02-13].","categories":[{"name":"wiki","slug":"wiki","permalink":"https://rovast.github.io/categories/wiki/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://rovast.github.io/tags/wiki/"}]},{"title":"【转】 字节顺序","slug":"Endianness","date":"2019-04-08T07:21:48.000Z","updated":"2020-11-28T08:49:18.042Z","comments":true,"path":"2019/04/08/Endianness/","link":"","permalink":"https://rovast.github.io/2019/04/08/Endianness/","excerpt":"","text":"原文地址： https://www.wikiwand.com/zh-hans/%E5%AD%97%E8%8A%82%E5%BA%8F – 字节顺序 字节最低有效位存储器 字节顺序，又称端序或尾序（英语：Endianness），在计算机科学领域中，指存储器中或在数字通信链路中，组成多字节的字)的字节的排列顺序。 在几乎所有的机器上，多字节对象都被存储为连续的字节序列。例如在C语言中，一个类型为int的变量x地址为0x100，那么其对应地址表达式&amp;x的值为0x100。且x的四个字节将被存储在存储器的0x100, 0x101, 0x102, 0x103位置。[1] 字节的排列方式有两个通用规则。例如，一个多位的整数，按照存储地址从低到高排序的字节中，如果该整数的最低有效字节（类似于最低有效位）在最高有效字节的前面，则称小端序；反之则称大端序。在网络应用中，字节序是一个必须被考虑的因素，因为不同机器类型可能采用不同标准的字节序，所以均按照网络标准转化。 例如假设上述变量x类型为int，位于地址0x100处，它的十六进制为0x01234567，地址范围为0x100~0x103字节，其内部排列顺序依赖于机器的类型。大端法从首位开始将是：0x100: 01, 0x101: 23,..。而小端法将是：0x100: 67, 0x101: 45,..。 端（endian）的起源“endian”一词来源于十八世纪爱尔兰作家乔纳森·斯威夫特（Jonathan Swift）的小说《格列佛游记》（Gulliver’s Travels）。小说中，小人国为水煮蛋该从大的一端（Big-End）剥开还是小的一端（Little-End）剥开而争论，争论的双方分别被称为“大端派”和“小端派”。以下是1726年关于大小端之争历史的描述： “ 我下面要告诉你的是，Lilliput和Blefuscu这两大强国在过去36个月里一直在苦战。战争开始是由于以下的原因：我们大家都认为，吃鸡蛋前，原始的方法是打破鸡蛋较大的一端，可是当今皇帝的祖父小时候吃鸡蛋，一次按古法打鸡蛋时碰巧将一个手指弄破了。因此他的父亲，当时的皇帝，就下了一道敕令，命令全体臣民吃鸡蛋时打破鸡蛋较小的一端，违令者重罚。老百姓们对这项命令极其反感。历史告诉我们，由此曾经发生过6次叛乱，其中一个皇帝送了命，另一个丢了王位。这些叛乱大多都是由Blefuscu的国王大臣们煽动起来的。叛乱平息后，流亡的人总是逃到那个帝国去寻求避难。据估计，先后几次有11000人情愿受死也不肯去打破鸡蛋较小的一端。关于这一争端，曾出版过几百本大部著作，不过大端派的书一直是受禁的，法律也规定该派任何人不得做官。” ” —— 《格列夫游记》 第一卷第4章 蒋剑锋（译） 1980年，丹尼·科恩（Danny Cohen），一位网络协议的早期开发者，在其著名的论文“On Holy Wars and a Plea for Peace“中，为平息一场关于字节该以什么样的顺序传送的争论，而第一次引用了该词。[2] 字节顺序在哪种字节顺序更合适的问题上，人们表现得非常情绪化，实际上，就像鸡蛋的问题一样，没有技术上的原因来选择字节顺序规则，因此，争论沦为关于社会政治问题的争论，只要选择了一种规则并且始终如一地坚持，其实对于哪种字节排序的选择是任意的。 对于单一的字节（a byte），大部分处理器以相同的顺序处理位元（bit），因此单字节的存放方法和传输方式一般相同。 对于多字节数据，如整数（32位机中一般占4字节），在不同的处理器的存放方式主要有两种，以内存中0x0A0B0C0D的存放方式为例，分别有以下几种方式： 大端序大端序（英：big-endian）或称大尾序。 数据以8bit为单位: 地址增长方向 → ... 0x0A 0x0B 0x0C 0x0D ... 示例中，最高位字节是0x0A 存储在最低的内存地址处。下一个字节0x0B存在后面的地址处。正类似于十六进制字节从左到右的阅读顺序。 数据以16bit为单位: 地址增长方向 → ... 0x0A0B 0x0C0D ... 最高的16bit单元0x0A0B存储在低位。 小端序小端序（英：little-endian）或称小尾序。 数据以8bit为单位: 地址增长方向 → ... 0x0D 0x0C 0x0B 0x0A ... 最低位字节是0x0D 存储在最低的内存地址处。后面字节依次存在后面的地址处。 数据以16bit为单位: 地址增长方向 → ... 0x0C0D 0x0A0B ... 最低的16bit单元0x0C0D存储在低位。 更改地址的增长方向: 当更改地址的增长方向，使之由右至左时，表格更具有可阅读性。 ← 地址增长方向 ... 0x0A 0x0B 0x0C 0x0D ... 最低有效位（LSB）是0x0D 存储在最低的内存地址处。后面字节依次存在后面的地址处。 ← 地址增长方向 ... 0x0A0B 0x0C0D ... 最低的16bit单元0x0C0D存储在低位。 混合序混合序（英：middle-endian）具有更复杂的顺序。以PDP-11为例，0x0A0B0C0D被存储为： 32bit在PDP-11的存储方式 地址增长方向 → ... 0x0B 0x0A 0x0D 0x0C ... 可以看作高16bit和低16bit以大端序存储，但16bit内部以小端存储。 处理器体系 x86、MOS Technology 6502、Z80、VAX、PDP-11等处理器为小端序； Motorola 6800、Motorola 68000、PowerPC 970、System/370、SPARC（除V9外）等处理器为大端序； ARM、PowerPC（除PowerPC 970外）、DEC Alpha、SPARC V9、MIPS、PA-RISC及IA64的字节序是可配置的。 网络序网络传输一般采用大端序，也被称之为网络字节序，或网络序。IP协议中定义大端序为网络字节序。 Berkeley套接字定义了一组转换函数，用于16和32bit整数在网络序和本机字节序之间的转换。htonl，htons用于本机序转换到网络序；ntohl，ntohs用于网络序转换到本机序。 位序一般用于描述串行设备的传输顺序。网络协议中只有数据链路层的底端会涉及到。 小端序（先传低位）的串行协议 RS-232 RS-422 RS-485 USB 以太网（虽然高字节先传，但每一字节内低位先传） 大端序（先传高位）的串行协议 I2C协议 SPI协议 摩尔斯电码 参见 最高有效位 最低有效位 网络协议 外部链接 Endian的由来 White Paper: Endianness or Where is Byte 0?（英文） Byte Ordering PPC（英文） The Layout of Data in Memory（英文） Writing endian-independent code in C（英文） How to convert an integer to little endian or big endian（英文） Understanding big and little endian byte order（英文） Mandatory reading: ON HOLY WARS AND A PLEA FOR PEACE（英文） 参考 ^ 《深入理解计算机系统》 第2章 信息的表示和处理 P26. ^ 《深入理解计算机系统》 第2章 信息的表示和处理 P27.","categories":[{"name":"wiki","slug":"wiki","permalink":"https://rovast.github.io/categories/wiki/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://rovast.github.io/tags/wiki/"}]},{"title":"virtualbox 在 ubuntu 中不能正常启动的解决办法","slug":"virtualbox-problems-in-ubuntu","date":"2019-04-04T01:53:06.000Z","updated":"2020-11-28T08:49:18.090Z","comments":true,"path":"2019/04/04/virtualbox-problems-in-ubuntu/","link":"","permalink":"https://rovast.github.io/2019/04/04/virtualbox-problems-in-ubuntu/","excerpt":"","text":"问题描述： vboxdrv.sh: failed: modprobe vboxdrv failed. Please use ‘dmesg’ to find out why 解决步骤1. 安装 virtualbox 2. 设置 RSA123456$ sudo -i# mkdir /root/module-signing# cd /root/module-signing# openssl req -new -x509 -newkey rsa:2048 -keyout MOK.priv -outform DER -out MOK.der -nodes -days 36500 -subj \"/CN=YOUR_NAME/\"[...]# chmod 600 MOK.priv 3. 导入啥啥啥123# mokutil --import /root/module-signing/MOK.derinput password:input password again: 4.重启机器。注意，注意观测开机时的提示，需要 press any key。然后选择 enable ...，输入上一步的密码即可 5. 新建一个脚本文件 /root/module-signing/sign-vbox-modules 12345678#!/bin/bashfor modfile in $(dirname $(modinfo -n vboxdrv))/*.ko; do echo \"Signing $modfile\" /usr/src/linux-headers-$(uname -r)/scripts/sign-file sha256 \\ /root/module-signing/MOK.priv \\ /root/module-signing/MOK.der \"$modfile\"done 1# chmod 700 /root/module-signing/sign-vbox-modules 6. 启动啥啥啥1# modprobe vboxdrv 7. 如果每次内核更新，记得再执行 6 即可 2019年07月03日 补充如果执行下述指令报错1# modprobe vboxdrv 尝试以下方案 12sudo apt updatesudo apt install --reinstall linux-headers-$(uname -r) virtualbox-dkms dkms 1sudo modprobe vboxdrv 应该就可以了。 And if it doesn’t work you must disable Secure Boot in your BIOS/UEFI settings because Secure Boot prevents unsigned modules from being loaded. 参考文章： https://askubuntu.com/questions/900118/vboxdrv-sh-failed-modprobe-vboxdrv-failed-please-use-dmesg-to-find-out-why https://askubuntu.com/questions/920689/how-to-fix-modprobe-vboxdrv-error-in-virtualbox","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[]},{"title":"记录一次 docker 部署前端应用 npm 的问题","slug":"docker-npm-development","date":"2019-03-12T05:12:00.000Z","updated":"2020-11-28T08:49:18.050Z","comments":true,"path":"2019/03/12/docker-npm-development/","link":"","permalink":"https://rovast.github.io/2019/03/12/docker-npm-development/","excerpt":"","text":"最近在部署一个较为复杂的 web 应用，其中涉及到 mongodb redis php node cron。为了简化部署，想到了使用 docker 部署。 使用 node 时，可以使用 node 的官方 image。 其 docker-compose.yaml 可以如下配置 123456789101112version: \"2\"services: node-build: image: \"node:8\" container_name: \"test-node\" working_dir: /home/node/app environment: - NODE_ENV=production volumes: - ./:/home/node/app command: &gt; bash -c \"npm install &amp;&amp; npm run build\" 发现，安装好了之后，不能执行 build。是因为 build 中引入了 webpack，而 webpack 是在 devDependencies 中定义的。 比较奇怪的是，在 自己的开发机 上是可以直接 npm install 安装 webpack，在 docker 容器中不可以。 初步怀疑是 images 搭载的操作系统问题。最后换了个镜像，依然不行。 最后发现，是 npm config 的问题。 执行1234567➜ ~ npm config ls -l | grep prohttps-proxy = nullnoproxy = nullproduction = falseprogress = trueproxy = nullsave-prod = false 我们看到 production=false，在这种模式下，npm install 就会安装 devDependencies ，而 docker 容器中执行 npm config ls -l | grep pro后发现， production=true。这就是问题所在。 更新 docker-compose.yaml 123456789101112version: \"2\"services: node-build: image: \"node:8\" container_name: \"test-node\" working_dir: /home/node/app environment: - NODE_ENV=development volumes: - ./:/home/node/app command: &gt; bash -c \"npm install &amp;&amp; npm run build\" 修改 NODE_ENV 为 development 即可。 虽然看起来是很小的问题，确着实花了好长时间去排错调试。特此记录！ 参考资料： npm install won’t install devDependencies Docker Official Images","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/categories/Linux/"}],"tags":[{"name":"node","slug":"node","permalink":"https://rovast.github.io/tags/node/"}]},{"title":"Linux cron 避坑指南","slug":"linux-cron-with-flock","date":"2019-03-11T01:22:57.000Z","updated":"2020-11-28T08:49:18.065Z","comments":true,"path":"2019/03/11/linux-cron-with-flock/","link":"","permalink":"https://rovast.github.io/2019/03/11/linux-cron-with-flock/","excerpt":"","text":"场景好多系统中会用到邮件系统，我们假设有一个 PHP 脚本用来发送邮件。使用 Linux cron 每分钟执行一次 我们暂时不引入队列系统，其实使用队列处理此方式更优。 我们得到下面的基本配置 1* * * * * php /home/app/email.php 问题分析和解决如果这个邮件服务出现异常，进程僵死怎么办？假设由于未知因素， email.php 脚本一直执行，没有退出。极端的情况，进入一个 while 死循环。 这下倒好，原来说好的一分钟执行一次，现在一直死这边了，后面的脚本也不能跑了 解决办法： 使用 timeout，假设我们设定每个脚本最多执行时间位 200秒，超过 200秒 就自动死掉。1* * * * * timeout 200 php /home/app/email.php 如果这个脚本执行时间超过 60秒，下一分钟又会执行 php email.php，如果避免重复执行？这样会出现，有两个进程同时在执行 php email.php，那会不会出现同一个任务被执行了两次？ 解决办法： 使用 flock 进行互斥控制 123456789101112131415161718192021用法： flock [选项] &lt;文件|目录&gt; &lt;命令&gt; [&lt;参数&gt;...] flock [选项] &lt;文件|目录&gt; -c &lt;命令&gt; flock [选项] &lt;文件描述符号码&gt;通过 shell 脚本管理文件锁。选项： -s, --shared 获取共享锁 -x, --exclusive 获取排他锁(默认) -u, --unlock 移除锁 -n, --nonblock 失败而非等待 -w, --timeout &lt;秒&gt; 等待限定的时间 -E, --conflict-exit-code &lt;数字&gt; 冲突或超时后的退出代码 -o, --close 运行命令前关闭文件描述符 -c, --command &lt;命令&gt; 通过 shell 运行单个命令字符串 -F, --no-fork 执行命令时不 fork --verbose 增加详尽程度 -h, --help display this help -V, --version display version 我们用到其中的排他设置 1* * * * * flock -xn /tmp/test.lock -c \"timeout 200 php /home/app/email.php\" 记录好日志定时任务可能要记录日志呀，不然后期怎么排查 1* * * * * flock -xn /tmp/test.lock -c \"timeout 200 php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1\" 总结1* * * * * flock -xn /tmp/test.lock -c \"timeout 200 php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1\" 番外篇 频率提升我觉得一分钟一次频率太低，想 10s 执行一次怎么办？ 123456* * * * * php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1* * * * * ( sleep 10 ; php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1 )* * * * * ( sleep 20 ; php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1 )* * * * * ( sleep 30 ; php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1 )* * * * * ( sleep 40 ; php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1 )* * * * * ( sleep 50 ; php /home/app/email.php &gt;&gt; /home/log/test.log 2&gt;&amp;1 ) 番外篇 flock 测试准备一个 php 脚本 /home/rovast/Code/flock/test.php1234567&lt;?php$i = 10000;while ($i &gt; 0) &#123; echo --$i . \\PHP_EOL; sleep(1);&#125; 执行1flock -xn /tmp/mytest.lock -c \"timeout 30 php /home/rovast/Code/flock/test.php\" 我们看到终端不停输出数值 123456789109999999899979996999599949993999299919990 我们再打开另外一个终端，执行 1flock -xn /tmp/mytest.lock -c \"timeout 30 php /home/rovast/Code/flock/test.php\" 我们发现： 第二次执行的没有输出（因为 flock 互斥） 第一个执行的，30秒后自动关闭进程（因为 timeout 30）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/tags/Linux/"}]},{"title":"vue组件中实现双向绑定","slug":"bind-value-in-vue-components","date":"2019-02-28T14:44:25.000Z","updated":"2020-11-28T08:49:18.044Z","comments":true,"path":"2019/02/28/bind-value-in-vue-components/","link":"","permalink":"https://rovast.github.io/2019/02/28/bind-value-in-vue-components/","excerpt":"","text":"背景在一些项目中，需要用到组件数据的双向绑定，即父子组件共享变量，一方改动另一方联动。 补充 2019年07月09日 根据之前用的方法，在部分环境中使用失效，参考 浅析Vue自定义组件的v-model 用了另外一种方式实现。虽然这样确实可以实现了，但是在一些原理上还是不太明白，有时间去看看源码吧。 SyncValue component 定义 12345678910111213141516&lt;template&gt; &lt;div&gt; &lt;input type=&quot;text&quot; :value=&quot;value&quot; @input=&quot;handleChange&quot;&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; props:[&apos;value&apos;], methods:&#123; handleChange(event) &#123; this.$emit(&apos;input&apos;, event.target.value); &#125; &#125; &#125;&lt;/script&gt; 组件调用方 123456789101112131415161718192021&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;SyncValue v-model=&quot;model&quot;&gt;&lt;/SyncValue&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import SyncValue from &apos;./components/SyncValue&apos;export default &#123; name: &apos;app&apos;, components: &#123; SyncValue &#125;, data() &#123; return &#123; model: &apos;123&apos; &#125; &#125;&#125;&lt;/script&gt; 使用 model 来实现双向绑定举例： 设计一个编辑器组件 editor，一般父组件调用时赋值给组件，当组件中内容变化时，父组件的变量也要变化。 参考 vue 自定义组件 v-model双向绑定、 父子组件同步通信的多种写法，得到解决办法。 我们使用文章的方案二，通过 v-model 来实现。 v-model父组件12345678910111213&lt;div&gt; &lt;editor v-model=\"content\"&gt;&lt;/editor&gt;&lt;/div&gt;&lt;script&gt;export default &#123; data() &#123; return &#123; content: '默认值' &#125; &#125;&#125;&lt;/script&gt; edtior component1234567891011121314151617181920212223&lt;div&gt; &#123;&#123;content&#125;&#125;&lt;/div&gt;&lt;script&gt;export default &#123; // 使用 model，定义好 prop 和 event 事件 model: &#123; prop: 'content', event: 'change' &#125;, props: &#123; content: &#123; type: String, default: '', required: false &#125; &#125; // 经过一系列处理 this.$emit('change', this.content)&#125;&lt;/script&gt;","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://rovast.github.io/tags/vue/"}]},{"title":"visudo 设置无需密码","slug":"linux-nopassword","date":"2019-02-28T02:04:19.000Z","updated":"2020-11-28T08:49:18.065Z","comments":true,"path":"2019/02/28/linux-nopassword/","link":"","permalink":"https://rovast.github.io/2019/02/28/linux-nopassword/","excerpt":"","text":"1234sudo visudo###luohao ALL=NOPASSWD: /usr/bin/supervisorctl, /bin/chmod","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/tags/Linux/"}]},{"title":"ubuntu 服务器 php 环境简单搭建","slug":"ubuntu-php-server-init","date":"2019-02-24T10:29:35.000Z","updated":"2020-11-28T08:49:18.085Z","comments":true,"path":"2019/02/24/ubuntu-php-server-init/","link":"","permalink":"https://rovast.github.io/2019/02/24/ubuntu-php-server-init/","excerpt":"","text":"中文语言调教安装中文支持，避免一些语言相关的坑 12345678sudo apt-get install language-pack-zh-hanssudo vim /etc/default/locale# vim /etc/default/locale 输入以下内容LANG=\"en_US.UTF-8\"LANGUAGE=\"zh_CN.utf8\"LC_ALL=\"zh_CN.utf8\" 安装 PHP此处安装的是 PHP 7.2，简单起见，我们直接使用现成的 package（当然了，你也可以使用源码编译）。 12345678910# 安装了此软件才能使用 PPA 呀sudo apt-get install -y software-properties-common# 安装 PPAsudo add-apt-repository ppa:ondrej/phpsudo apt-get update# 安装 PHP 7.2，如果需要额外的拓展，可以后期再安装sudo apt-get install php7.2 php 调优我们即将使用 nginx 配合 php-fpm 使用，所以配置文件路径为 /etc/php/7.2/fpm/php.ini 修改一个容易导致内存溢出的问题php.ini修改 pcre.recursion_limit=5000 其他调整123max_input_vars = 20000post_max_size = 50M 安装 fpm1sudo apt-get install php7.2-fpm php-fpm 调优修改 /etc/php/7.1/fpm/php-fpm.conf 12emergency_restart_threshold = 10 emergency_restart_interval = 1m 修改 PHP-FPM /etc/php/7.2/fpm/pool.d/www.conf 12345678910listen = 127.0.0.1:9000 listen.allowed_clients = 127.0.0.1 pm.max_children = 51 pm.start_servers = 3 pm.min_spare_servers = 2 pm.max_spare_servers = 4 pm.max_requests = 1000slowlog = /var/log/$pool.log.slow request_slowlog_timeout = 5s 安装 nginxsudo apt-get install nginx PHP7.2 拓展1sudo apt-get install php7.2-mbstring php7.2-xml php7.2-intl","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/tags/Linux/"}]},{"title":"源码编译安装PHP","slug":"build-php","date":"2019-01-15T02:13:33.000Z","updated":"2020-12-27T03:36:16.316Z","comments":true,"path":"2019/01/15/build-php/","link":"","permalink":"https://rovast.github.io/2019/01/15/build-php/","excerpt":"","text":"查看可用的参数./configure –help 编译安装MacOS 123456789./configure --enable-fpm --with-openssl=/usr/local/Cellar/openssl@1.1/1.1.1i/ \\--enable-bcmath --with-curl --enable-exif --with-mysqli --with-pdo-mysql \\--enable-zip --with-zlib=/usr/local/Cellar/zlib/1.2.11/ --enable-intl --enable-pcntl --enable-mbstring --enable-soap \\--with-icu-dir=/usr/local/Cellar/icu4c/67.1 \\--with-iconv=/usr/local/Cellar/libiconv/1.16 \\--with-libxml-dir=/usr/local/Cellar/libxml2/2.9.10_2makesudo make install ./configure –enable-debug 如果需要 debug 版本的 Linux 12345./configure --enable-fpm --with-openssl \\--enable-bcmath --with-curl --enable-exif --with-mysqli --with-pdo-mysql \\--enable-zip --with-zlib --enable-intl --enable-pcntl --enable-mbstring --enable-soapmakesudo make install 配置文件123456# /usr/local/etc/sudo cp php-fpm.conf.default php-fpm.conf# /usr/local/etc/php-fpm.dsudo cp www.conf.default www.conf 修改 php-fpm.conf 的最后一行1include=/usr/local/etc/php-fpm.d/*.conf 部分问题 Unable to detect ICU prefix or no failed. Please verify ICU install prefix 1./configure --with-icu-dir=/usr/local/Cellar/icu4c/63.1 php.ini12345678extension=mongodb.soextension=swoole.soextension=yaf.sozend_extension=xdebug.soxdebug.remote_enable = 1xdebug.remote_autostart = 1xdebug.remote_port = 9001","categories":[],"tags":[]},{"title":"【转】为什么星巴克的员工都不太热情？背后这4点值得深思","slug":"thinking-in-starbucks","date":"2019-01-12T13:25:07.000Z","updated":"2020-11-28T08:49:18.085Z","comments":true,"path":"2019/01/12/thinking-in-starbucks/","link":"","permalink":"https://rovast.github.io/2019/01/12/thinking-in-starbucks/","excerpt":"","text":"原文地址：https://mp.weixin.qq.com/s/_IZjTugVB6SjHizuVaHi5w 原文标题：为什么星巴克的员工都不太热情？背后这4点值得深思 原文公众号：人生格局 我是星巴克的常客，经常观察他们的日常运营。我发现实地观察，比读100本管理书籍都管用。列四条有意思的现象，和你分享一下。 开始前，先问四个问题，看你是否知道？ 1. 为什么星巴克的排队模式和别家不一样，顾客都被要求横向排队，而非竖向？ 2. 为什么星巴克陈列柜里的“x云矿泉水”，几乎卖不出去，还天天摆着？ 3. 为什么你什么都不买，干坐在星巴克，工作人员也不会赶你？ 4. 为什么星巴克的工作人员没那么热情？ - 01 - 降低焦虑的方法，是让对方看到过程 星巴克设计横向排队有什么好处呢？ 显然，最大的一个好处是，让所有顾客都是面对工作区。 这样，他们能看到工作人员的忙忙碌碌，一杯又一杯调制而出的咖啡，意味着自己那杯也很快来临，焦虑感也随之降低。 反之，你回忆一下竖形排队时的心情，大家都会焦急的望向柜台，心理不停的嘀咕，怎么这么慢？ 这样的情景在生活中很常见，塞车时，你会忍不住把头伸出窗外，想一探究竟。但是，就算你看到塞车的原因，难道路面情况会好一点吗？当然不能，但你心里会好受些。 再比如，曾有个实验，电梯里不显示楼层的变化，里面的人焦虑感立刻上升了很多。所以，你应该明白，为什么大家在电梯里，都统一盯着门上变化的楼层显示，那就是在消除焦虑感。 人是唯一拥有控制感的动物，控制感的获得，不仅来源于对事件进程的显性干预，也来源于对事件的目所能及。 是的，当你在观察一件事物时，就会因此获得了一种控制感。 这在现实中有很多可应用的场景。 如果你是个创业者，就可以考虑如何把内部运作的流程向客户展示，这会极大的提高客户的信任感和参与度。 比如，很多饭店的后厨是全透明的，就是让顾客看到整个过程；再比如，为什么“得到”会把内部例会内容公开，让所有用户看到？就是为了增加用户的参与度嘛。 如果你是个职场人，领导给你布置个工作，你就一定要记得在过程中时时汇报，不要总想着把事搞完后，有了结果，再给领导一个surprise。 领导不需要惊喜，只需要控制。 - 02 - 人的主观感受来自于对比 先揭晓答案，星巴克摆放“x云矿泉水”根本不是拿来卖的，而是给你看的。 “x云矿泉水”在星巴克一般标价20多人民币，而星巴克咖啡价格在20-30上下。 所以，“x云矿泉水”只是个陪衬，由此在向你传递一个潜台词： 你看，一瓶水都卖20多，我20到30的咖啡还能算贵吗？ 这种现象在营销领域很常见，《经济学人》杂志曾说过一个非常经典的案例： 一家杂志社想推出网络版，于是找营销专家策划，专家做了两个方案： 1、购买网络版要56美元； 2、购买网络加纸质版125美元； 结果，用户大多会选择56美元的网络版。 但是问题随之而来，纸质版的没人买，于是又请来一位营销大师，这位大师给了三个方案： 1、购买网络版要56美元； 2、购买纸质版125美元； 3、购买网络加纸质版125美元。 结果可想而知，大家都选第三个方案，第二个方案其实就是个陪衬。 这一招我们现实中随处可见，如果你留意一下手机话费套餐，就会发现确实存在陪衬者，只为你做决策方便。 这种“陪衬机制”的底层原理，就是诺贝尔得主卡尼曼所揭示的：人类的主观感受主要来自对比。 这给我们有什么启发吗？其实很多。 比如，你给领导写报告，如果时间充足，第一稿可以糙一点，因为无论怎样，领导看完都会提出意见让你改，所以第二稿要憋足劲，搞得完美一些，对比之下，比第一稿好那么多，通过率自然也高。 再比如，如果你是女孩，找闺蜜逛街，就不能找和你颜值差不多，要找比你差一点的，道理你自然懂。 “陪衬机制”在生活中处处有应用的机会，只看你是不是个“有心人”了。 - 03 - 经营如做人，不要太势利 十几年前，我和几个朋友谈事，就近找了个星巴克，但我们几个都是一喝咖啡睡不着的主，所以什么都没点，只是干坐着。 一位工作人员，走了过来，我以为是撵我们走，连忙站了起来。 谁知，她笑了笑说：没关系，你们坐，你们坐。我只是看到桌子上有点污渍，来擦一下。 这下让我感觉挺不好意思，于是点了几杯咖啡含量极低的“摩卡”。 那是我第一次喝星巴克的饮品，却对这家企业顿生好感，成为日后的忠实拥趸。 本来以为，是那位工作人员的个人行为，最近有件事更让我觉得不可思议。 我经常在深圳书城星巴克写文章，而且有个御用宝位，安静、景色佳，可最近一直被一名流浪汉占据。 是的，你没看错，真的是名流浪汉，很年轻，但头发几乎能挤出油，整天一身油污满身的衣服。 一连两个月，都占据我的宝位，而且什么东西都不点，只是坐在那里，看手机里的动画片，一待一上午。但是，工作人员对他却置之不理，甚至在店内分发免费饮品时，也给他也分一小杯…… 我问一名工作人员，这人什么都不点，一坐两个月的人，你们也不赶走，为什么？ 她说：“这是公司规定，只要在店里坐的人，都是顾客。” 这句话，还是小小颠覆了我对经营的认知。 放眼多数的餐厅、茶饮，很少会让你白坐，没一会儿店员就会问你要喝点什么，如果你说什么都不要，对方马上会说：“不好意思，不消费不能白坐。” 哪怕当下一个顾客也没有，店家也会下逐客令。 这就是格局不够大，只把真正花钱的才当顾客，而忽视了那些潜在的消费者。 人家坐久了，多数人都会花销，这不就有转化率了吗？就算别人不消费，最起码也给商家攒个人气啊，路过的人看到你热火朝天，就有进来的冲动。 你看就是这样，做生意和做人一样，不要太势利。 人这一生很漫长，说不好谁会成为你的贵人。 之前，看到一篇文章，说刚刚离职，就被很多同事拉黑。我觉得那些同事真的好傻，多个朋友多条路，这句话什么时候都适用。 我以前在500强时有个习惯，但凡有离职的同事，我都会发个信息，道声别，说声保持联系。 因为这些出去的人就是一个个窗口啊，他们在外面混得如何，不也给你的未来做个参照吗？ 后来我出来创业，就是得到了一位离职同事的帮助，他几年前创业做培训。我是踩着他的脚印一步步走来，还真省了不少劲。 所以，我老妈以前说“人缘是攒出来的”。现在想想还真有道理，就像星巴克的理念，来的就是客，现在不消费，但终究有消费的机会。 - 04 - 狼性文化不如人性文化 去年过年期间，我在欢乐海岸星巴克，旁边来了一个中年妇女，带着两个娃，她衣着华丽，穿金戴银。 只是她嗓门大了些，一直大声呵责那俩熊孩子，引来很多人侧望。 没一会儿，其中一熊娃把饮料打翻了，那妇女又尖叫起来，给了娃两巴掌，娃哇哇大哭。 妇女气急败坏的对着柜台大声： “服务员！服务员！快拿抹布过来啊！” 结果，柜台内的几个工作人员，没一个理她。 于是，她走向柜台，对着最近的工作人员嗓道：“服务员！我叫你呢，你装着没听见吗？” 那女孩环顾左右，一脸懵懂回到：“我不知道你在叫谁？我们这儿没有服务员，只有咖啡师。” 妇女威胁到：“你怎么这种服务态度，不想让别人再来了吗？” 女孩微微一笑说：“请便。” 亲眼看到这一幕，心里默默给那女孩点赞。 日常中，你也会发现，星巴克的服务员，不，咖啡师，不像海底捞那般的热情，当然也不是冷冰冰，而是和你平起平坐。 他们不会因为你是顾客就刻意讨好你，这其实就是企业文化的体现。 星巴克中国区人力资源副总裁余华曾说过，企业内部从来不称呼“店员”或“员工”，而是称“伙伴”（Partner），就是想让每个人之间是彼此尊重。 这种人性文化，也许就是咖啡师们不太热情，却又恰如其分的原因。 相比较而言，我极讨厌很多企业崇尚的“狼性文化”，而且“狼性文化”往往会演变成一种“狼狗文化”。 怎么说呢？他们期望员工对待纪律的统一性像狼，但又有希望员工对待公司的忠诚度像狗；他们期望员工对待竞争的进取心像狼，但又希望员工对待客户的迎合度像狗。 这一会儿狼性，一会儿狗性的，员工不分裂吗，为啥就不能让他们拥有“人性”。 我的MBA管理学教授说过一句话，我很认可，他说：“管理就像教育小孩，身体力行大于说教，你对员工啥样，员工也会对客户啥样。” 想想也是吧，你一嘴的仁义道德，却对员工百般苛刻，你还能指望员工对客户好到哪里？多半是能骗一个算一个。 最后，吃亏的到底是谁？ 所以这件事对我的启发是，无论经营还是管理，无论对待客户还是对待员工，都还是回归本性好些。 不能因为员工身处底层，你就飞扬跋扈；也不要因为客户手握财源，你就媚颜百献。 对人实实在在，把该做的做好，比啥都强。也别再鼓吹什么“狼性文化”，这个年代更需要的是“人性文化”。 - THE END - * 作者：徐大维，知名培训顾问，原平安集团渠道总监，香港理工大学管理硕士，简书签约作者。公众号：良大师（ID:lang-da-shi）。","categories":[{"name":"随想","slug":"随想","permalink":"https://rovast.github.io/categories/随想/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://rovast.github.io/tags/转载/"}]},{"title":"phpunit 快速入门","slug":"start-phpunit","date":"2019-01-08T05:25:32.000Z","updated":"2020-11-28T08:49:18.083Z","comments":true,"path":"2019/01/08/start-phpunit/","link":"","permalink":"https://rovast.github.io/2019/01/08/start-phpunit/","excerpt":"","text":"phpunit 的官方文档对如何使用 phpunit 进行了详细的说明。本人在通读文档后进行了一些概要提升，同时摘录了一些示例 phpunit-demo，便于以后理解和查阅。 文档较为简洁，但是也涵盖了平时使用的基本用法，适合入门使用。 安装 phpunit项目安装1composer require --dev phpunit/phpunit 使用 ./vendor/bin/phpunit 全局安装1composer global require --dev phpunit/phpunit 使用 phpunit 快速入门基本格式 测试类命名： 类名 + Test ， eg FooClassTest 测试方法命名： test + 方法名, eg testFoo 也可以使用注释 @test 来标注需要测试的方法 1234567891011121314151617use PHPUnit\\Framework\\TestCase;class SampleTest extends TestCase&#123; public function testSomething() &#123; $this-&gt;assertTrue(true, 'This should already work.'); &#125; /** * @test */ public function something() &#123; $this-&gt;assertTrue(true, 'This should already work.'); &#125;&#125; 测试依赖(@depends)有一些测试方法需要依赖于另一个测试方法的返回值，此时需要使用测试依赖。测试依赖通过注释 @depends 来标记。 下列中， depends 方法的 return 值作为 testConsumer 的参数传入 1234567891011121314151617181920212223242526use PHPUnit\\Framework\\TestCase;class MultipleDependenciesTest extends TestCase&#123; public function testProducerFirst() &#123; $this-&gt;assertTrue(true); return 'first'; &#125; public function testProducerSecond() &#123; $this-&gt;assertTrue(true); return 'second'; &#125; /** * @depends testProducerFirst * @depends testProducerSecond */ public function testConsumer($a, $b) &#123; $this-&gt;assertSame('first', $a); $this-&gt;assertSame('second', $b); &#125;&#125; 数据提供器(@dataProvider)在依赖中，所依赖函数的返回值作为参数传入测试函数。除此之外，我们也可以用数据提供器来定义传入的数据。 12345678910111213141516171819202122use PHPUnit\\Framework\\TestCase;class DataTest extends TestCase&#123; /** * @dataProvider additionProvider */ public function testAdd($a, $b, $expected) &#123; $this-&gt;assertSame($expected, $a + $b); &#125; public function additionProvider() &#123; return [ 'adding zeros' =&gt; [0, 0, 0], // 0 + 0 = 0 pass 'zero plus one' =&gt; [0, 1, 1], // 0 + 1 = 1 pass 'one plus zero' =&gt; [1, 0, 1], // 1 + 0 = 1 pass 'one plus one' =&gt; [1, 1, 2], // 1 + 1 = 2 pass ]; &#125;&#125; 测试异常(expectException)需要在测试方法的开始处声明断言，然后执行语句。而不是调用后再声明 也可以通过注释来声明 @expectedException, @expectedExceptionCode,@expectedExceptionMessage, @expectedExceptionMessageRegExp 123456789101112131415161718192021use PHPUnit\\Framework\\TestCase;class ExceptionTest extends TestCase&#123; public function testException() &#123; $this-&gt;expectException(\\Exception::class); throw new \\Exception('test'); &#125; /** * @throws \\Exception * @test * @expectedException \\Exception */ public function exceptionExpect() &#123; throw new \\Exception('test'); &#125;&#125; 测试 PHP 错误通过提前添加期望，来使测试正常进行，而不会报出 PHP 错误 123456789101112use PHPUnit\\Framework\\TestCase;class ExpectedErrorTest extends TestCase&#123; /** * @expectedException PHPUnit\\Framework\\Error\\Error */ public function testFailingInclude() &#123; include 'not_existing_file.php'; &#125;&#125; 测试输出直接添加期望输出，然后执行相关函数。和测试异常类似，需要先添加期望，再执行代码。 12345678910111213141516use PHPUnit\\Framework\\TestCase;class OutputTest extends TestCase&#123; public function testExpectFooActualFoo() &#123; $this-&gt;expectOutputString('foo'); print 'foo'; &#125; public function testExpectBarActualBaz() &#123; $this-&gt;expectOutputString('bar'); print 'baz'; &#125;&#125; 命令行测试此章节主要说明了命令行的一些格式和可用参数。可以参考官方文档获取细节。The Command-Line Test Runner 基境基境就是在测试前需要准备的一系列东西。 比如有的测试需要依赖数据库的数据，那么在测试类运作前需要进行数据的准备。 主要有两个函数 setUp 和 tearDown。 那为什么不直接用构造函数和析构函数呢？是因为这两个有他用，当然你可可以直接用构造函数，然后再执行 parent::__construct，但不是麻烦嘛; 组织你的测试代码可以通过命令行的 --bootstrap 参数来指定启动文件，用于文件加载。正常情况下，可以指向 composer 的 autoload 文件。也可以在配置文件中配置（推荐）。 12345678$ phpunit --bootstrap src/autoload.php testsPHPUnit |version|.0 by Sebastian Bergmann and contributors..................................Time: 636 ms, Memory: 3.50MbOK (33 tests, 52 assertions) 1234567&lt;phpunit bootstrap=\"src/autoload.php\"&gt; &lt;testsuites&gt; &lt;testsuite name=\"money\"&gt; &lt;directory&gt;tests&lt;/directory&gt; &lt;/testsuite&gt; &lt;/testsuites&gt;&lt;/phpunit&gt; 有风险的测试(Risky Tests)无用测试(Useless Tests)默认情况下，如果你的测试函数没有添加预期或者断言，就会被认为是无用测试。 通过设置 --dont-report-useless-tests 命令行参数，或者在 xml 配置文件中配置 beStrictAboutTestsThatDoNotTestAnything=&quot;false&quot; 来更改这一默认行为。 意外的代码覆盖(Unintentionally Covered Code)当打开这个配置后，如果使用 @covers 注释来包含一些文件的覆盖报告，就会被判定为有风险的测试。 通过设置 --strict-coverage 命令行参数，或者在 xml 配置文件中配置 beStrictAboutCoversAnnotation=&quot;true&quot; 来更改这一默认行为。 测试过程中有输出(Output During Test Execution)如果在测试过程中输出文本，则会被认定为有风险的测试。 通过设置 --disallow-test-output 命令行参数，或者在 xml 配置文件中配置 beStrictAboutOutputDuringTests=&quot;true&quot; 来更改这一默认行为。 测试超时(Test Execution Timeout)通过注释来限制某些测试不能超过一定时间： @large 60秒 @medium 10秒 @small 1秒 通过设置 --enforce-time-limit 命令行参数，或者在 xml 配置文件中配置 enforceTimeLimit=&quot;true&quot; 来更改这一默认行为。 操作全局状态(Global State Manipulation)phpunit 可以对全局状态进行检测。 通过设置 --strict-global-state 命令行参数，或者在 xml 配置文件中配置 beStrictAboutChangesToGlobalState=&quot;true&quot; 来更改这一默认行为。 待完善的测试和跳过的测试处于一些原因，我们希望跳过或者对某些测试方法标记未待完善 待完善的测试使用 $this-&gt;markTestIncomplete 标记待完善的测试 123456789101112use PHPUnit\\Framework\\TestCase;class SampleTest extends TestCase&#123; public function testSomething() &#123; $this-&gt;assertTrue(true, 'This should already work.'); $this-&gt;markTestIncomplete( 'This test has not been implemented yet.' ); &#125; 跳过的测试使用 markTestSkipped 来标记跳过的测试。123456789101112131415161718use PHPUnit\\Framework\\TestCase;class DatabaseTest extends TestCase&#123; protected function setUp() &#123; if (!extension_loaded('mysqli')) &#123; $this-&gt;markTestSkipped( 'The MySQLi extension is not available.' ); &#125; &#125; public function testConnection() &#123; // ... &#125;&#125; 结合 @require 来跳过测试以下的示例中，使用 require 来限定测试需要依赖 mysqli 拓展和 5.3 以上的 PHP 版本，否则跳过测试 1234567891011121314151617use PHPUnit\\Framework\\TestCase;/** * @requires extension mysqli */class DatabaseTest extends TestCase&#123; /** * @requires PHP 5.3 */ public function testConnection() &#123; // Test requires the mysqli extension and PHP &gt;= 5.3 &#125; // ... All other tests require the mysqli extension&#125; 数据库测试使用数据库测试之前先安装拓展 composer require --dev phpunit/dbunit。 总的来说，我们在好多的测试场景中都会用到数据库，我们可以结合 PHPUnit 的基境章节中提到的 setUp 来进行测试。 我们来看一个示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293use PHPUnit\\DbUnit\\DataSet\\ArrayDataSet;use PHPUnit\\DbUnit\\TestCaseTrait;use PHPUnit\\Framework\\TestCase;/** * 测试之前，需要在 MySQL 中新建数据库 phpunit，并且新建表 guestbook * CREATE TABLE `guestbook` ( * `id` bigint(20) NOT NULL, * `content` varchar(255) COLLATE utf8mb4_bin NOT NULL, * `user` varchar(255) COLLATE utf8mb4_bin NOT NULL, * `created` datetime NOT NULL * ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; * Class ConnectionTest. * * @requires extension pdo_mysql */class ConnectionTest extends TestCase&#123; use TestCaseTrait; /** * @return \\PHPUnit\\DbUnit\\Database\\DefaultConnection */ public function getConnection() &#123; $pdo = new \\PDO( 'mysql:host=127.0.0.1:33060;dbname=phpunit;charset=utf8mb4', 'root', '112233' ); return $this-&gt;createDefaultDBConnection($pdo); &#125; /** * 请注意，phpunit每次会先 TRUNCATE 数据库，然后把下面数组的数据插入进去. * * @return ArrayDataSet */ public function getDataSet() &#123; return new ArrayDataSet( [ 'guestbook' =&gt; [ [ 'id' =&gt; 1, 'content' =&gt; 'Hello buddy!', 'user' =&gt; 'joe', 'created' =&gt; '2010-04-24 17:15:23', ], [ 'id' =&gt; 2, 'content' =&gt; 'I like it!', 'user' =&gt; 'mike', 'created' =&gt; '2010-04-26 12:14:20', ], ], ] ); &#125; public function testCreateDataSet() &#123; $this-&gt;markTestSkipped('just an example, skipped'); $tableNames = ['guestbook']; $dataSet = $this-&gt;getConnection()-&gt;createDataSet(); &#125; public function testCreateQueryTable() &#123; $this-&gt;markTestSkipped('just an example, skipped'); $tableNames = ['guestbook']; $queryTable = $this-&gt;getConnection()-&gt;createQueryTable('guestbook', 'SELECT * FROM guestbook'); &#125; public function testGetRowCount() &#123; $this-&gt;assertSame(2, $this-&gt;getConnection()-&gt;getRowCount('guestbook')); &#125; /** * 测试表的内容和给定的数据集相等. */ public function testAddEntry() &#123; $queryTable = $this-&gt;getConnection()-&gt;createQueryTable( 'guestbook', 'SELECT * FROM guestbook' ); $expectedTable = $this-&gt;createFlatXmlDataSet(__DIR__.'/expectedBook.xml') -&gt;getTable('guestbook'); $this-&gt;assertTablesEqual($expectedTable, $queryTable); &#125;&#125; 其中 getConnection 和 getDataSet 都是 TestCaseTrait 中提供的方法，我们在 getConnection 中设定数据库的链接动作，同时在 getDataSet 中设定需要往数据库中写入的数据，注意，每次执行这个测试类时，都会执行 清空数据库 TRUNCATE 填充数据 如何验证呢？加一个字段为 datetime 类型，设置位数据库自动更新时间，即可看到每次执行测试时，时间都在变化 测试桩所谓的桩测试，其实就是对一些类的方法进行一番 mock，强制其返回一些数据。因为在开发中，有一些类依赖于第三方服务，而第三方服务又属于“不可控”因素，所以这个时候就需要使用“桩”了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141use PHPUnit\\Framework\\TestCase;class StubTest extends TestCase&#123; public function testStub() &#123; // Create a stub for the SomeClass class. $stub = $this-&gt;createMock(SomeClass::class); // Configure the stub. $stub-&gt;method('doSomething') -&gt;willReturn('foo'); // Calling $stub-&gt;doSomething() will now return // 'foo'. $this-&gt;assertSame('foo', $stub-&gt;doSomething()); &#125; public function testStub2() &#123; // Create a stub for the SomeClass class. $stub = $this-&gt;getMockBuilder(SomeClass::class) -&gt;disableOriginalConstructor() -&gt;disableOriginalClone() -&gt;disableArgumentCloning() -&gt;disallowMockingUnknownTypes() -&gt;getMock(); // Configure the stub. $stub-&gt;method('doSomething') -&gt;willReturn('foo'); // Calling $stub-&gt;doSomething() will now return // 'foo'. $this-&gt;assertSame('foo', $stub-&gt;doSomething()); &#125; public function testReturnArgumentStub() &#123; // Create a stub for the SomeClass class. $stub = $this-&gt;createMock(SomeClass::class); // Configure the stub. $stub-&gt;method('doSomething') -&gt;will($this-&gt;returnArgument(0)); // $stub-&gt;doSomething('foo') returns 'foo' $this-&gt;assertSame('foo', $stub-&gt;doSomething('foo')); // $stub-&gt;doSomething('bar') returns 'bar' $this-&gt;assertSame('bar', $stub-&gt;doSomething('bar')); &#125; public function testReturnSelf() &#123; // Create a stub for the SomeClass class. $stub = $this-&gt;createMock(SomeClass::class); // Configure the stub. $stub-&gt;method('doSomething') -&gt;will($this-&gt;returnSelf()); // $stub-&gt;doSomething() returns $stub $this-&gt;assertSame($stub, $stub-&gt;doSomething()); &#125; public function testReturnValueMapStub() &#123; // Create a stub for the SomeClass class. $stub = $this-&gt;createMock(SomeClass::class); // Create a map of arguments to return values. $map = [ ['a', 'b', 'c', 'd'], ['e', 'f', 'g', 'h'], ]; // Configure the stub. $stub-&gt;method('doSomething') -&gt;will($this-&gt;returnValueMap($map)); // $stub-&gt;doSomething() returns different values depending on // the provided arguments. $this-&gt;assertSame('d', $stub-&gt;doSomething('a', 'b', 'c')); $this-&gt;assertSame('h', $stub-&gt;doSomething('e', 'f', 'g')); &#125; public function testReturnCallbackStub() &#123; // Create a stub for the SomeClass class. $stub = $this-&gt;createMock(SomeClass::class); // Configure the stub. $stub-&gt;method('doSomething') -&gt;will($this-&gt;returnCallback('str_rot13')); // $stub-&gt;doSomething($argument) returns str_rot13($argument) $this-&gt;assertSame('fbzrguvat', $stub-&gt;doSomething('something')); &#125; /** * 按照指定顺序返回列表中的值 */ public function testOnConsecutiveCallsStub() &#123; // 为 SomeClass 类创建桩件。 $stub = $this-&gt;createMock(SomeClass::class); // 配置桩件。 $stub-&gt;method('doSomething') -&gt;will($this-&gt;onConsecutiveCalls(2, 3, 5, 7)); // $stub-&gt;doSomething() 每次返回值都不同 $this-&gt;assertSame(2, $stub-&gt;doSomething()); $this-&gt;assertSame(3, $stub-&gt;doSomething()); $this-&gt;assertSame(5, $stub-&gt;doSomething()); &#125; public function testThrowExceptionStub() &#123; $this-&gt;expectException(\\Exception::class); // 为 SomeClass 类创建桩件 $stub = $this-&gt;createMock(SomeClass::class); // 配置桩件。 $stub-&gt;method('doSomething') -&gt;will($this-&gt;throwException(new \\Exception())); // $stub-&gt;doSomething() 抛出异常 $stub-&gt;doSomething(); &#125;&#125;class SomeClass&#123; public function doSomething() &#123; // Do something. &#125;&#125; 我们看到， SomeClass 的 doSomething() 本身没有返回数据，我们通过桩动作，来完成了测试。 这个在测试依赖于第三方服务的相关代码时很管用。 代码覆盖度白名单文件(Whitelisting Files)添加到白名单文件的文件或者文件夹，会进行代码覆盖度统计的工作。具体的参数可以看帮助文档 ### 忽略代码块(Ignoring Code Blocks) 我们可以添加部分代码不进行覆盖度统计。通过一些注释来标记即可 1234567891011121314151617181920212223242526272829use PHPUnit\\Framework\\TestCase;/** * @codeCoverageIgnore */class Foo&#123; public function bar() &#123; &#125;&#125;class Bar&#123; /** * @codeCoverageIgnore */ public function foo() &#123; &#125;&#125;if (false) &#123; // @codeCoverageIgnoreStart print '*'; // @codeCoverageIgnoreEnd&#125;exit; // @codeCoverageIgnore 执行方法进行统计(Specifying Covered Methods)同样通过添加注释标记的方法来执行需要覆盖的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869use PHPUnit\\Framework\\TestCase;class BankAccountTest extends TestCase&#123; protected $ba; protected function setUp() &#123; $this-&gt;ba = new BankAccount; &#125; /** * @covers BankAccount::getBalance */ public function testBalanceIsInitiallyZero() &#123; $this-&gt;assertSame(0, $this-&gt;ba-&gt;getBalance()); &#125; /** * @covers BankAccount::withdrawMoney */ public function testBalanceCannotBecomeNegative() &#123; try &#123; $this-&gt;ba-&gt;withdrawMoney(1); &#125; catch (BankAccountException $e) &#123; $this-&gt;assertSame(0, $this-&gt;ba-&gt;getBalance()); return; &#125; $this-&gt;fail(); &#125; /** * @covers BankAccount::depositMoney */ public function testBalanceCannotBecomeNegative2() &#123; try &#123; $this-&gt;ba-&gt;depositMoney(-1); &#125; catch (BankAccountException $e) &#123; $this-&gt;assertSame(0, $this-&gt;ba-&gt;getBalance()); return; &#125; $this-&gt;fail(); &#125; /** * @covers BankAccount::getBalance * @covers BankAccount::depositMoney * @covers BankAccount::withdrawMoney */ public function testDepositWithdrawMoney() &#123; $this-&gt;assertSame(0, $this-&gt;ba-&gt;getBalance()); $this-&gt;ba-&gt;depositMoney(1); $this-&gt;assertSame(1, $this-&gt;ba-&gt;getBalance()); $this-&gt;ba-&gt;withdrawMoney(1); $this-&gt;assertSame(0, $this-&gt;ba-&gt;getBalance()); &#125;&#125;","categories":[{"name":"流程","slug":"流程","permalink":"https://rovast.github.io/categories/流程/"}],"tags":[]},{"title":"谷歌浏览器截取整个网页","slug":"capture-full-size-in-chrome","date":"2018-12-29T05:35:04.000Z","updated":"2020-11-28T08:49:18.045Z","comments":true,"path":"2018/12/29/capture-full-size-in-chrome/","link":"","permalink":"https://rovast.github.io/2018/12/29/capture-full-size-in-chrome/","excerpt":"","text":"问，把大象装进冰箱要几步？ 答，三步。先打开冰箱，然后塞进去，再关上冰箱。 问，chrome 截取整个网页要几步？ 答：三步。 1. 打开控制台 2. 依次键入 ctrl shift p 3. 输入 capture，选择 capture full size 即可","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[]},{"title":"restful API 的 code 码定义","slug":"define-restful-api-code","date":"2018-12-28T12:32:35.000Z","updated":"2020-11-28T08:49:18.050Z","comments":true,"path":"2018/12/28/define-restful-api-code/","link":"","permalink":"https://rovast.github.io/2018/12/28/define-restful-api-code/","excerpt":"","text":"前言随着网络应用的不断发展，衍生出了「前后端分离」的基本架构。前后端分离的优势这里不作深入讨论。 前后端完全分离后，多端（浏览器、APP等）和服务端的交互可以通过 API 请求的方式进行，本文主要讨论restful api 实践中的一环：数据返回格式的定义。 关于 rest 的一些设计原则，可以参考阮一峰总结的两篇文章： 《RESTful API 设计指南》 RESTful API 最佳实践 数据返回格式数据返回主要要包含以下信息： 服务器的响应状态，起码要知道是成功还是失败是吧 请求的数据内容，比如我获取了产品列表，你要告诉我有哪些产品是吧 请求的更多说明，就是对1的说明，比如失败了，你要告诉我什么原因是吧 总结下来，基本结构为 12345678&#123; code: 200, data: [ &#123; name: \"xiao mi\"&#125;, &#123; name: \"apple\"&#125; ], msg: \"success\"&#125; 其中 code 为接口返回的状态码（和 http 码不太一样，完全可以自己定义） data 为返回的数据，为 json 格式，可以是数组，也可以是单条数据 msg 为 code 的说明，尤其在请求错误时，进行相关描述 需要注意的是，推荐 data 字段采取标准json进行传输，即使是再简单的数据，不要进行自定义格式。这样方便前后端编码 code 的定义规则code 一般采取通用码和业务码相结合的方式进行。 通用码通用码可以参考 http 协议的状态码，定义了最基本的一些情况，简单列举如下 200 请求成功 201 创建成功 400 错误的请求 401 未授权 403 无权限访问 404 无效的请求地址 500 服务器内部错误 -1 业务错误，具体原因看 msg 除了上述的错误外，我们还会遇到更多和业务相关的错误。比如请求某个产品详情接口，没有传递 product_id 的「参数错误」，或者需要传入 id 但是传入参数不是符合规定的数据类型（如：int）。 甚至是因为仓库产品不足，导致请求不能拿到产品列表需要提示的，等等。 在这种情况下，我们的通用码就不够看了，有个折衷的办法，就是返回统一的 code 码，如 -1。然后在 msg 中对具体原因做说明。 对于出现错误排查原因，我们只需要看 code 为 500 和 -1 的请求，再结合 msg 即可排查 业务码等等！仅仅靠 msg 来么，万一项目比较大，msg 近似，还怎么排查？有没有一种办法，根据 code 能快速定位到问题呢？ 当然可以！ 我们假设有如下业务模块：用户（User）、产品（Product）、评论（Comment） 我们可以对业务进行相关编码。 User 01 Product 02 Comment 03 然后，我们在假设各个模块下，不同具体功能定义不同码，如： User 01 user/list 01 user/detail 02 Product 02 product/list 01 product/detail 02 Comment 03 comment/list 01 comment/detail 03 好了，目前我们根据业务拓展出了两层编码，如果后面有更多的业务层级，可以继续拓展下去。甚至是不同的错误，我们可以映射出一张 code table，在编码过程中抛出。 至此，如果请求用户列表出错了，我们可以返回12345&#123; code: 0101, data: null, msg: \"请求用户列表出错\"&#125; 总结定义返回值的意义在于约束多端开发，统一规范，大家可以根据自己的业务复杂程度和团队规模去指定符合自己的规范。毕竟，其实好多团队也不是这么定义的，大家多去看看一些成熟平台定义的 API，完全可以参考，如： 百度地图 微信开发文档","categories":[{"name":"流程","slug":"流程","permalink":"https://rovast.github.io/categories/流程/"}],"tags":[]},{"title":"在MySQL中使用utf8mb4来取代utf8(又名：utf8mb3)","slug":"use-utf8mb4-in-mysql","date":"2018-12-27T02:45:51.000Z","updated":"2020-11-28T08:49:18.089Z","comments":true,"path":"2018/12/27/use-utf8mb4-in-mysql/","link":"","permalink":"https://rovast.github.io/2018/12/27/use-utf8mb4-in-mysql/","excerpt":"","text":"结论先抛出一个结论： MySQL中，utf8 又名 utf8mb3，存储的字符使用 1~3 个 byte utf8mb4，储存字符时，使用 1~4 个 byte utf8mb4 是 utf8 的超集，对于 utf8 存储的内容， utf8mb4 使用相同的方式存储。 utf8的储存的东西，可以无痛转为 utf8mb4 理论支撑给出结论，是要有理论依据的，让我们来查查 MySQL 官方文档： 10.9.1 The utf8mb4 Character Set (4-Byte UTF-8 Unicode Encoding)The utfmb4 character set has these characteristics: Supports BMP and supplementary[翻译：补充的] characters. Requires a maximum of four bytes per multibyte character. utf8mb4 contrasts with the utf8mb3 character set, which supports only BMP characters and uses a maximum of three bytes per character: For a BMP character, utf8mb4 and utf8mb3 have identical[翻译：完全相同] storage characteristics: same code values, same encoding, same length. For a supplementary character, utf8mb4 requires four bytes to store it, whereas utf8mb3 cannot store the character at all. When converting utf8mb3 columns toutf8mb4, you need not worry about converting supplementary characters because there will be none. utf8mb4 is a superset of utf8mb3, so for an operation such as the following concatenation, the result has character set utf8mb4 and the collation of utf8mb4_col: undefined Similarly, the following comparison in the WHERE clause works according to the collation of utf8mb4_col: undefined For information about data type storage as it relates to multibyte character sets, see String Type Storage Requirements. @mysql.comdev.mysql.com/doc/refman/5.7/en/charset-unicode-utf8mb4.html 注意我标注的加粗的部分。 PHP 中目前主流处理PDO目前 php 链接数据库时，可以设定字符集。比如 pdo，那么我们在使用 pdo 时，就需要设定 charset 为 utf8mb4 了， 来看一则 stackoverflow 的问答 Question: when initializing PDO - should I do: charset=UTF8 or charset=UTF8MB4 ? here’s my intialization: undefined But should dsn be this: undefined if mysql database has a default charset UTF8MB4. mysql pdo character-encoding shareedit asked Jul 27 ‘15 at 17:56 Dannyboy Answer You should use utf8mb4 for PDO and your database structures. undefined When possible, don’t forget to set the character encoding of your pages as well. PHP example: undefined @stackoverflow.comstackoverflow.com/questions/31660005/when-initializing-pdo-should-i-do-charset-utf8-or-charset-utf8mb4 Laravel我们来看看优雅的 laravel 如何处理的： file: config/database.php123456789101112131415'mysql' =&gt; [ 'driver' =&gt; 'mysql', 'host' =&gt; env('DB_HOST', '127.0.0.1'), 'port' =&gt; env('DB_PORT', '3306'), 'database' =&gt; env('DB_DATABASE', 'forge'), 'username' =&gt; env('DB_USERNAME', 'forge'), 'password' =&gt; env('DB_PASSWORD', ''), 'unix_socket' =&gt; env('DB_SOCKET', ''), 'charset' =&gt; 'utf8mb4', 'collation' =&gt; 'utf8mb4_unicode_ci', 'prefix' =&gt; '', 'prefix_indexes' =&gt; true, 'strict' =&gt; true, 'engine' =&gt; null,], 所以， utf8mb4 用起来吧！ 至于为什么默认的 utf8 不采取 4 个 byte 来存储，想必是 MySQL 设计初期还没有这么多奇奇怪怪的字符吧。为了性能效率，所以用了最多 3 个来储存。感兴趣的童鞋可以去搜罗下相关资料。 补充Note The utf8mb3 character set is deprecated and will be removed in a future MySQL release.Please use utf8mb4 instead. Although utf8 is currently an alias for utf8mb3,at that point utf8 will become a reference to utf8mb4.To avoid ambiguity about the meaning of utf8, consider specifying utf8mb4explicitly for character set referencesinstead of utf8. @mysql.comdev.mysql.com/doc/refman/8.0/en/charset-unicode-utf8mb3.html 啥意思呢，就是说，未来就没有 utfbmb3 了，那时候，utf8 代表的就是 utf8mb4 了，期待那一天吧！","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://rovast.github.io/categories/MySQL/"}],"tags":[]},{"title":"URL和URI的区别","slug":"url-and-uri","date":"2018-12-26T01:59:26.000Z","updated":"2020-11-28T08:49:18.085Z","comments":true,"path":"2018/12/26/url-and-uri/","link":"","permalink":"https://rovast.github.io/2018/12/26/url-and-uri/","excerpt":"","text":"摘自：《HTTP权威指南》 1.3 资源Web 服务器是 Web 资源（Web resource）的宿主。Web 资源是 Web 内容的源头。最简单的 Web 资源就是 Web 服务器文件系统中的静态文件。这些文件可以包含任意内容：文本文件、 HTML 文件、微软的 Word 文件、 Adobe 的 Acrobat 文件、 JPEG 图片文件、 AVI 电影文件，或所有其他你能够想到的格式。 但资源不一定非得是静态文件。资源还可以是根据需要生成内容的软件程序。这些动态内容资源可以根据你的身份、所请求的信息或每天的不同时段来产生内容。它们可以为你显示照相机中活生生的照片，也可以帮你进行股票交易，搜索房产数据库，或者从在线商店中购买礼物（参见图 1-2）。 图 1-2 所有能够提供 Web 内容的东西都是 Web 资源 总之，所有类型的内容来源都是资源。包含公司销售预测电子表格的文件是一种资源。扫描本地公共图书馆书架的 Web 网关是一种资源。因特网搜索引擎也是一种资源。 1.3.1 媒体类型因特网上有数千种不同的数据类型，HTTP 仔细地给每种要通过 Web 传输的对象都打上了名为 MIME 类型（MIME type）的数据格式标签。最初设计 MIME （Multipurpose Internet Mail Extension，多用途因特网邮件扩展）是为了解决在不同的电子邮件系统之间搬移报文时存在的问题。MIME 在电子邮件系统中工作得非常好，因此 HTTP 也采纳了它，用它来描述并标记多媒体内容。 Web 服务器会为所有 HTTP 对象数据附加一个 MIME 类型（参见图 1-3）。当 Web 浏览器从服务器中取回一个对象时，会去查看相关的 MIME 类型，看看它 是否知道应该如何处理这个对象。大多数浏览器都可以处理数百种常见的对象类型：显示图片文件、解析并格式化 HTML 文件、通过计算机声卡播放音频文件，或者运行外部插件软件来处理特殊格式的数据。 图 1-3 与数据内容一同回送的 MIME 类型 MIME 类型是一种文本标记，表示一种主要的对象类型和一个特定的子类型，中间由一条斜杠来分隔。 HTML 格式的文本文档由 text/html 类型来标记。 普通的 ASCII 文本文档由 text/plain 类型来标记。 JPEG 格式的图片为 image/jpeg 类型。 GIF 格式的图片为 image/gif 类型。 Apple 的 QuickTime 电影为 video/quicktime 类型。 微软的 PowerPoint 演示文件为 application/vnd.ms-powerpoint 类型。 常见的 MIME 类型有数百个，实验性或用途有限的 MIME 类型则更多。附录 D 提供了一个非常完整的 MIME 类型列表。 1.3.2 URI每个 Web 服务器资源都有一个名字，这样客户端就可以说明它们感兴趣的资源是什么了。服务器资源名被称为统一资源标识符（Uniform Resource Identifier, URI）。URI 就像因特网上的邮政地址一样，在世界范围内唯一标识并定位信息资源。 这是 Joe 的五金商店的 Web 服务器上一个图片资源的 URI： http://www.joes-hardware.com/specials/saw-blade.gif 图 1-4 显示了 URI 是怎样指示 HTTP 协议去访问 Joe 商店服务器上的图片资源的。给定了 URI，HTTP 就可以解析出对象。URI 有两种形式，分别称为 URL 和 URN。现在我们分别来看看这些资源标识符类型。 1.3.3. URL统一资源定位符（URL）是资源标识符最常见的形式。URL 描述了一台特定服务器上某资源的特定位置。它们可以明确说明如何从一个精确、固定的位置获取资源。图 1-4 显示了 URL 如何精确地说明某资源的位置以及如何去访问它。表 1-1 显示了几个 URL 实例。 表 1-1 URL实例 URL 描 述 http://www.oreilly.com/index.html O’Reilly &amp; Associates 公司的主URL http://www.yahoo.com/images/logo.gif Yahoo! 的Web 站点标志URL http://www.joes-hardware.com/inventory-check.cgi?item=12731 一个查看库存条目#12731 是否有现货的程序的URL ftp://joe:tools4u@ftp.joes-hardware.com/lockingpliers.gif 以密码保护的FTP 作为访问协议的lockingpliers.gif 图片文件的URL 大部分 URL 都遵循一种标准格式，这种格式包含三个部分。 URL 的第一部分被称为方案（scheme），说明了访问资源所使用的协议类型。这部分通常就是 HTTP 协议（http://）。 第二部分给出了服务器的因特网地址（比如，www.joes-hardware.com）。 其余部分指定了 Web 服务器上的某个资源（比如，/specials/saw-blade.gif）。 现在，几乎所有的 URI 都是 URL。 1.3.4. URNURI 的第二种形式就是统一资源名（URN）。URN 是作为特定内容的唯一名称使用的，与目前的资源所在地无关。使用这些与位置无关的 URN，就可以将资源四处搬移。通过 URN，还可以用同一个名字通过多种网络访问协议来访问资源。 比如，不论因特网标准文档 RFC 2141 位于何处（甚至可以将其复制到多个地方），都可以用下列 URN 来命名它： urn:ietf:rfc:2141 URN 仍然处于试验阶段，还未大范围使用。为了更有效地工作，URN 需要一个支撑架构来解析资源的位置。而此类架构的缺乏也延缓了其被采用的进度。但 URN 确实为未来发展作出了一些令人兴奋的承诺。我们将在第 2 章较为详细地讨论 URN，而本书的其余部分讨论的基本上都是 URL。 除非特殊说明，否则本书的其余部分都会使用约定的术语，并且会不加区别地使用 URI 和 URL。","categories":[],"tags":[]},{"title":"【转】蓝绿部署、金丝雀发布（灰度发布）、A/B测试的准确定义","slug":"deploy-enviroment-words","date":"2018-12-21T09:30:17.000Z","updated":"2020-11-28T08:49:18.050Z","comments":true,"path":"2018/12/21/deploy-enviroment-words/","link":"","permalink":"https://rovast.github.io/2018/12/21/deploy-enviroment-words/","excerpt":"","text":"原文标题：蓝绿部署、金丝雀发布（灰度发布）、A/B测试的准确定义原文链接：https://www.lijiaocn.com/%E6%96%B9%E6%B3%95/2018/10/23/devops-blue-green-deployment-ab-test-canary.html 说明蓝绿部署、A/B测试、金丝雀发布，以及灰度发布、流量切分等，经常被混为一谈，影响沟通效率。 根本原因是这些名词经常出现，人们耳熟能详能够熟练地谈起，对这些术语的理解却没有达成一致。 下面是从Blue-green Deployments, A/B Testing, and Canary Releases中整理出来的定义。 蓝绿部署蓝绿部署的目的是减少发布时的中断时间、能够快速撤回发布。 It’s basically a technique for releasing your application in a predictable manner with an goal of reducing any downtime associated with a release. It’s a quick way to prime your app before releasing, and also quickly roll back if you find issues. 蓝绿部署中，一共有两套系统：一套是正在提供服务系统，标记为“绿色”；另一套是准备发布的系统，标记为“蓝色”。两套系统都是功能完善的，并且正在运行的系统，只是系统版本和对外服务情况不同。 最初，没有任何系统，没有蓝绿之分。 然后，第一套系统开发完成，直接上线，这个过程只有一个系统，也没有蓝绿之分。 后来，开发了新版本，要用新版本替换线上的旧版本，在线上的系统之外，搭建了一个使用新版本代码的全新系统。 这时候，一共有两套系统在运行，正在对外提供服务的老系统是绿色系统，新部署的系统是蓝色系统。 蓝色系统不对外提供服务，用来做啥？ 用来做发布前测试，测试过程中发现任何问题，可以直接在蓝色系统上修改，不干扰用户正在使用的系统。（注意，两套系统没有耦合的时候才能百分百保证不干扰） 蓝色系统经过反复的测试、修改、验证，确定达到上线标准之后，直接将用户切换到蓝色系统： 切换后的一段时间内，依旧是蓝绿两套系统并存，但是用户访问的已经是蓝色系统。这段时间内观察蓝色系统（新系统）工作状态，如果出现问题，直接切换回绿色系统。 当确信对外提供服务的蓝色系统工作正常，不对外提供服务的绿色系统已经不再需要的时候，蓝色系统正式成为对外提供服务系统，成为新的绿色系统。 原先的绿色系统可以销毁，将资源释放出来，用于部署下一个蓝色系统。 蓝绿部署只是上线策略中的一种，它不是可以应对所有情况的万能方案。 蓝绿部署能够简单快捷实施的前提假设是目标系统是非常内聚的，如果目标系统相当复杂，那么如何切换、两套系统的数据是否需要以及如何同步等，都需要仔细考虑。 BlueGreenDeployment中给出的一张图特别形象： 金丝雀发布金丝雀发布（Canary）也是一种发布策略，和国内常说的灰度发布是同一类策略。 蓝绿部署是准备两套系统，在两套系统之间进行切换，金丝雀策略是只有一套系统，逐渐替换这套系统。 譬如说，目标系统是一组无状态的Web服务器，但是数量非常多，假设有一万台。 这时候，蓝绿部署就不能用了，因为你不可能申请一万台服务器专门用来部署蓝色系统（在蓝绿部署的定义中，蓝色的系统要能够承接所有访问）。 可以想到的一个方法是： 只准备几台服务器，在上面部署新版本的系统并测试验证。测试通过之后，担心出现意外，还不敢立即更新所有的服务器。 先将线上的一万台服务器中的10台更新为最新的系统，然后观察验证。确认没有异常之后，再将剩余的所有服务器更新。 这个方法就是金丝雀发布。 实际操作中还可以做更多控制，譬如说，给最初更新的10台服务器设置较低的权重、控制发送给这10台服务器的请求数，然后逐渐提高权重、增加请求数。 这个控制叫做“流量切分”，既可以用于金丝雀发布，也可以用于后面的A/B测试。 蓝绿部署和金丝雀发布是两种发布策略，都不是万能的。有时候两者都可以使用，有时候只能用其中一种。 上面的例子中可以用金丝雀，不能用蓝绿，那么什么时候可以用蓝绿，不能用金丝雀呢？整个系统只有一台服务器的时候。 A/B测试首先需要明确的是，A/B测试和蓝绿部署以及金丝雀，完全是两回事。 蓝绿部署和金丝雀是发布策略，目标是确保新上线的系统稳定，关注的是新系统的BUG、隐患。 A/B测试是效果测试，同一时间有多个版本的服务对外服务，这些服务都是经过足够测试，达到了上线标准的服务，有差异但是没有新旧之分（它们上线时可能采用了蓝绿部署的方式）。 A/B测试关注的是不同版本的服务的实际效果，譬如说转化率、订单情况等。 A/B测试时，线上同时运行多个版本的服务，这些服务通常会有一些体验上的差异，譬如说页面样式、颜色、操作流程不同。相关人员通过分析各个版本服务的实际效果，选出效果最好的版本。 在A/B测试中，需要能够控制流量的分配，譬如说，为A版本分配10%的流量，为B版本分配10%的流量，为C版本分配80%的流量。 参考 Blue-green Deployments, A/B Testing, and Canary Releases BlueGreenDeployment","categories":[{"name":"流程","slug":"流程","permalink":"https://rovast.github.io/categories/流程/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://rovast.github.io/tags/转载/"}]},{"title":"初探laravel-facade实现","slug":"how-laravel-facade-works","date":"2018-12-21T09:13:24.000Z","updated":"2020-11-28T08:49:18.064Z","comments":true,"path":"2018/12/21/how-laravel-facade-works/","link":"","permalink":"https://rovast.github.io/2018/12/21/how-laravel-facade-works/","excerpt":"","text":"Facade 门面模式定义： 门面模式（Facade）又称外观模式，用于为子系统中的一组接口提供一个一致的界面。门面模式定义了一个高层接口，这个接口使得子系统更加容易使用：引入门面角色之后，用户只需要直接与门面角色交互，用户与子系统之间的复杂关系由门面角色来实现，从而降低了系统的耦合度。 在 laravel 中，使用 facade 可以提高很高的便利性，比如我们使用缓存，可用下述代码实现 12345use Illuminate\\Support\\Facades\\Cache;Route::get('/cache', function () &#123; return Cache::get('key');&#125;); 那么，在 laravel 中，是如何做到这个的呢？为什么可以直接使用静态调用呢？以 cache 为例，我们一探究竟。 调用方代码 12345use Illuminate\\Support\\Facades\\Cache;Route::get('/cache', function () &#123; return Cache::get('key');&#125;); 我们再看看 vendor/laravel/framework/src/Illuminate/Support/Facades/Cache.php 代码 1234567891011121314namespace Illuminate\\Support\\Facades;class Cache extends Facade&#123; /** * Get the registered name of the component. * * @return string */ protected static function getFacadeAccessor() &#123; return 'cache'; &#125;&#125; 我们发现继承了 vendor/laravel/framework/src/Illuminate/Support/Facades/Facade.php 的 abstract class Facade，并且重写了 getFacadeAccessor()。 接下来，我们摘录 abstract class Facade 中几处有意思的代码，注意看我的注释：123456789101112131415161718192021222324252627282930313233343536namespace Illuminate\\Support\\Facades;abstract class Facade&#123; // 当调用 Cache::get() 时，由于 Facade 类本身没有 get 这个静态方法，所以会执行 __callStatic public static function __callStatic($method, $args) &#123; // 看 Illuminate\\Support\\Facades\\Cache 中实现的，就是返回了 cache 字符串，其实就是服务名称 $instance = static::getFacadeRoot(); if (! $instance) &#123; throw new RuntimeException('A facade root has not been set.'); &#125; // 执行服务对应的方法，即： vendor/laravel/framework/src/Illuminate/Cache/CacheManager.php 的方法 return $instance-&gt;$method(...$args); &#125; public static function getFacadeRoot() &#123; return static::resolveFacadeInstance(static::getFacadeAccessor()); &#125; protected static function resolveFacadeInstance($name) &#123; if (is_object($name)) &#123; return $name; &#125; if (isset(static::$resolvedInstance[$name])) &#123; return static::$resolvedInstance[$name]; &#125; return static::$resolvedInstance[$name] = static::$app[$name]; &#125;&#125; 这下思路一下子简单了：使用 Facade 时，其实就是直接调用的相关服务的某个方法。只不过写法上是静态方法，然后继承了基础的 vendor/laravel/framework/src/Illuminate/Support/Facades/Facade.php，由于静态方法不存在，自动调用魔术方法 __callStatic，在魔术方法中进行了查找对应服务，并执行对应的方法。 看下图中蓝色标注的部分，像不像个代理？其实在 laravel 官方文档 中正有此介绍 Facades provide a “static” interface to classes that are available in the application’s service container. Laravel ships with many facades which provide access to almost all of Laravel’s features. Laravel facades serve as “static proxies” to underlying classes in the service container, providing the benefit of a terse, expressive syntax while maintaining more testability and flexibility than traditional static methods","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"laravel","slug":"laravel","permalink":"https://rovast.github.io/tags/laravel/"}]},{"title":"【转】不要自称是程序员，我十多年的 IT 职场总结","slug":"dont-call-yourself-a-programmer","date":"2018-12-21T08:11:24.000Z","updated":"2020-11-28T08:49:18.050Z","comments":true,"path":"2018/12/21/dont-call-yourself-a-programmer/","link":"","permalink":"https://rovast.github.io/2018/12/21/dont-call-yourself-a-programmer/","excerpt":"","text":"原文标题：《不要自称是程序员，我十多年的 IT 职场总结》原文链接：https://mp.weixin.qq.com/s?__biz=MjM5OTA1MDUyMA==&amp;mid=2655438297&amp;idx=1&amp;sn=708c99f61f9843e9fd32b8495e42aac5&amp;chksm 如果我可以给每个工程教育增加一门课，它不会涉及编译器、门电路或是时间复杂度，而是一门介绍行业现实的入门课，因为没人教过这些，所以我们遭受了很多不必要的痛苦和折磨。 希望本文可以成为年轻工程师职业生涯的自述文档（ readme.txt）。目的是填补“现实世界”运作方式与教育之间的空白，并让你快乐起来。我从“一个还算聪明，但是不自信、毫无商业经验的工程师”，耗费了十年多的时间，经受了很多的苦难，才总结出这些经验之谈。我不会把这些当成金科玉律，但希望它可以告诉你一些大学职业中心没有告诉你的事情。 90% 的编程工作来自内部软件 经济入门课程就说过：任何东西（包括你在内）的价值都取决于供求关系。首先让我们来谈谈需求方面。大多数软件不是装在盒子里卖的，也不可能从互联网上得到或者从 App Store 下载。大多数软件都是公司内部的应用程序，它们通常令人厌倦，缺乏长远考虑。但却服务于全球经济的方方面面，比如跟踪费用、优化运费、协助会计部门做预算、帮助设计新的工具、计算保单价格和识别恶意订单等等。软件解决内部问题。软件总是用来解决内部的问题，尽管这些问题往往是令人乏味和没有什么技术含量的。比如以一个内部出差费用的申报表为例。假设一家公司有 2000 名雇员，和在纸面上处理费用相比，一年可以节省 5000 个工时（平均满负荷下的成本是每小时 50 美元），一年一共可以节省 25 万美元。这家公司不在乎这个申报表是不是世上最简单的 CRUD（即为 Create、Read、Update、Delete 等四项基本数据库操作）应用程序 ，只在乎可以节省公司的成本还是可以创造额外的收入。 当你想到软件时，会认为公司开发的软件都是提供给客户使用的。但实际上你不太可能在这样的公司工作。就算你在这样的公司工作，也只有极少数程序员直接编写面向外部客户的软件。 别人雇用你的目的，是让你创造价值，而不是让你编程 公司总是出于非理性和政治的原因做事情（请看下面），但他们聚在一起做事情的主要目的是为了增加收入或者降低成本。运行良好的业务往往得益于在某一方面非常擅长的人。（可以，但不一定非要这样做。）决定再多招聘一名工程师的人，不是因为他们喜欢有一个 Geek 在房间里，只是因为增加这个 Geek 可以完成一个项目（或多个项目），增加收入和降低成本。开发优美的软件、解决复杂的技术问题、编写没有 bug 的代码、使用迷人的编程语言，这些统统不是目的。唯一的目的就是增加收入、降低成本。 彼得·德鲁克提出了利润中心和成本中心的概念。利润中心是一个组织中用来赚钱的：律师事务所的合伙人、企业级软件公司的销售以及华尔街的大鳄们等等。成本中心，就是剩下的人。人人都想进入利润中心，因为这样会带来更高的工资、更多的尊敬以及更多获得好处的机会。这并不难：一个聪明的中学生，只要看过一段关于业务的描述，通常就可以确认利润中心在哪里。如果你想在那里工作，就要为之努力。如果你不能这样，要么在其他地方工作，要么先进入公司再转换工作。 彼得·德鲁克 Peter Drucker，现代管理学之父，你可能没有听说过他，但他是老板们中的先知。 通常工程师的成本都非常高，这会触发 MBA 优化成本的本能。于是就有了类似外包这样很棒的想法，“用一个低工资国家的成本中心，替换掉这些相当昂贵的成本中心，这些昂贵的成本中心并不能给我们带来什么。”（提示：如果你读到这个指导后面的部分，你完全可以忽略外包，不用把它当作职业生涯中的威胁。）没有人会外包利润中心。只有在 MBA 开的玩笑中才会发生这样的事情。这就好比建议用软盘保存一堆副本，用来代替源码控制系统。 不要自称为程序员 “程序员”听上去“只会在一台复杂的机器上干一些难懂的事情，而且成本奇高。” 如果你自称为程序员，有些人已经在想办法把你解雇掉。有一家公司叫 Salesforce，工程师熟知他们所提出的“软件即服务”（SaaS，Software as a Services）。他们的口号就是“没有软件”，他们向实际客户灌输这样的观点，“你知道你们内部的程序员在做什么吗 ？如果你使用 Saleforce，你可以解雇一半的程序员，并把节省下来的一部分钱作为奖金放进你自己的口袋。”（顺便说一句，这样没有错。你效力的公司会让别人失业。如果你认为这不公平，回到学校爱干嘛干嘛。） 正确的做法是，你应该把自己描述成与增加收入、降低成本有关系的人。如果你还没有机会做到这些，应该说明你有能力去增加收入或降低成本，或者有这样的想法。 很多拿着不错薪水的编码专家，并不把他们自己形容成是以码代码谋生的。华尔街的宽客就是第一个和最著名的例子： 和那些没有帮助的人相比，他们使用计算机和数学作为杠杆，可以更快更好地做出后果严重的决定，这些决定可笑的地方在于“我们公司赚了数十亿美元。” （译者注：对金融衍生品的讽刺？）年景好的时候，成功宽客一年的奖金，要比同样才智的工程师干十年或一辈子赚的钱还要来得多。 宽客（quant）：指一群靠数学模型分析金融市场的物理学家和数学家。他们相信数学的精确性是分析最复杂的人类活动的基础，还曾用分析神经系统的数学技巧来赚钱。也被称为金融工程师，他们将自己戏称为“矿工”。 同样就算你认为 Google 看上去是一家对程序员友好的公司，那里有程序员，也有一些人对 AdWords 点击率 提升 1% 都相当关注。（提示：证明价值是数十亿美元。）我最近偶然发现一个家伙的网页，他上面的履历是这样写的，“编写了后台计费代码，Google公司 97% 的收入，与我的代码有关”。他现在是一个天使投资人（“有钱人”另一个礼貌点的称呼）。 不要受制于你的技术栈 我最近在 Twitter 上问了一个问题，对于职业生涯，年轻工程师想知道些什么。很多人都问到如何学习某某语言或者协议栈。这些不重要，请往下面看。 Java 程序员比 .Net 程序员更能赚钱吗？任何把他们自己限定成 Java 或者 .Net 程序员的人已经是卢瑟了，因为首先他们是程序员（理由参考上面），其次这种限定使得他们自动被排除在世界上大多数编程工作之外。现实生活中，学会一种新语言只需要几个星期，然后再过半年到一年，你就会变成老手。那时，根本没人在乎你以前用什么语言。早在 2010 年 3 月，我还开发了Java Web 应用程序的后台。相信我，没有人在乎那些。如果一家 Python 公司正在寻找一位技术专家为他们赚一大笔钱，虽然事实上我没有写过一行 Python 代码，但这也阻止不了我。 天才程序员是很少的 —— 可是需要天才程序员的工作机会却很多很多 —— 大多数场合都是需求远远大于供给。Matasono 公司的人都在使用 Ruby。如果你不会，只要你是一个优 秀工程师，他们也会立刻录用你。（重复一遍，所谓”优秀工程师”，就是你的履历上有一连串增加收入、降低成本的记录。）Frog Creek 中大多数人都使用 Microsoft 的协议栈。我甚至不会拼写 ASP.NET，但他们还是会雇我。 有些公司的人事部门，会根据某个关键词过滤简历。虽然这样的公司根本不值得去，但是如果你真的想过这一关，也很容易：投入几个晚上和周末，在你当前的项目中设法用到这个关键词，然后再把它写进简历就行了。想在一家 .NET 公司累积 Ruby 的经验？用 Ruby 完成一个一次性的项目，你就是一个专业的 Ruby 程序员 —— 你编写了 Ruby 代码还赚了钱。（你乐了吧？我在一家 Java 公司干过类似的事。有个一次性的项目给公司赚了 3 万美元。不出所料，我老板乐坏了，甚至都没有问过要交付什么。） 同事和老板通常不是你的朋友 你有很长时间和同事们在一起。最后你可能会和他们中的一些人成为很亲密的朋友，但通常三年内你们就会分开，除了保持友好的关系外，你不会再邀请他们出去共进晚餐。他们也将同样对待你。任何见过你的人都会认为你是个好人 —— 这是道德层面的事情，对你的人际关系有所帮助 —— 但是不能由此妄想所有人都是你的朋友。 比如在一个面试中，你和一个 28 岁的友善的家伙相谈甚欢，让你感觉他就是几年后的你，但他还是处在一个交易中。你不是他的朋友，你只是一个工业流程的输入，他会为公司用最少的钱去雇你。他用魔兽世界的话题跟你套近乎，其实是在建立一种职业关系，他会尝试（当然是绝对符合职业道德地）做那些你真正朋友不会对你做的事情。比如试图说服你接受几千美元的薪水，或者让你心怀内疚得在公司里待更长的时间，而你原本可以和真正的朋友在一起。你还有其他一些友好和有职业道德的同事 —— 他们建议的东西会损害你的利益，从“你做的那个项目里面可有我的功劳”（措辞上可能不会有这么多单词）到“我们应该做这件事情，它对我的职业发展有帮助，而不是你的。” 当这些事情发生时，不要感到惊讶。 彻底高估了竞争对手的平均水平 实际上，很多被雇的高级工程师不会实现 FizzBuzz 序列。读到这里你泪流满面了吧。这里有个关键点：对于那些公司而言，你已经足够好了，但你自己却不这么认为。他们会雇用牛人，但他们也会雇用普通人。 “阅读招聘广告→发送简历→参加面试→拿到Offer” 这个不是被录用的常见途径，只是个意外。 大多数职位从来都没有对外公布过，就像在市面上很少能找到不错的候选人一样（看这里）。在大家一起喝啤酒时，这个职位的信息候就传播出去了，有时候还需要通过邮件撮合一下。公司里做决定的人要找一个人。他告诉他的朋友和有业务往来的人。他们中的一个人刚好知道这么一个人 —— 家庭成员、大学室友、会议上认识的某个人、以前的同事之类的。做了一些介绍，大家见了个面，这个工作就谈得八九不离十了。接下来简历、人力部门、正式录用之类的开始进场了。 这可能是你真正想得到的工作。“一个成功创业公司的首位员工”这对很多 Geek 来说有一定的吸引力，但事实上他们也找不到地方去发求职信给人力部门，部分原因是两个人的创业公司也不太需要成立人力部门。（备注：你可能不想成为创业公司的首位员工，而是最后一位合伙人。）想在 Google 谋得一份工作？如果Google 里面有人喜欢你，他们有一个正式的流程可以助你一臂之力。（如果这个 Google 的人很喜欢你，有很多非正式的方法可以缩短这个流程。比如：买下你工作的公司。当有很多钱的时候，解决问题也就有很多有趣的选择。） 私底下雇用有很多原因。一个原因是工作机会公开后会收到上百份简历（特别在这种经济环境下），但很多人其实并不适合这个职位。另一个原因是其他公司在招聘方面的惨痛经历，除非你对应聘者很了解，不然你很可能招进一个连 FizzBuzz 都搞不定的人。 社交网络（人际关系）不仅仅是 TCP 数据包 社交网络/关系网有两个意义，一是遇到在某些方面可以为你提供帮助的人（反过来也一样），二是给他们留下良好的影响。 有很多场合可以结交其他人。行业里举办的活动就是一个不错的选择，比如会议或者学术座谈会。用户组是另外一个选择，用户组里的人和行业活动上的人完全不同，而且有用得多。 尽量帮助别人，这是正确的做法，人们会很在意那些过去帮助过他们的人。如果你帮不了某人，但知道谁可以提供帮助，请介绍他们相互认识。如果你做得足够好，双方都会感激你并且愿意在以后的日子里为你提供帮助。 你可以在互联网上结识其他人（天呐，你能吗？），但是惯常思维让我们觉得面对面的交流会更好一些。我曾经在网上结识过不少牛人，过不了多久我就会去拜访本尊。即使通过网上的交流彼此了解颇深，甚至“因为对方的一个建议发了财”，见个面握个手也会让关系更进一步。发博客和加入类似 HN （译者注：HackNews）这种业界灌水区是很有必要的，但要通过它们能让大家见面交流。 学术界和现实世界不一样 你的 GPA 分数（译者注：平均分数，Grade-Point Average）不重要（跨国广告公司是一个例外）。它很大程度只决定你的简历是否会被选入工作面试阶段。如果你读了本文后面的部分，你就会理解简历不是获得面试的主要方式，不要耗费精力去改善那些原本就已经不错的东西（无论GPA分数是 3.96 还是 3.8 ，你获得的工作面试都差不多），或者你根本就不需要（因为你邀请到正确的人出去喝咖啡，而获得工作面试）。 你的主修科目和辅修科目也不重要。业界中的大多数决策者就算想尝试，也不能辨别计算机专业和数学专业的差别。我曾经有一次伤心到了落泪，因为一个学术上的小差错，让我获得主修计算机科学学士的能力倍受质疑，我的指导老师告诉我它比计算机科学学士更为有名。学术上就在乎这些区别。但是现实世界不会这样。 你的教授可能会理解学术就业市场是如何运作的（小插曲：他们在工程上方面，低效得可笑。在英语表述上，混乱到常人无法理解），但他们还常常如唐吉珂德般幻想着真实的世界。比如，他们会强迫你追求更高的学位，因为从他们看来这是一个很棒的主意，而且他们喜欢有苦力（只为吃一碗拉面的苦力）进行学术研究。在你所在的领域，相关研究人员的市价都是 80~100k+++ 美元。足够买很多拉面了。（译者注：估计作者在大学期间，没少给老板干活） 主管我研究项目的教授在实验室里面给我安排了一个座位，免了学费，还给了我总共 12000 美元奖学金，但我要保证替他工作 4-6 年。只有当你刚从一个低工资的国家移民过来，并需要有人和政府交涉发给你签证的时候，这才是一个不错的交易。 如果你真的喜欢大学里的氛围，这的确很棒。无论何时，无论哪一所美国大学，无论其中的哪一座建筑，你都可以背着背包走进其中。在学术界工作，背包还是买得起的。你也可以成为业界的精神领袖 —— 享受更少的政治和更好的待遇。只要你愿意，你甚至可以在杂志上发表文章。（当你从学术中的乌烟瘴气解脱之后，你可能会质疑对个人或社会而言，在杂志上发表一篇文章，是不是比写一个给聪明人看的博客很重要。） 工程师赚多少钱？ 错误的问题。正确的问题应该是“工程师在这份工作中，平时都做什么？”，薪水是众多杠杆之一，人们可以用它来激励你。没有多少帮助的答案是，“工作到处都是。” 通常，大公司要比创业公司好一些（包含金钱，福利等）。能够创造高感知价值的工程师要比普通工程师赚得多。资深工程师要比初级工程师赚得多。高成本领域的人要比低成本的赚得多。熟练掌握谈判能力的人要比其他人赚得多。 我们的文化传统不允许询问薪水。但这并不普遍。在其他文化中，非常合适在专业背景下讨论钱。（如果你是一个日本的中产阶级，你理所当然得要在第二次见面的时候，告诉别人你拿的薪水，比如你足球俱乐部的人，或者给你做寿司的家伙。如果你拥有一家公司，对你的资产可能会守口如瓶，但你还是会频繁和毫不尴尬地谈论雇员们的薪水，就像程序员讨论编译器一样。）如果我是一名马克思主义学者或者一名阴谋理论家，会认为美国中产阶级的这一套文化是为雇主而特别设计的，但却损害了雇员的利益。前面关于任何特定目标雇主的薪水讨论，你应该和工作在相同情况的人聊一下，问问他们这个职位的薪水范围。此时此刻你就可以在网上找到这些人。（可以借助LinkedIn，Facebook，Twitter和没有图形化数据库的社交网络。） 无论如何，工程师通常得到一系列福利。在美国值得担心的是，健康保险（通常你会得到，你的雇主会支付大部分或所有的花销）和退休计划，换种说法就是“我们会为你的 401K 计划交纳薪水的 X% 。” 这个数值很好计算：薪水的 X% 。（这是免费的，所以总是要为你的个人退休账号（IRA，Individual Retirement Account）找到最适合的雇主。把这些钱放到指数基金，然后40年内都不要想它们。） 伯乐在线补注：401K 计划也称401K 条款，401K 计划始于 20 世纪 80 年代初，是一种由雇员、雇主共同缴费建立起来的完全基金式的养老保险制度，是指美国 1978 年《国内税收法》新增的第401条k项条款的规定，1979 年得到法律认可，1981 年又追加了实施规则，20 世纪 90 年代迅速发展，逐渐取代了传统的社会保障体系，成为美国诸多雇主首选的社会保障计划。适用于私人盈利性公司。 还有其他福利，类似“免费汽水”、“提供午餐”、“免费编程书籍”等。这些只是社交信号而已。举一个我在工作中如何做的具体例子，当我说要给你买汽水时，说明我想让谁为我工作和我会如何对待他们。（这也就是说“我喜欢转移年轻不成熟工程师的注意力，通过买20美分一瓶的汽水让这个工作变得有趣，鼓励他们损害自己的健康的同时，还为我自己节省了成千上万的报酬。 ” 我真的喜欢汽水）读取社交信号并予以适当的反应—— 某个人发出信号，比如愿为雇员教育买单的公司很可能是一家值得效力的好公司 —— 不要为这些蝇头小利，就放弃大量的报酬…… 如何提高求职时的谈判能力？ 虽然这可以另写一篇文章，这里我简要地说一下： 1）记住你不是在展示编程技巧或者漂亮的脸蛋，而是在推销某种商业需求（增加收入或降低成本）的解决方案。 2）面试时，要有自信，要平等的对话。你的对手可能也在做同样的事情。你要的是一个互利的录用合同，不要每次对方提出要求，你都说 Yes。 3）雇主可能会问”你的上一份工资是多少”，他们其实在说”给我一个理由，压低你的报酬”。你要想好如何适当地回答这个问题。 4）要讨价还价。这里不仅仅指钱，还指其它你关心的方面。如果你无法要求更高的薪水，那就试着要求更多的假期。 5）在对方决定录用你以后，才开始讨论薪水。因为那时，他们已经在你身上，投入了大量的时间和金钱。这个时候他们说“不行，我们不能成交”会浪费很大的成本，他们会觉得一些小问题已经不值得再纠缠了，比如每年的工资增加几千元。 6）多读书吧。很多人写过谈判方面的书。我喜欢《Getting To Yes | 谈判力》这本书。有一点令人不解的是，就整个职业生涯而言，谈判技巧值得每年花费数千美元，但工程师们却认为针对这学习方面很疯狂，他们宁愿去学习感兴趣技术的细枝末节。 如何评估股权： 用 d100 摇骰子。（对极客而言，不知道是什么？抱歉，那么rand（100）好了） 0～70：你的股权不值钱。 71～94：你的股权值一大笔钱，足以让你放弃大公司优厚的薪水和良好的福利，为这家创业公司工作。 95～99：你的股权将改变你的人生。你倒是不会觉得自己多么有富有 —— 因为还有人比你更有钱，很多过去几年和你一起共事的人会比你富有得多 —— 不过你的家人倒不会因为你入错了行（挣不了钱）这种事情再对你指责抱怨了。 100：你将为下一个 Google 工作，会富得超出想象。恭喜你。 细心的读者会注意到，事实上 100 不会出现在 d100 和 rand(100) 里。 为什么不看好股权呢？ 因为你过分高估了创业公司成功的可能性，以及创业公司成功后你能分到的部分。阅读 Hacker News 或者 Venture Hacks 上面关于股权稀释和清算优先权的讨论，记住有很多人对交易谈判的理解程度，超过你对编程的理解。 创业公司是否适合应届毕业生？ 如果你一毕业就加入创业公司，最可能的结果是，接下来几年你都工作得非常辛苦，然后公司悲惨地失败了，你失业了，不得不又去另一家创业公司工作。如果你真的想去创业公司，应该首先找一家大公司干上两年，攒一点钱，积累一些经验，然后精心挑选后再去创业公司。 在创业公司工作，一般情况下，你遇到的都是创业者。他们大多数人没有能力在两年后雇佣你；而在大公司工作，你遇到的都是其他大公司的人，他们中很多人将来有能力雇用你或者帮你介绍工作。 在创业公司工作是否值得推荐？ 选择创业公司，就是选择一条职业道路，但更是一种生活方式。类似在投行或学术界工作，它们是三种截然不同的生活方式。他们推荐创业公司，实际上是在推荐一种你感兴趣的生活方式。如果你确实喜欢这种生活方式，那就尽情地疯吧。如果你没那么喜欢，老实说，你其实有很多的选择。你在大公司里也可以得到它们。比如，你想钻研最新的技术，又想还能5点半准时回家照顾孩子，你在许许多多大公司里可以做到这一点。 （真的。如果为他们创造了价值，他们一定会投资的。他们会投资很多 CRUD 应用程序，不过然后开始创业。 他们只是比大多数大公司更善于营销 CRUD 应用。《社交网络》电影前一个小时就在讲做一个看着挺酷的 CRUD 应用，第二个小时就像 Lifetime 频道的电视剧，就是一场不太可能涉及两个异性恋男人的之间离婚。） 编注：Lifetime 是迪士尼旗下专门为女性所开的电视台。 沟通是最重要的职业技能 记住工程师被雇用不是编写程序，而是为了创造价值。所以你要让人们相信你能创造价值，这是帮助你找到工作的最重要的能力。这种能力与你真的能创造多少价值，实际上联系不是很紧密。 我认识的一些非常优秀的程序员，他们往往不善于表达。因此，别人不是不想与他们一起工作，就是低估了他们的价值。相反地，如果你看上去很会编程，并且能说会道，而且文笔也好，那别人就会真的这样看待你。 （曾经有一次我这样形容自己的编程能力，“中等偏下”。我已经知道我对能力分布有一个彻底扭曲的印象，编程能力不是人们真得想要优化的，我对谦虚也不感兴趣。现在如果你问我是多棒的程序员，我会开始和你讲故事，我编程的系统如何帮助数以百万计的孩子学会了阅读，或确定为公司赚了数百万美元。关于我在钟形曲线什么位置的问题不会影响到任何人，所以为什么要担心它？） 沟通是一种能力，越练越好。一个关键的亚技能就是能够简明快速和自信满满地解释，你如何为那些领域之外的人和之前没有理由爱你的人，创造了价值。如果当你尝试这样做，发现技术术语不断出现（“通过优化索引，第 99 个百分位的查询时间减少了200毫秒……”），把它们去掉再试一次。你应该能够通过适当的抽象，向一个聪明的 8 岁小朋友，你公司的CFO或者其他专业的程序员，解释明白你做的事情。 你通常被称为「企业销售」或者其他在工程上要避免的 企业销售去一家公司，尝试说服他们花几十万或几百万购买一套能提高收入或降低成本的系统。每一次工作面试都是一次企业销售。政治、人际关系和沟通技巧相当重要，技术在现实中并不是那么重要。 当你和同事们开会并试图说服他们采纳你的建议，你就是在进行企业销售。如果你的工作就是要把事情搞定，你关键的工作就是说服人们完成任务。要努力把它做好。要能够透过便签、邮件、交谈、会议和 PPT（适当的时候） 等进行有效地沟通。要理解如何把一个技术创新推向市场。为了追求商业目的，有时要在技术上有所取舍，而且这么做是正确的。 工作中不必谦虚 很多工程师都过于自信（我本人就是这样：））。也有很多人成长的地方，在文化上会认为谦虚是个人成就的一部分。美国企业基本上不认为谦虚对个人成就有什么价值。在面试中、与他人互动和生活中，正确的态度应该是“克制、自信的专业精神。” 如果你是团队的一员，团队的努力取得了成功，“我把这一切都归功于我的团队”不能切中要点，除非你想让每个人都知道你故作谦虚。试试这个“很荣幸可以用我的专长带领并帮助我的团队取得成功”。站在镜子前面重复上千次，直到你绷着脸说出这些。你可能会觉得夸大了你的成就。别理它。有着三明治大师头衔的人声称领导优化了产品，这显然是夸大其词。你是一个工程师。你神奇的工作让人们生活得更好。如果你负责数据库，特别当一个涉及到人的重要项目，你所领导的数据库工作，对项目的成功绝对是至关重要的。这就是游戏规则。如果你感觉不好，那你就像在棒球中对偷垒感觉糟糕的击球手：你不是道德优越，你只是玩得太差。 所有商业的决定最终是由一个或者一些人所决定的，并不是规则或算法 人类就是人类。社会协作（social grooming，原意是动物界相互梳理毛发，抓虱子，引申为社会协作）是一个很重要的能力。因为是朋友，人们通常会采纳朋友们的建议，即使事实上其它建议可能更好。人们通常对分享面包的人表示友好。（有一本商业书籍叫做《别独自用餐》。它值得一读，但标题和内容是相反的。）人们通常喜欢那些像他们一样的人，而不喜欢不像他们的人。（这可以是很好的、中性的或惹人厌恶的。利用它盈利的第一步是接受它。） 事实上着装也是比较重要的，人们非常容易被得体的穿着、专业的形象和自信的讲话所被蒙蔽。你的西装可能和一台电脑显示器一样贵。你用它的机会千载难逢，但一旦你需要它的时候，你会非常非常高兴。相信我的话，如果我穿日常休闲服饰去市政厅，我会被当作一个倒霉尴尬的二十多岁小伙，如果我穿着西装，我会被当作跨国公司的CEO。虽然实际上我一个二十多岁窘迫的跨国公司 CEO，但当我需要从官方获得优待时，我会选择西装革履。 （熟悉我公司的人，可能会反对我把它形容成一个跨国公司，因为它不是谈话中大多数人认为的“跨国公司”。抱歉， 这只是为了模拟一个简单的谈话。如果你认为人们发现被操纵时会很生气，好吧，也有些人非常讨厌西装。这并不意味着西装毫无价值。要注意当时的环境。顺便说一句，如果另一个答案是移民局驱逐你，如实回答才是最佳选择。） 到最后，事业不能决定生活的快乐 和老人们聊一聊，或者相信社会学者们吧，他们都认为：家庭、信仰、爱好等等这些东西，会比金钱和事业上的成就更容易带来幸福。妥善调整一下吧。虽然当下你的职业很重要，看上去是你生活中最重要的事情，但是你不会一直这样认为。我们工作是为了生活，而不是为了工作而活着","categories":[{"name":"随想","slug":"随想","permalink":"https://rovast.github.io/categories/随想/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://rovast.github.io/tags/转载/"}]},{"title":"useful-docker-links","slug":"useful-docker-links","date":"2018-12-21T01:56:18.000Z","updated":"2020-11-28T08:49:18.089Z","comments":true,"path":"2018/12/21/useful-docker-links/","link":"","permalink":"https://rovast.github.io/2018/12/21/useful-docker-links/","excerpt":"","text":"自动构建 Set up Automated builds 指定了 dockerfile 后，docker hub 会根据 dockerfile 自动构建。以后你更新了 dockerfile 后，也会触发自动构建（如果你配置了相关设置）。","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://rovast.github.io/tags/docker/"}]},{"title":"soar 启发规则汇总 && 常见 MySQL 优化案例","slug":"soar-heuristic-list","date":"2018-12-20T07:43:49.000Z","updated":"2020-11-28T08:49:18.082Z","comments":true,"path":"2018/12/20/soar-heuristic-list/","link":"","permalink":"https://rovast.github.io/2018/12/20/soar-heuristic-list/","excerpt":"","text":"摘自： https://github.com/XiaoMi/soar/blob/master/doc/heuristic.md 这是小米 soar 的默认启发规则汇总，也是 DBA 多年精华总结。熟读各个案例，对于一般的 MySQL 优化有很高的帮助。如果你不喜欢太理论的东西，或者没时间去深入，举一反三学习也未尝不可。 启发式规则建议建议使用 AS 关键字显示声明一个别名 Item:ALI.001 Severity:L0 Content:在列或表别名(如”tbl AS alias”)中, 明确使用 AS 关键字比隐含别名(如”tbl alias”)更易懂。 Case: 1select name from tbl t1 where id &lt; 1000 不建议给列通配符’*‘设置别名 Item:ALI.002 Severity:L8 Content:例: “SELECT tbl.* col1, col2”上面这条 SQL 给列通配符设置了别名，这样的SQL可能存在逻辑错误。您可能意在查询 col1, 但是代替它的是重命名的是 tbl 的最后一列。 Case: 1select tbl.* as c1,c2,c3 from tbl where id &lt; 1000 别名不要与表或列的名字相同 Item:ALI.003 Severity:L1 Content:表或列的别名与其真实名称相同, 这样的别名会使得查询更难去分辨。 Case: 1select name from tbl as tbl where id &lt; 1000 修改表的默认字符集不会改表各个字段的字符集 Item:ALT.001 Severity:L4 Content:很多初学者会将 ALTER TABLE tbl_name [DEFAULT] CHARACTER SET ‘UTF8’ 误认为会修改所有字段的字符集，但实际上它只会影响后续新增的字段不会改表已有字段的字符集。如果想修改整张表所有字段的字符集建议使用 ALTER TABLE tbl_name CONVERT TO CHARACTER SET charset_name; Case: 1ALTER TABLE tbl_name CONVERT TO CHARACTER SET charset_name; 同一张表的多条 ALTER 请求建议合为一条 Item:ALT.002 Severity:L2 Content:每次表结构变更对线上服务都会产生影响，即使是能够通过在线工具进行调整也请尽量通过合并 ALTER 请求的试减少操作次数。 Case: 1ALTER TABLE tbl ADD COLUMN col int, ADD INDEX idx_col (`col`); 删除列为高危操作，操作前请注意检查业务逻辑是否还有依赖 Item:ALT.003 Severity:L0 Content:如业务逻辑依赖未完全消除，列被删除后可能导致数据无法写入或无法查询到已删除列数据导致程序异常的情况。这种情况下即使通过备份数据回滚也会丢失用户请求写入的数据。 Case: 1ALTER TABLE tbl DROP COLUMN col; 删除主键和外键为高危操作，操作前请与 DBA 确认影响 Item:ALT.004 Severity:L0 Content:主键和外键为关系型数据库中两种重要约束，删除已有约束会打破已有业务逻辑，操作前请业务开发与 DBA 确认影响，三思而行。 Case: 1ALTER TABLE tbl DROP PRIMARY KEY; 不建议使用前项通配符查找 Item:ARG.001 Severity:L4 Content:例如 “％foo”，查询参数有一个前项通配符的情况无法使用已有索引。 Case: 1select c1,c2,c3 from tbl where name like '%foo' 没有通配符的 LIKE 查询 Item:ARG.002 Severity:L1 Content:不包含通配符的 LIKE 查询可能存在逻辑错误，因为逻辑上它与等值查询相同。 Case: 1select c1,c2,c3 from tbl where name like 'foo' 参数比较包含隐式转换，无法使用索引 Item:ARG.003 Severity:L4 Content:隐式类型转换有无法命中索引的风险，在高并发、大数据量的情况下，命不中索引带来的后果非常严重。 Case: 1SELECT * FROM sakila.film WHERE length &gt;= '60'; IN (NULL)/NOT IN (NULL) 永远非真 Item:ARG.004 Severity:L4 Content:正确的作法是 col IN (‘val1’, ‘val2’, ‘val3’) OR col IS NULL Case: 1SELECT * FROM tb WHERE col IN (NULL); IN 要慎用，元素过多会导致全表扫描 Item:ARG.005 Severity:L1 Content: 如：select id from t where num in(1,2,3)对于连续的数值，能用 BETWEEN 就不要用 IN 了：select id from t where num between 1 and 3。而当 IN 值过多时 MySQL 也可能会进入全表扫描导致性能急剧下降。 Case: 1select id from t where num in(1,2,3) 应尽量避免在 WHERE 子句中对字段进行 NULL 值判断 Item:ARG.006 Severity:L1 Content:使用 IS NULL 或 IS NOT NULL 将可能导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null;可以在num上设置默认值0，确保表中 num 列没有 NULL 值，然后这样查询： select id from t where num=0; Case: 1select id from t where num is null 避免使用模式匹配 Item:ARG.007 Severity:L3 Content:性能问题是使用模式匹配操作符的最大缺点。使用 LIKE 或正则表达式进行模式匹配进行查询的另一个问题，是可能会返回意料之外的结果。最好的方案就是使用特殊的搜索引擎技术来替代 SQL，比如 Apache Lucene。另一个可选方案是将结果保存起来从而减少重复的搜索开销。如果一定要使用SQL，请考虑在 MySQL 中使用像 FULLTEXT 索引这样的第三方扩展。但更广泛地说，您不一定要使用SQL来解决所有问题。 Case: 1select c_id,c2,c3 from tbl where c2 like 'test%' OR 查询索引列时请尽量使用 IN 谓词 Item:ARG.008 Severity:L1 Content:IN-list 谓词可以用于索引检索，并且优化器可以对 IN-list 进行排序，以匹配索引的排序序列，从而获得更有效的检索。请注意，IN-list 必须只包含常量，或在查询块执行期间保持常量的值，例如外引用。 Case: 1SELECT c1,c2,c3 FROM tbl WHERE c1 = 14 OR c1 = 17 引号中的字符串开头或结尾包含空格 Item:ARG.009 Severity:L1 Content:如果 VARCHAR 列的前后存在空格将可能引起逻辑问题，如在 MySQL 5.5中 ‘a’ 和 ‘a ‘ 可能会在查询中被认为是相同的值。 Case: 1SELECT 'abc ' 不要使用 hint，如：sql_no_cache, force index, ignore key, straight join等 Item:ARG.010 Severity:L1 Content:hint 是用来强制 SQL 按照某个执行计划来执行，但随着数据量变化我们无法保证自己当初的预判是正确的。 Case: 1SELECT * FROM t1 USE INDEX (i1) ORDER BY a; 不要使用负向查询，如：NOT IN/NOT LIKE Item:ARG.011 Severity:L3 Content:请尽量不要使用负向查询，这将导致全表扫描，对查询性能影响较大。 Case: 1select id from t where num not in(1,2,3); 一次性 INSERT/REPLACE 的数据过多 Item:ARG.012 Severity:L2 Content:单条 INSERT/REPLACE 语句批量插入大量数据性能较差，甚至可能导致从库同步延迟。为了提升性能，减少批量写入数据对从库同步延时的影响，建议采用分批次插入的方法。 Case: 1INSERT INTO tb (a) VALUES (1), (2) 最外层 SELECT 未指定 WHERE 条件 Item:CLA.001 Severity:L4 Content:SELECT 语句没有 WHERE 子句，可能检查比预期更多的行(全表扫描)。对于 SELECT COUNT(*) 类型的请求如果不要求精度，建议使用 SHOW TABLE STATUS 或 EXPLAIN 替代。 Case: 1select id from tbl 不建议使用 ORDER BY RAND() Item:CLA.002 Severity:L3 Content:ORDER BY RAND() 是从结果集中检索随机行的一种非常低效的方法，因为它会对整个结果进行排序并丢弃其大部分数据。 Case: 1select name from tbl where id &lt; 1000 order by rand(number) 不建议使用带 OFFSET 的LIMIT 查询 Item:CLA.003 Severity:L2 Content:使用 LIMIT 和 OFFSET 对结果集分页的复杂度是 O(n^2)，并且会随着数据增大而导致性能问题。采用“书签”扫描的方法实现分页效率更高。 Case: 1select c1,c2 from tbl where name=xx order by number limit 1 offset 20 不建议对常量进行 GROUP BY Item:CLA.004 Severity:L2 Content:GROUP BY 1 表示按第一列进行 GROUP BY。如果在 GROUP BY 子句中使用数字，而不是表达式或列名称，当查询列顺序改变时，可能会导致问题。 Case: 1select col1,col2 from tbl group by 1 ORDER BY 常数列没有任何意义 Item:CLA.005 Severity:L2 Content:SQL 逻辑上可能存在错误; 最多只是一个无用的操作，不会更改查询结果。 Case: 1select id from test where id=1 order by id 在不同的表中 GROUP BY 或 ORDER BY Item:CLA.006 Severity:L4 Content:这将强制使用临时表和 filesort，可能产生巨大性能隐患，并且可能消耗大量内存和磁盘上的临时空间。 Case: 1select tb1.col, tb2.col from tb1, tb2 where id=1 group by tb1.col, tb2.col ORDER BY 语句对多个不同条件使用不同方向的排序无法使用索引 Item:CLA.007 Severity:L2 Content:ORDER BY 子句中的所有表达式必须按统一的 ASC 或 DESC 方向排序，以便利用索引。 Case: 1select c1,c2,c3 from t1 where c1='foo' order by c2 desc, c3 asc 请为 GROUP BY 显示添加 ORDER BY 条件 Item:CLA.008 Severity:L2 Content:默认 MySQL 会对 ‘GROUP BY col1, col2, …’ 请求按如下顺序排序 ‘ORDER BY col1, col2, …’。如果 GROUP BY 语句不指定 ORDER BY 条件会导致无谓的排序产生，如果不需要排序建议添加 ‘ORDER BY NULL’。 Case: 1select c1,c2,c3 from t1 where c1='foo' group by c2 ORDER BY 的条件为表达式 Item:CLA.009 Severity:L2 Content:当 ORDER BY 条件为表达式或函数时会使用到临时表，如果在未指定 WHERE 或 WHERE 条件返回的结果集较大时性能会很差。 Case: 1select description from film where title ='ACADEMY DINOSAUR' order by length-language_id; GROUP BY 的条件为表达式 Item:CLA.010 Severity:L2 Content:当 GROUP BY 条件为表达式或函数时会使用到临时表，如果在未指定 WHERE 或 WHERE 条件返回的结果集较大时性能会很差。 Case: 1select description from film where title ='ACADEMY DINOSAUR' GROUP BY length-language_id; 建议为表添加注释 Item:CLA.011 Severity:L1 Content:为表添加注释能够使得表的意义更明确，从而为日后的维护带来极大的便利。 Case: 1CREATE TABLE `test1` (`ID` bigint(20) NOT NULL AUTO_INCREMENT,`c1` varchar(128) DEFAULT NULL,PRIMARY KEY (`ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 将复杂的裹脚布式查询分解成几个简单的查询 Item:CLA.012 Severity:L2 Content:SQL是一门极具表现力的语言，您可以在单个SQL查询或者单条语句中完成很多事情。但这并不意味着必须强制只使用一行代码，或者认为使用一行代码就搞定每个任务是个好主意。通过一个查询来获得所有结果的常见后果是得到了一个笛卡儿积。当查询中的两张表之间没有条件限制它们的关系时，就会发生这种情况。没有对应的限制而直接使用两张表进行联结查询，就会得到第一张表中的每一行和第二张表中的每一行的一个组合。每一个这样的组合就会成为结果集中的一行，最终您就会得到一个行数很多的结果集。重要的是要考虑这些查询很难编写、难以修改和难以调试。数据库查询请求的日益增加应该是预料之中的事。经理们想要更复杂的报告以及在用户界面上添加更多的字段。如果您的设计很复杂，并且是一个单一查询，要扩展它们就会很费时费力。不论对您还是项目来说，时间花在这些事情上面不值得。将复杂的意大利面条式查询分解成几个简单的查询。当您拆分一个复杂的SQL查询时，得到的结果可能是很多类似的查询，可能仅仅在数据类型上有所不同。编写所有的这些查询是很乏味的，因此，最好能够有个程序自动生成这些代码。SQL代码生成是一个很好的应用。尽管SQL支持用一行代码解决复杂的问题，但也别做不切实际的事情。 Case: 1这是一条很长很长的 SQL，案例略。 不建议使用 HAVING 子句 Item:CLA.013 Severity:L3 Content:将查询的 HAVING 子句改写为 WHERE 中的查询条件，可以在查询处理期间使用索引。 Case: 1SELECT s.c_id,count(s.c_id) FROM s where c = test GROUP BY s.c_id HAVING s.c_id &lt;&gt; '1660' AND s.c_id &lt;&gt; '2' order by s.c_id 删除全表时建议使用 TRUNCATE 替代 DELETE Item:CLA.014 Severity:L2 Content:删除全表时建议使用 TRUNCATE 替代 DELETE Case: 1delete from tbl UPDATE 未指定 WHERE 条件 Item:CLA.015 Severity:L4 Content:UPDATE 不指定 WHERE 条件一般是致命的，请您三思后行 Case: 1update tbl set col=1 不要 UPDATE 主键 Item:CLA.016 Severity:L2 Content:主键是数据表中记录的唯一标识符，不建议频繁更新主键列，这将影响元数据统计信息进而影响正常的查询。 Case: 1update tbl set col=1 不建议使用 SELECT * 类型查询 Item:COL.001 Severity:L1 Content:当表结构变更时，使用 * 通配符选择所有列将导致查询的含义和行为会发生更改，可能导致查询返回更多的数据。 Case: 1select * from tbl where id=1 INSERT/REPLACE 未指定列名 Item:COL.002 Severity:L2 Content:当表结构发生变更，如果 INSERT 或 REPLACE 请求不明确指定列名，请求的结果将会与预想的不同; 建议使用 “INSERT INTO tbl(col1，col2)VALUES …” 代替。 Case: 1insert into tbl values(1,'name') 建议修改自增 ID 为无符号类型 Item:COL.003 Severity:L2 Content:建议修改自增 ID 为无符号类型 Case: 1create table test(`id` int(11) NOT NULL AUTO_INCREMENT) 请为列添加默认值 Item:COL.004 Severity:L1 Content:请为列添加默认值，如果是 ALTER 操作，请不要忘记将原字段的默认值写上。字段无默认值，当表较大时无法在线变更表结构。 Case: 1CREATE TABLE tbl (col int) ENGINE=InnoDB; 列未添加注释 Item:COL.005 Severity:L1 Content:建议对表中每个列添加注释，来明确每个列在表中的含义及作用。 Case: 1CREATE TABLE tbl (col int) ENGINE=InnoDB; 表中包含有太多的列 Item:COL.006 Severity:L3 Content:表中包含有太多的列 Case: 1CREATE TABLE tbl ( cols ....); 可使用 VARCHAR 代替 CHAR， VARBINARY 代替 BINARY Item:COL.008 Severity:L1 Content:为首先变长字段存储空间小，可以节省存储空间。其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 Case: 1create table t1(id int,name char(20),last_time date) 建议使用精确的数据类型 Item:COL.009 Severity:L2 Content:实际上，任何使用 FLOAT, REAL 或 DOUBLE PRECISION 数据类型的设计都有可能是反模式。大多数应用程序使用的浮点数的取值范围并不需要达到IEEE 754标准所定义的最大/最小区间。在计算总量时，非精确浮点数所积累的影响是严重的。使用 SQL 中的 NUMERIC 或 DECIMAL 类型来代替 FLOAT 及其类似的数据类型进行固定精度的小数存储。这些数据类型精确地根据您定义这一列时指定的精度来存储数据。尽可能不要使用浮点数。 Case: 1CREATE TABLE tab2 (p_id BIGINT UNSIGNED NOT NULL,a_id BIGINT UNSIGNED NOT NULL,hours float not null,PRIMARY KEY (p_id, a_id)) 不建议使用 ENUM 数据类型 Item:COL.010 Severity:L2 Content:ENUM 定义了列中值的类型，使用字符串表示 ENUM 里的值时，实际存储在列中的数据是这些值在定义时的序数。因此，这列的数据是字节对齐的，当您进行一次排序查询时，结果是按照实际存储的序数值排序的，而不是按字符串值的字母顺序排序的。这可能不是您所希望的。没有什么语法支持从 ENUM 或者 check 约束中添加或删除一个值；您只能使用一个新的集合重新定义这一列。如果您打算废弃一个选项，您可能会为历史数据而烦恼。作为一种策略，改变元数据——也就是说，改变表和列的定义——应该是不常见的，并且要注意测试和质量保证。有一个更好的解决方案来约束一列中的可选值:创建一张检查表，每一行包含一个允许在列中出现的候选值；然后在引用新表的旧表上声明一个外键约束。 Case: 1create table tab1(status ENUM('new','in progress','fixed')) 当需要唯一约束时才使用 NULL，仅当列不能有缺失值时才使用 NOT NULL Item:COL.011 Severity:L0 Content:NULL 和0是不同的，10乘以 NULL 还是 NULL。NULL 和空字符串是不一样的。将一个字符串和标准 SQL 中的 NULL 联合起来的结果还是 NULL。NULL 和 FALSE 也是不同的。AND、OR 和 NOT 这三个布尔操作如果涉及 NULL，其结果也让很多人感到困惑。当您将一列声明为 NOT NULL 时，也就是说这列中的每一个值都必须存在且是有意义的。使用 NULL 来表示任意类型不存在的空值。 当您将一列声明为 NOT NULL 时，也就是说这列中的每一个值都必须存在且是有意义的。 Case: 1select c1,c2,c3 from tbl where c4 is null or c4 &lt;&gt; 1 BLOB 和 TEXT 类型的字段不可设置为 NULL Item:COL.012 Severity:L5 Content:BLOB 和 TEXT 类型的字段不可设置为 NULL Case: 1CREATE TABLE `tbl` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `c` longblob, PRIMARY KEY (`id`)); TIMESTAMP 类型未设置默认值 Item:COL.013 Severity:L4 Content:TIMESTAMP 类型未设置默认值 Case: 1CREATE TABLE tbl( `id` bigint not null, `create_time` timestamp); 为列指定了字符集 Item:COL.014 Severity:L5 Content:建议列与表使用同一个字符集，不要单独指定列的字符集。 Case: 1CREATE TABLE `tb2` ( `id` int(11) DEFAULT NULL, `col` char(10) CHARACTER SET utf8 DEFAULT NULL) BLOB 类型的字段不可指定默认值 Item:COL.015 Severity:L4 Content:BLOB 类型的字段不可指定默认值 Case: 1CREATE TABLE `tbl` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `c` blob NOT NULL DEFAULT '', PRIMARY KEY (`id`)); 整型定义建议采用 INT(10) 或 BIGINT(20) Item:COL.016 Severity:L1 Content:INT(M) 在 integer 数据类型中，M 表示最大显示宽度。 在 INT(M) 中，M 的值跟 INT(M) 所占多少存储空间并无任何关系。 INT(3)、INT(4)、INT(8) 在磁盘上都是占用 4 bytes 的存储空间。 Case: 1CREATE TABLE tab (a INT(1)); VARCHAR 定义长度过长 Item:COL.017 Severity:L2 Content:varchar 是可变长字符串，不预先分配存储空间，长度不要超过255，如果存储长度过长 MySQL 将定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。 Case: 1CREATE TABLE tab (a varchar(3500)); 消除不必要的 DISTINCT 条件 Item:DIS.001 Severity:L1 Content:太多DISTINCT条件是复杂的裹脚布式查询的症状。考虑将复杂查询分解成许多简单的查询，并减少DISTINCT条件的数量。如果主键列是列的结果集的一部分，则DISTINCT条件可能没有影响。 Case: 1SELECT DISTINCT c.c_id,count(DISTINCT c.c_name),count(DISTINCT c.c_e),count(DISTINCT c.c_n),count(DISTINCT c.c_me),c.c_d FROM (select distinct id, name from B) as e WHERE e.country_id = c.country_id COUNT(DISTINCT) 多列时结果可能和你预想的不同 Item:DIS.002 Severity:L3 Content:COUNT(DISTINCT col) 计算该列除NULL之外的不重复行数，注意 COUNT(DISTINCT col, col2) 如果其中一列全为 NULL 那么即使另一列有不同的值，也返回0。 Case: 1SELECT COUNT(DISTINCT col, col2) FROM tbl; DISTINCT * 对有主键的表没有意义 Item:DIS.003 Severity:L3 Content:当表已经有主键时，对所有列进行 DISTINCT 的输出结果与不进行 DISTINCT 操作的结果相同，请不要画蛇添足。 Case: 1SELECT DISTINCT * FROM film; 避免在 WHERE 条件中使用函数或其他运算符 Item:FUN.001 Severity:L2 Content:虽然在 SQL 中使用函数可以简化很多复杂的查询，但使用了函数的查询无法利用表中已经建立的索引，该查询将会是全表扫描，性能较差。通常建议将列名写在比较运算符左侧，将查询过滤条件放在比较运算符右侧。也不建议在查询比较条件两侧书写多余的括号，这会对阅读产生比较大的困扰。 Case: 1select id from t where substring(name,1,3)='abc' 指定了 WHERE 条件或非 MyISAM 引擎时使用 COUNT(*) 操作性能不佳 Item:FUN.002 Severity:L1 Content:COUNT(*) 的作用是统计表行数，COUNT(COL) 的作用是统计指定列非 NULL 的行数。MyISAM 表对于 COUNT(*) 统计全表行数进行了特殊的优化，通常情况下非常快。但对于非 MyISAM 表或指定了某些 WHERE 条件，COUNT(*) 操作需要扫描大量的行才能获取精确的结果，性能也因此不佳。有时候某些业务场景并不需要完全精确的 COUNT 值，此时可以用近似值来代替。EXPLAIN 出来的优化器估算的行数就是一个不错的近似值，执行 EXPLAIN 并不需要真正去执行查询，所以成本很低。 Case: 1SELECT c3, COUNT(*) AS accounts FROM tab where c2 &lt; 10000 GROUP BY c3 ORDER BY num 使用了合并为可空列的字符串连接 Item:FUN.003 Severity:L3 Content:在一些查询请求中，您需要强制让某一列或者某个表达式返回非 NULL 的值，从而让查询逻辑变得更简单，担忧不想将这个值存下来。使用 COALESCE() 函数来构造连接的表达式，这样即使是空值列也不会使整表达式变为 NULL。 Case: 1select c1 || coalesce(' ' || c2 || ' ', ' ') || c3 as c from tbl 不建议使用 SYSDATE() 函数 Item:FUN.004 Severity:L4 Content:SYSDATE() 函数可能导致主从数据不一致，请使用 NOW() 函数替代 SYSDATE()。 Case: 1SELECT SYSDATE(); 不建议使用 COUNT(col) 或 COUNT(常量) Item:FUN.005 Severity:L1 Content:不要使用 COUNT(col) 或 COUNT(常量) 来替代 COUNT(*), COUNT(*) 是 SQL92 定义的标准统计行数的方法，跟数据无关，跟 NULL 和非 NULL 也无关。 Case: 1SELECT COUNT(1) FROM tbl; 使用 SUM(COL) 时需注意 NPE 问题 Item:FUN.006 Severity:L1 Content:当某一列的值全是 NULL 时，COUNT(COL) 的返回结果为0,但 SUM(COL) 的返回结果为 NULL，因此使用 SUM() 时需注意 NPE 问题。可以使用如下方式来避免 SUM 的 NPE 问题: SELECT IF(ISNULL(SUM(COL)), 0, SUM(COL)) FROM tbl Case: 1SELECT SUM(COL) FROM tbl; 不建议使用触发器 Item:FUN.007 Severity:L1 Content:触发器的执行没有反馈和日志，隐藏了实际的执行步骤，当数据库出现问题是，不能通过慢日志分析触发器的具体执行情况，不易发现问题。在MySQL中，触发器不能临时关闭或打开，在数据迁移或数据恢复等场景下，需要临时drop触发器，可能影响到生产环境。 Case: 1CREATE TRIGGER t1 AFTER INSERT ON work FOR EACH ROW INSERT INTO time VALUES(NOW()); 不建议使用存储过程 Item:FUN.008 Severity:L1 Content:存储过程无版本控制，配合业务的存储过程升级很难做到业务无感知。存储过程在拓展和移植上也存在问题。 Case: 1CREATE PROCEDURE simpleproc (OUT param1 INT); 不建议使用自定义函数 Item:FUN.009 Severity:L1 Content:不建议使用自定义函数 Case: 1CREATE FUNCTION hello (s CHAR(20)); 不建议对等值查询列使用 GROUP BY Item:GRP.001 Severity:L2 Content:GROUP BY 中的列在前面的 WHERE 条件中使用了等值查询，对这样的列进行 GROUP BY 意义不大。 Case: 1select film_id, title from film where release_year='2006' group by release_year JOIN 语句混用逗号和 ANSI 模式 Item:JOI.001 Severity:L2 Content:表连接的时候混用逗号和 ANSI JOIN 不便于人类理解，并且MySQL不同版本的表连接行为和优先级均有所不同，当 MySQL 版本变化后可能会引入错误。 Case: 1select c1,c2,c3 from t1,t2 join t3 on t1.c1=t2.c1,t1.c3=t3,c1 where id&gt;1000 同一张表被连接两次 Item:JOI.002 Severity:L4 Content:相同的表在 FROM 子句中至少出现两次，可以简化为对该表的单次访问。 Case: 1select tb1.col from (tb1, tb2) join tb2 on tb1.id=tb.id where tb1.id=1 OUTER JOIN 失效 Item:JOI.003 Severity:L4 Content:由于 WHERE 条件错误使得 OUTER JOIN 的外部表无数据返回，这会将查询隐式转换为 INNER JOIN 。如：select c from L left join R using(c) where L.a=5 and R.b=10。这种 SQL 逻辑上可能存在错误或程序员对 OUTER JOIN 如何工作存在误解，因为 LEFT/RIGHT JOIN 是 LEFT/RIGHT OUTER JOIN 的缩写。 Case: 1select c1,c2,c3 from t1 left outer join t2 using(c1) where t1.c2=2 and t2.c3=4 不建议使用排它 JOIN Item:JOI.004 Severity:L4 Content:只在右侧表为 NULL 的带 WHERE 子句的 LEFT OUTER JOIN 语句，有可能是在WHERE子句中使用错误的列，如：“… FROM l LEFT OUTER JOIN r ON l.l = r.r WHERE r.z IS NULL”，这个查询正确的逻辑可能是 WHERE r.r IS NULL。 Case: 1select c1,c2,c3 from t1 left outer join t2 on t1.c1=t2.c1 where t2.c2 is null 减少 JOIN 的数量 Item:JOI.005 Severity:L2 Content:太多的 JOIN 是复杂的裹脚布式查询的症状。考虑将复杂查询分解成许多简单的查询，并减少 JOIN 的数量。 Case: 1select bp1.p_id, b1.d_d as l, b1.b_id from b1 join bp1 on (b1.b_id = bp1.b_id) left outer join (b1 as b2 join bp2 on (b2.b_id = bp2.b_id)) on (bp1.p_id = bp2.p_id ) join bp21 on (b1.b_id = bp1.b_id) join bp31 on (b1.b_id = bp1.b_id) join bp41 on (b1.b_id = bp1.b_id) where b2.b_id = 0 将嵌套查询重写为 JOIN 通常会导致更高效的执行和更有效的优化 Item:JOI.006 Severity:L4 Content:一般来说，非嵌套子查询总是用于关联子查询，最多是来自FROM子句中的一个表，这些子查询用于 ANY, ALL 和 EXISTS 的谓词。如果可以根据查询语义决定子查询最多返回一个行，那么一个不相关的子查询或来自FROM子句中的多个表的子查询就被压平了。 Case: 1SELECT s,p,d FROM tbl WHERE p.p_id = (SELECT s.p_id FROM tbl WHERE s.c_id = 100996 AND s.q = 1 ) 不建议使用联表删除或更新 Item:JOI.007 Severity:L4 Content:当需要同时删除或更新多张表时建议使用简单语句，一条 SQL 只删除或更新一张表，尽量不要将多张表的操作在同一条语句。 Case: 1UPDATE users u LEFT JOIN hobby h ON u.id = h.uid SET u.name = 'pianoboy' WHERE h.hobby = 'piano'; 不要使用跨数据库的 JOIN 查询 Item:JOI.008 Severity:L4 Content:一般来说，跨数据库的 JOIN 查询意味着查询语句跨越了两个不同的子系统，这可能意味着系统耦合度过高或库表结构设计不合理。 Case: 1SELECT s,p,d FROM tbl WHERE p.p_id = (SELECT s.p_id FROM tbl WHERE s.c_id = 100996 AND s.q = 1 ) 建议使用自增列作为主键，如使用联合自增主键时请将自增键作为第一列 Item:KEY.001 Severity:L2 Content:建议使用自增列作为主键，如使用联合自增主键时请将自增键作为第一列 Case: 1create table test(`id` int(11) NOT NULL PRIMARY KEY (`id`)) 无主键或唯一键，无法在线变更表结构 Item:KEY.002 Severity:L4 Content:无主键或唯一键，无法在线变更表结构 Case: 1create table test(col varchar(5000)) 避免外键等递归关系 Item:KEY.003 Severity:L4 Content:存在递归关系的数据很常见，数据常会像树或者以层级方式组织。然而，创建一个外键约束来强制执行同一表中两列之间的关系，会导致笨拙的查询。树的每一层对应着另一个连接。您将需要发出递归查询，以获得节点的所有后代或所有祖先。解决方案是构造一个附加的闭包表。它记录了树中所有节点间的关系，而不仅仅是那些具有直接的父子关系。您也可以比较不同层次的数据设计：闭包表，路径枚举，嵌套集。然后根据应用程序的需要选择一个。 Case: 1CREATE TABLE tab2 (p_id BIGINT UNSIGNED NOT NULL,a_id BIGINT UNSIGNED NOT NULL,PRIMARY KEY (p_id, a_id),FOREIGN KEY (p_id) REFERENCES tab1(p_id),FOREIGN KEY (a_id) REFERENCES tab3(a_id)) 提醒：请将索引属性顺序与查询对齐 Item:KEY.004 Severity:L0 Content:如果为列创建复合索引，请确保查询属性与索引属性的顺序相同，以便DBMS在处理查询时使用索引。如果查询和索引属性订单没有对齐，那么DBMS可能无法在查询处理期间使用索引。 Case: 1create index idx1 on tbl (last_name,first_name) 表建的索引过多 Item:KEY.005 Severity:L2 Content:表建的索引过多 Case: 1CREATE TABLE tbl ( a int, b int, c int, KEY idx_a (`a`),KEY idx_b(`b`),KEY idx_c(`c`)); 主键中的列过多 Item:KEY.006 Severity:L4 Content:主键中的列过多 Case: 1CREATE TABLE tbl ( a int, b int, c int, PRIMARY KEY(`a`,`b`,`c`)); 未指定主键或主键非 bigint Item:KEY.007 Severity:L4 Content:未指定主键或主键非 bigint，建议将主键设置为 bigint unsigned。 Case: 1CREATE TABLE tbl (a bigint); ORDER BY 多个列但排序方向不同时可能无法使用索引 Item:KEY.008 Severity:L4 Content:在 MySQL 8.0之前当 ORDER BY 多个列指定的排序方向不同时将无法使用已经建立的索引。 Case: 1SELECT * FROM tbl ORDER BY a DESC, b ASC; 添加唯一索引前请注意检查数据唯一性 Item:KEY.009 Severity:L0 Content:请提前检查添加唯一索引列的数据唯一性，如果数据不唯一在线表结构调整时将有可能自动将重复列删除，这有可能导致数据丢失。 Case: 1CREATE UNIQUE INDEX part_of_name ON customer (name(10)); 全文索引不是银弹 Item:KEY.010 Severity:L0 Content:全文索引主要用于解决模糊查询的性能问题，但需要控制好查询的频率和并发度。同时注意调整 ft_min_word_len, ft_max_word_len, ngram_token_size 等参数。 Case: 1CREATE TABLE `tb` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `ip` varchar(255) NOT NULL DEFAULT '', PRIMARY KEY (`id`), FULLTEXT KEY `ip` (`ip`) ) ENGINE=InnoDB; SQL_CALC_FOUND_ROWS 效率低下 Item:KWR.001 Severity:L2 Content:因为 SQL_CALC_FOUND_ROWS 不能很好地扩展，所以可能导致性能问题; 建议业务使用其他策略来替代 SQL_CALC_FOUND_ROWS 提供的计数功能，比如：分页结果展示等。 Case: 1select SQL_CALC_FOUND_ROWS col from tbl where id&gt;1000 不建议使用 MySQL 关键字做列名或表名 Item:KWR.002 Severity:L2 Content:当使用关键字做为列名或表名时程序需要对列名和表名进行转义，如果疏忽被将导致请求无法执行。 Case: 1CREATE TABLE tbl ( `select` int ) 不建议使用复数做列名或表名 Item:KWR.003 Severity:L1 Content:表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。 Case: 1CREATE TABLE tbl ( `books` int ) 不建议使用使用多字节编码字符(中文)命名 Item:KWR.004 Severity:L1 Content:为库、表、列、别名命名时建议使用英文，数字，下划线等字符，不建议使用中文或其他多字节编码字符。 Case: 1select col as 列 from tb INSERT INTO xx SELECT 加锁粒度较大请谨慎 Item:LCK.001 Severity:L3 Content:INSERT INTO xx SELECT 加锁粒度较大请谨慎 Case: 1INSERT INTO tbl SELECT * FROM tbl2; 请慎用 INSERT ON DUPLICATE KEY UPDATE Item:LCK.002 Severity:L3 Content:当主键为自增键时使用 INSERT ON DUPLICATE KEY UPDATE 可能会导致主键出现大量不连续快速增长，导致主键快速溢出无法继续写入。极端情况下还有可能导致主从数据不一致。 Case: 1INSERT INTO t1(a,b,c) VALUES (1,2,3) ON DUPLICATE KEY UPDATE c=c+1; 用字符类型存储IP地址 Item:LIT.001 Severity:L2 Content:字符串字面上看起来像IP地址，但不是 INET_ATON() 的参数，表示数据被存储为字符而不是整数。将IP地址存储为整数更为有效。 Case: 1insert into tbl (IP,name) values('10.20.306.122','test') 日期/时间未使用引号括起 Item:LIT.002 Severity:L4 Content:诸如“WHERE col &lt;2010-02-12”之类的查询是有效的SQL，但可能是一个错误，因为它将被解释为“WHERE col &lt;1996”; 日期/时间文字应该加引号。 Case: 1select col1,col2 from tbl where time &lt; 2018-01-10 一列中存储一系列相关数据的集合 Item:LIT.003 Severity:L3 Content:将 ID 存储为一个列表，作为 VARCHAR/TEXT 列，这样能导致性能和数据完整性问题。查询这样的列需要使用模式匹配的表达式。使用逗号分隔的列表来做多表联结查询定位一行数据是极不优雅和耗时的。这将使验证 ID 更加困难。考虑一下，列表最多支持存放多少数据呢？将 ID 存储在一张单独的表中，代替使用多值属性，从而每个单独的属性值都可以占据一行。这样交叉表实现了两张表之间的多对多关系。这将更好地简化查询，也更有效地验证ID。 Case: 1select c1,c2,c3,c4 from tab1 where col_id REGEXP '[[:&lt;:]]12[[:&gt;:]]' 请使用分号或已设定的 DELIMITER 结尾 Item:LIT.004 Severity:L1 Content:USE database, SHOW DATABASES 等命令也需要使用使用分号或已设定的 DELIMITER 结尾。 Case: 1USE db 非确定性的 GROUP BY Item:RES.001 Severity:L4 Content:SQL返回的列既不在聚合函数中也不是 GROUP BY 表达式的列中，因此这些值的结果将是非确定性的。如：select a, b, c from tbl where foo=”bar” group by a，该 SQL 返回的结果就是不确定的。 Case: 1select c1,c2,c3 from t1 where c2='foo' group by c2 未使用 ORDER BY 的 LIMIT 查询 Item:RES.002 Severity:L4 Content:没有 ORDER BY 的 LIMIT 会导致非确定性的结果，这取决于查询执行计划。 Case: 1select col1,col2 from tbl where name=xx limit 10 UPDATE/DELETE 操作使用了 LIMIT 条件 Item:RES.003 Severity:L4 Content:UPDATE/DELETE 操作使用 LIMIT 条件和不添加 WHERE 条件一样危险，它可将会导致主从数据不一致或从库同步中断。 Case: 1UPDATE film SET length = 120 WHERE title = 'abc' LIMIT 1; UPDATE/DELETE 操作指定了 ORDER BY 条件 Item:RES.004 Severity:L4 Content:UPDATE/DELETE 操作不要指定 ORDER BY 条件。 Case: 1UPDATE film SET length = 120 WHERE title = 'abc' ORDER BY title UPDATE 语句可能存在逻辑错误，导致数据损坏 Item:RES.005 Severity:L4 Content:在一条 UPDATE 语句中，如果要更新多个字段，字段间不能使用 AND ，而应该用逗号分隔。 Case: 1update tbl set col = 1 and cl = 2 where col=3; 永远不真的比较条件 Item:RES.006 Severity:L4 Content:查询条件永远非真，如果该条件出现在 where 中可能导致查询无匹配到的结果。 Case: 1select * from tbl where 1 != 1; 永远为真的比较条件 Item:RES.007 Severity:L4 Content:查询条件永远为真，可能导致 WHERE 条件失效进行全表查询。 Case: 1select * from tbl where 1 = 1; 不建议使用LOAD DATA/SELECT … INTO OUTFILE Item:RES.008 Severity:L2 Content:SELECT INTO OUTFILE 需要授予 FILE 权限，这通过会引入安全问题。LOAD DATA 虽然可以提高数据导入速度，但同时也可能导致从库同步延迟过大。 Case: 1LOAD DATA INFILE 'data.txt' INTO TABLE db2.my_table; 请谨慎使用TRUNCATE操作 Item:SEC.001 Severity:L0 Content:一般来说想清空一张表最快速的做法就是使用TRUNCATE TABLE tbl_name;语句。但TRUNCATE操作也并非是毫无代价的，TRUNCATE TABLE无法返回被删除的准确行数，如果需要返回被删除的行数建议使用DELETE语法。TRUNCATE 操作还会重置 AUTO_INCREMENT，如果不想重置该值建议使用 DELETE FROM tbl_name WHERE 1;替代。TRUNCATE 操作会对数据字典添加源数据锁(MDL)，当一次需要 TRUNCATE 很多表时会影响整个实例的所有请求，因此如果要 TRUNCATE 多个表建议用 DROP+CREATE 的方式以减少锁时长。 Case: 1TRUNCATE TABLE tbl_name 不使用明文存储密码 Item:SEC.002 Severity:L0 Content:使用明文存储密码或者使用明文在网络上传递密码都是不安全的。如果攻击者能够截获您用来插入密码的SQL语句，他们就能直接读到密码。另外，将用户输入的字符串以明文的形式插入到纯SQL语句中，也会让攻击者发现它。如果您能够读取密码，黑客也可以。解决方案是使用单向哈希函数对原始密码进行加密编码。哈希是指将输入字符串转化成另一个新的、不可识别的字符串的函数。对密码加密表达式加点随机串来防御“字典攻击”。不要将明文密码输入到SQL查询语句中。在应用程序代码中计算哈希串，只在SQL查询中使用哈希串。 Case: 1create table test(id int,name varchar(20) not null,password varchar(200)not null) 使用DELETE/DROP/TRUNCATE等操作时注意备份 Item:SEC.003 Severity:L0 Content:在执行高危操作之前对数据进行备份是十分有必要的。 Case: 1delete from table where col = 'condition' 建议使用 datetime 替换 timestamp 类型 Item:SKEY.005 Severity:L4 Content:建议使用 datetime 替换 timestamp 类型，且默认值设置为 1970-01-01 00:00:00。 datetime 类型能保存大范围的值，从1001年到9999年，且与时区无关。使用8个字节的存储空间（比 timestamp 多出4字节） Case: 1CREATE TABLE tbl (a datetime); 缺少数据库必须字段 last_update_time 和 is_del Item:SKEY.006 Severity:L4 Content:数据库必须字段 （`last_update_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT ‘最后更新时间’; `is_del` TINYINT (1) UNSIGNED NOT NULL DEFAULT ‘0’ COMMENT ‘是否删除 0：未删除 1：已删除’） Case: 1CREATE TABLE tbl （`last_update_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后更新时间'; `is_del` TINYINT (1) UNSIGNED NOT NULL DEFAULT '0' COMMENT '是否删除 0：未删除 1：已删除'）; last_update_time 和 is_del 类型不对 Item:SKEY.006a Severity:L4 Content:数据库必须字段 （`last_update_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT ‘最后更新时间’; `is_del` TINYINT (1) UNSIGNED NOT NULL DEFAULT ‘0’ COMMENT ‘是否删除 0：未删除 1：已删除’） Case: 1CREATE TABLE tbl （`last_update_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后更新时间'; `is_del` TINYINT (1) UNSIGNED NOT NULL DEFAULT '0' COMMENT '是否删除 0：未删除 1：已删除'）; 不建议使用大字段 TEXT BLOB Item:SKEY.010 Severity:L1 Content:BLOB 和 TEXT 都是为存储很大的数据而设计的字符串数据类型，且性能开销较大，请检查是否有必要使用 Case: 1CREATE TABLE tbl （a TEXT）; 整形建议使用 unsigned Item:SKEY.011 Severity:L1 Content:请检查整形是否有负数场景，如无特殊场景，建议使用 unsigned Case: 1CREATE TABLE tbl （a int unsigned）; ‘!=’ 运算符是非标准的 Item:STA.001 Severity:L0 Content:”&lt;&gt;”才是标准SQL中的不等于运算符。 Case: 1select col1,col2 from tbl where type!=0 库名或表名点后建议不要加空格 Item:STA.002 Severity:L1 Content:当使用 db.table 或 table.column 格式访问表或字段时，请不要在点号后面添加空格，虽然这样语法正确。 Case: 1select col from sakila. film 索引起名不规范 Item:STA.003 Severity:L1 Content:建议普通二级索引以idx_为前缀，唯一索引以uniq_为前缀。 Case: 1select col from now where type!=0 起名时请不要使用字母、数字和下划线之外的字符 Item:STA.004 Severity:L1 Content:以字母或下划线开头，名字只允许使用字母、数字和下划线。请统一大小写，不要使用驼峰命名法。不要在名字中出现连续下划线’__‘，这样很难辨认。 Case: 1CREATE TABLE ` abc` (a int); MySQL 对子查询的优化效果不佳 Item:SUB.001 Severity:L4 Content:MySQL 将外部查询中的每一行作为依赖子查询执行子查询。 这是导致严重性能问题的常见原因。这可能会在 MySQL 5.6 版本中得到改善, 但对于5.1及更早版本, 建议将该类查询分别重写为 JOIN 或 LEFT OUTER JOIN。 Case: 1select col1,col2,col3 from table1 where col2 in(select col from table2) 如果您不在乎重复的话，建议使用 UNION ALL 替代 UNION Item:SUB.002 Severity:L2 Content:与去除重复的UNION不同，UNION ALL允许重复元组。如果您不关心重复元组，那么使用UNION ALL将是一个更快的选项。 Case: 1select teacher_id as id,people_name as name from t1,t2 where t1.teacher_id=t2.people_id union select student_id as id,people_name as name from t1,t2 where t1.student_id=t2.people_id 考虑使用 EXISTS 而不是 DISTINCT 子查询 Item:SUB.003 Severity:L3 Content:DISTINCT 关键字在对元组排序后删除重复。相反，考虑使用一个带有 EXISTS 关键字的子查询，您可以避免返回整个表。 Case: 1SELECT DISTINCT c.c_id, c.c_name FROM c,e WHERE e.c_id = c.c_id 执行计划中嵌套连接深度过深 Item:SUB.004 Severity:L3 Content:MySQL对子查询的优化效果不佳,MySQL将外部查询中的每一行作为依赖子查询执行子查询。 这是导致严重性能问题的常见原因。 Case: 1SELECT * from tb where id in (select id from (select id from tb)) 子查询不支持LIMIT Item:SUB.005 Severity:L8 Content:当前 MySQL 版本不支持在子查询中进行 ‘LIMIT &amp; IN/ALL/ANY/SOME’。 Case: 1SELECT * FROM staff WHERE name IN (SELECT NAME FROM customer ORDER BY name LIMIT 1) 不建议在子查询中使用函数 Item:SUB.006 Severity:L2 Content:MySQL将外部查询中的每一行作为依赖子查询执行子查询，如果在子查询中使用函数，即使是semi-join也很难进行高效的查询。可以将子查询重写为OUTER JOIN语句并用连接条件对数据进行过滤。 Case: 1SELECT * FROM staff WHERE name IN (SELECT max(NAME) FROM customer) 不建议使用分区表 Item:TBL.001 Severity:L4 Content:不建议使用分区表 Case: 1CREATE TABLE trb3(id INT, name VARCHAR(50), purchased DATE) PARTITION BY RANGE(YEAR(purchased)) (PARTITION p0 VALUES LESS THAN (1990), PARTITION p1 VALUES LESS THAN (1995), PARTITION p2 VALUES LESS THAN (2000), PARTITION p3 VALUES LESS THAN (2005) ); 请为表选择合适的存储引擎 Item:TBL.002 Severity:L4 Content:建表或修改表的存储引擎时建议使用推荐的存储引擎，如：innodb Case: 1create table test(`id` int(11) NOT NULL AUTO_INCREMENT) 以DUAL命名的表在数据库中有特殊含义 Item:TBL.003 Severity:L8 Content:DUAL表为虚拟表，不需要创建即可使用，也不建议服务以DUAL命名表。 Case: 1create table dual(id int, primary key (id)); 表的初始AUTO_INCREMENT值不为0 Item:TBL.004 Severity:L2 Content:AUTO_INCREMENT不为0会导致数据空洞。 Case: 1CREATE TABLE tbl (a int) AUTO_INCREMENT = 10; 请使用推荐的字符集 Item:TBL.005 Severity:L4 Content:表字符集只允许设置为utf8mb4 Case: 1CREATE TABLE tbl (a int) DEFAULT CHARSET = latin1; 不建议使用视图 Item:TBL.006 Severity:L1 Content:不建议使用视图 Case: 1create view v_today (today) AS SELECT CURRENT_DATE; 不建议使用临时表 Item:TBL.007 Severity:L1 Content:不建议使用临时表 Case: 1CREATE TEMPORARY TABLE `work` (`time` time DEFAULT NULL) ENGINE=InnoDB;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://rovast.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://rovast.github.io/tags/MySQL/"},{"name":"soar","slug":"soar","permalink":"https://rovast.github.io/tags/soar/"}]},{"title":"使用 soar 优化 MySQL","slug":"optimize-mysql-with-soar","date":"2018-12-20T07:00:52.000Z","updated":"2020-11-28T08:49:18.067Z","comments":true,"path":"2018/12/20/optimize-mysql-with-soar/","link":"","permalink":"https://rovast.github.io/2018/12/20/optimize-mysql-with-soar/","excerpt":"","text":"介绍项目地址： https://github.com/XiaoMi/soar SOAR SOAR(SQL Optimizer And Rewriter)是一个对SQL进行优化和改写的自动化工具。 由小米人工智能与云平台的数据库团队开发与维护。 功能特点 跨平台支持（支持Linux, Mac环境，Windows环境理论上也支持，不过未全面测试） 目前只支持 MySQL 语法族协议的SQL优化 支持基于启发式算法的语句优化 支持复杂查询的多列索引优化（UPDATE, INSERT, DELETE, SELECT） 支持EXPLAIN信息丰富解读 支持SQL指纹、压缩和美化 支持同一张表多条ALTER请求合并 支持自定义规则的SQL改写 终端运行下载二进制文件 在 https://github.com/XiaoMi/soar/releases 中下载合适的二进制文件 运行效果 test.sql 12345678910CREATE TABLE `users` ( `id` int(10) UNSIGNED NOT NULL, `name` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `email` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `email_verified_at` timestamp NULL DEFAULT NULL, `password` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `remember_token` varchar(100) COLLATE utf8mb4_unicode_ci DEFAULT NULL, `created_at` timestamp NULL DEFAULT NULL, `updated_at` timestamp NULL DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci; soar -query test.sql 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# Query: F5422F7F42F440DF☆ ☆ ☆ ☆ ☆ 0分sqlCREATE TABLE `users` ( `id` int( 10) UNSIGNED NOT NULL, `name` varchar( 255) COLLATE utf8mb4_unicode_ci NOT NULL, `email` varchar( 255) COLLATE utf8mb4_unicode_ci NOT NULL, `email_verified_at` TIMESTAMP NULL DEFAULT NULL, `password` varchar( 255) COLLATE utf8mb4_unicode_ci NOT NULL, `remember_token` varchar( 100) COLLATE utf8mb4_unicode_ci DEFAULT NULL, `created_at` TIMESTAMP NULL DEFAULT NULL, `updated_at` TIMESTAMP NULL DEFAULT NULL) ENGINE= InnoDB DEFAULT CHARSET= utf8mb4 COLLATE= utf8mb4_unicode_ci## 建议为表添加注释* **Item:** CLA.011* **Severity:** L1* **Content:** 为表添加注释能够使得表的意义更明确，从而为日后的维护带来极大的便利。## 请为列添加默认值* **Item:** COL.004* **Severity:** L1* **Content:** 请为列添加默认值，如果是 ALTER 操作，请不要忘记将原字段的默认值写上。字段无默认值，当表较大时无法在线变更表结构。## 列未添加注释* **Item:** COL.005* **Severity:** L1* **Content:** 建议对表中每个列添加注释，来明确每个列在表中的含义及作用。## 为列指定了字符集* **Item:** COL.014* **Severity:** L5* **Content:** 建议列与表使用同一个字符集，不要单独指定列的字符集。## 未指定主键或主键非 bigint* **Item:** KEY.007* **Severity:** L4* **Content:** 未指定主键或主键非 bigint，建议将主键设置为 bigint unsigned。## 不建议使用复数做列名或表名* **Item:** KWR.003* **Severity:** L1* **Content:** 表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。## 不使用明文存储密码* **Item:** SEC.002* **Severity:** L0* **Content:** 使用明文存储密码或者使用明文在网络上传递密码都是不安全的。如果攻击者能够截获您用来插入密码的SQL语句，他们就能直接读到密码。另外，将用户输入的字符串以明文的形式插入到纯SQL语句中，也会让攻击者发现它。如果您能够读取密码，黑客也可以。解决方案是使用单向哈希函数对原始密码进行加密编码。哈希是指将输入字符串转化成另一个新的、不可识别的字符串的函数。对密码加密表达式加点随机串来防御“字典攻击”。不要将明文密码输入到SQL查询语句中。在应用程序代码中计算哈希串，只在SQL查询中使用哈希串。 web 可视化为了更好地进行使用，社区出现了 web 可视化工具，如 soar-web https://github.com/xiyangxixian/soar-web 由于这个源之前存在的一个中文问题#issue71，我 fork 了项目，并且制作了一个 docker docker run -d -p 5077:5077 rovast/soar-web，在本地访问 http://127.0.0.1:5077 即可。 新增启发规则如果我们需要限定查询的规则中必须包含 last_updated_at 字段，可对 soar 进行如下修改后编译 soar/advisor/rules.go 增加一条规则 12345678\"MY_KEY.001\": &#123; Item: \"MY_KEY.001\", Severity: \"L4\", Summary: \"缺少数据库必须字段 last_updated_at\", Content: \"数据库必须字段 last_updated_at\", Case: \"CREATE TABLE tbl （`last_updated_at` DATETIME COMMENT '最后更新时间';\", Func: (*Query4Audit).RuleRequiredFields,&#125;, soar/advisor/heuristic.go 12345678910111213141516171819202122232425262728293031// MY_KEY.001 数据库必须字段func (q *Query4Audit) RuleRequiredFields() Rule &#123; var rule = q.RuleOK() switch s := q.Stmt.(type) &#123; case *sqlparser.DDL: if s.Action == \"create\" &#123; if s.TableSpec == nil &#123; return rule &#125; // 必须包含 last_updated_at hitCount := 0 for _, col := range s.TableSpec.Columns &#123; switch col.Name.String() &#123; case \"last_updated_at\": // 检测字段类型 if col.Type.Type != \"datetime\" &amp;&amp; col.Type.Type != \"timestamp\" &#123; return HeuristicRules[\"MY_KEY.001\"] &#125; hitCount++ break &#125; if hitCount != 1 &#123; rule = HeuristicRules[\"MY_KEY.001\"] &#125; &#125; &#125; return rule&#125; 基本思路就是新增 rule, soar 每次执行的时候会遍历 rule 去执行响应的函数检测。编译后可以看看自己的规则是否生效了。 启发规则汇总可以参考另外一篇文章 《soar 启发规则汇总 &amp;&amp; 常见 MySQL 优化案例》","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://rovast.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://rovast.github.io/tags/MySQL/"},{"name":"soar","slug":"soar","permalink":"https://rovast.github.io/tags/soar/"}]},{"title":"linux常用指令和函数备忘录","slug":"forget-linux-commands","date":"2018-12-14T14:19:01.000Z","updated":"2020-11-28T08:49:18.051Z","comments":true,"path":"2018/12/14/forget-linux-commands/","link":"","permalink":"https://rovast.github.io/2018/12/14/forget-linux-commands/","excerpt":"","text":"Commandsdocker12345docker-compose psdocker-compose up -ddocker exec -it HASHID_xxxx bash fg使用 Linux 的 job 功能，在终端使用组合键 ctrl + z 将当前任务挂起。 使用 jobs 查看当前挂起的任务和序号 使用 fg %1 来恢复会话 1234567891011121314151617➜ ~ tail -f debug.log [success]:redis[success]:redis[success]:redis[success]:redis[success]:redis[success]:redis[success]:redis[success]:redis[success]:redis[success]:redis^Z[1] + 13195 suspended tail -f debug.log➜ ~ jobs[1] + suspended tail -f debug.log➜ ~ fg %1[1] + 13195 continued tail -f debug.log git12# git origin 更改了可以用此命令git remote set-url origin git@xxx.com/xxxx netstat12# 查看端口占用netstat -tulpn sudo apt-get install net-tools redis-cli12# redis-cli 指定 host 和端口号redis-cli -h 127.0.0.1 -p 6379 sudo apt-get install redis-tools tc1234567891011# 指定网卡网络延迟 100ms sudo tc qdisc add dev eth0 root netem delay 100ms# 指定网卡丢包率 10%sudo tc qdisc add dev eth0 root netem loss 10%# 如果已经设置过，可以用 changesudo tc qdisc change dev eth0 root netem loss 10%# 移除网卡延迟或丢包设置sudo tc qdisc del dev eth0 root wc12# 统计一个文件的行数cat file.txt | wc -l FunctionskillByName根据名称中的关键字来杀死进程 123function killByName() &#123; sudo kill -9 $(ps -aux | grep $1 | awk '&#123;print $2&#125;')&#125; example: killByName php-fpm 杀死所有 php-fpm munzip解压 windows 下的 zip 文件，用来避免乱码 123function munzip()&#123; unzip -O cp936 $*&#125; example: munzip xxx.zip open在 Ubuntu 上用 open 来打开文件管理器（像 Mac 一样） 123function open()&#123; nautilus $* 1&gt; /dev/null&#125; example: open ~ 打开 home 目录","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/categories/Linux/"}],"tags":[]},{"title":"jmeter 使用入门","slug":"use-jmeter","date":"2018-12-14T10:30:10.000Z","updated":"2020-11-28T08:49:18.087Z","comments":true,"path":"2018/12/14/use-jmeter/","link":"","permalink":"https://rovast.github.io/2018/12/14/use-jmeter/","excerpt":"","text":"引言进行压测时，使用 ab 是个不错的选择，奈何 ab 的报表纬度有时候不能满足需要。除了 ab，我们还可以用 jmeter 呀！ 安装1. 下载压缩包 https://jmeter.apache.org/download_jmeter.cgi 2. 安装 jre Ubuntu sudo apt-get install default-jre 3. 运行 我的包解压目录 /home/rovast/Applications/，运行比较简单，直接运行 /home/rovast/Applications/apache-jmeter-4.0/bin/jmeter.sh 即可 4. 设定 desktop 文件 除了直接运行脚本，我们也可以新建 desktop 文件，这样就可以在应用程序列表中直接找到运行 新建文件 /usr/local/share/applications/jmeter.desktop 123456789[Desktop Entry]Encoding=UTF-8Name=jmeterComment=Apache Jmeter ToolExec=/bin/sh &quot;/home/rovast/Applications/apache-jmeter-4.0/bin/jmeter.sh&quot;Categories=Application;Development;Version=1.0Type=ApplicationTerminal=0 使用运行软件 请确定已经安装 java 环境了 新建测试计划添加测试组，请注意层级关系！不然不能正常工作。 1234567测试计划 线程组 HTTP请求 HTTP信息头管理器 聚合报告 图形结果 查看结果树 HTTP 信息头管理器可以管理 http headers，对于一些把认证放到 header 里的测试很有用 线程组设置一般情况下进行压测，线程数 50, 循环数 10000。什么意思呢？就是位有 50 个线程请求 http，每一个请求 1w 次，总计也就是 50w 次。 开始运行点击工具栏的绿色运行按钮（一般运行前会点击扫帚按钮，清除之前记录），运行完指定循环次数后，就结束了。 查看报告聚合报告。主要关注吞吐量、错误率 图形报告。可以查看响应是否稳定 查看图形树。这里存放了每一个请求，可以看到响应数据","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[]},{"title":"在 phpstorm 中使用 xdebug","slug":"debug-with-xdebug-in-phpstorm","date":"2018-12-11T06:15:39.000Z","updated":"2020-11-28T08:49:18.049Z","comments":true,"path":"2018/12/11/debug-with-xdebug-in-phpstorm/","link":"","permalink":"https://rovast.github.io/2018/12/11/debug-with-xdebug-in-phpstorm/","excerpt":"","text":"前言在开发过程中，如果没有 debug，那是无法想象的。目前调试手段大体有如下几种： 代码中直接输出相关信息，可以是 echo var_dump var_export print_r dd dd 这个函数在 laravel 中直接可用。其他框架需要安装拓展。 使用 var_dump 时，最好结合 &lt;pre&gt; 标签一起使用 输出调试信息至日志，可以是文件日志、数据库日志等 3、使用 xdebug，单步调试，查看运行时变量等。 以上几点各有各的特点和应用场景，无需分出一个优劣。比如： 线上环境，一般不会直接将信息打印出来，更多使用日志调试。例如：微信支付回调 debug xdebug 严重损耗性能，一般在本地使用 本文主要讲述如何在 phpstorm 中使用 xdebug 进行调试 install xdebug extension 进入网址 https://xdebug.org/wizard.php 打开终端， php -i &gt; info.txt，将本机 phpinfo 输出到 info.txt 中 拷贝 info.txt 内容到 1 的输入框中，点击框下面的分析按钮 ubuntu 用户可以使用 gedit 打开，全选复制即可gedit info.txt 分析后，得到安装指引： Summary Xdebug installed: noServer API: Command Line InterfaceWindows: noZend Server: noPHP Version: 7.1.24Zend API nr: 320160303PHP API nr: 20160303Debug Build: noThread Safe Build: noConfiguration File Path: /usr/local/libConfiguration File: /usr/local/lib/php.iniExtensions directory: /usr/local/lib/php/extensions/no-debug-non-zts-20160303 Instructions Download xdebug-2.6.1.tgz Unpack the downloaded file with tar -xvzf xdebug-2.6.1.tgz Run: cd xdebug-2.6.1 Run: phpize (See the FAQ if you don’t have phpize. As part of its output it should show: Configuring for:…Zend Module Api No: 20160303Zend Extension Api No: 320160303If it does not, you are using the wrong phpize. Please follow this FAQ entry and skip the next step. Run: ./configureRun: makeRun: cp modules/xdebug.so /usr/local/lib/php/extensions/no-debug-non-zts-20160303Edit /usr/local/lib/php.ini and add the linezend_extension = /usr/local/lib/php/extensions/no-debug-non-zts-20160303/xdebug.so https://xdebug.org/wizard.php 根据 Instructions 的提示安装即可。 123456cd xdebug-2.6.1phpizemake./configuremakesudo make install 最后得到以下输出信息1234567891011121314151617181920212223Installing shared extensions: /usr/local/lib/php/extensions/no-debug-non-zts-20160303/ +----------------------------------------------------------------------+ | | | INSTALLATION INSTRUCTIONS | | ========================= | | | | See http://xdebug.org/install.php#configure-php for instructions | | on how to enable Xdebug for PHP. | | | | Documentation is available online as well: | | - A list of all settings: http://xdebug.org/docs-settings.php | | - A list of all functions: http://xdebug.org/docs-functions.php | | - Profiling instructions: http://xdebug.org/docs-profiling2.php | | - Remote debugging: http://xdebug.org/docs-debugger.php | | | | | | NOTE: Please disregard the message | | You should add &quot;extension=xdebug.so&quot; to php.ini | | that is emitted by the PECL installer. This does not work for | | Xdebug. | | | +----------------------------------------------------------------------+ php.ini 中加入：1234zend_extension=xdebug.soxdebug.remote_enable = 1xdebug.remote_autostart = 1xdebug.remote_port = 9001 php -m 看加载的模块中是否有 xdebug config in phpstormTODO 解决端口冲突 修改配置后重启 php-fpm 验证配置是否生效Can’t start listening for connections from ‘xdebug’: Port 9000 is busy","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[]},{"title":"谷歌浏览器强制 dev 域名使用 https","slug":"force-dev-domains-to-https-in-chrome","date":"2018-12-10T06:27:47.000Z","updated":"2020-11-28T08:49:18.051Z","comments":true,"path":"2018/12/10/force-dev-domains-to-https-in-chrome/","link":"","permalink":"https://rovast.github.io/2018/12/10/force-dev-domains-to-https-in-chrome/","excerpt":"","text":"前言今天在跑本地项目时，一如既往的配置了 nginx，然后在本地修改了 /etc/hosts nginx server 配置1234567891011121314151617181920212223242526server &#123; listen 80; server_name sample-app.dev; index index.php index.html; error_log /var/log/nginx/sample-app-error.log; access_log /var/log/nginx/sample-app-access.log; root /home/rovast/Code/sample-app/public; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location ~ \\.php &#123; try_files $uri =404; fastcgi_split_path_info ^(.+\\.php)(/.+)$; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_index index.php; fastcgi_pass 127.0.0.1:9000; fastcgi_read_timeout 180; &#125;&#125; /etc/hosts配置1127.0.0.1 sample-app.dev 然后打开 chrome 输入 sample-app.dev。 奇怪的事情发生了，浏览器自动加上了 https，使得我访问的地址变成了 https://sample-app.dev/ 。 然后无法访问了 解决办法还能怎么办呢，谷歌都说了， dev 是人家的，建议我们用其他的域名后缀。我们用 test 吧！ 其实在 valet 中，默认的后缀就是 test nginx server 配置1234567891011121314151617181920212223242526server &#123; listen 80; server_name sample-app.test; index index.php index.html; error_log /var/log/nginx/sample-app-error.log; access_log /var/log/nginx/sample-app-access.log; root /home/rovast/Code/sample-app/public; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location ~ \\.php &#123; try_files $uri =404; fastcgi_split_path_info ^(.+\\.php)(/.+)$; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_index index.php; fastcgi_pass 127.0.0.1:9000; fastcgi_read_timeout 180; &#125;&#125; /etc/hosts配置1127.0.0.1 sample-app.test 参考资料 谷歌论坛 Chrome &amp; Firefox now force .dev domains to HTTPS via preloaded HSTS","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[]},{"title":"深入理解DIP、IoC、DI以及IoC容器","slug":"learning-ioc","date":"2018-12-10T03:28:39.000Z","updated":"2020-11-28T08:49:18.065Z","comments":true,"path":"2018/12/10/learning-ioc/","link":"","permalink":"https://rovast.github.io/2018/12/10/learning-ioc/","excerpt":"","text":"参考资料 《深入理解DIP、IoC、DI以及IoC容器》 《服务容器》 《Understanding Dependency Injection》 《用PHP撸一个DI容器》","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://rovast.github.io/tags/设计模式/"}]},{"title":"PHP 冷门但使用的函数","slug":"cool-php","date":"2018-12-10T02:22:12.000Z","updated":"2020-11-28T09:48:05.630Z","comments":true,"path":"2018/12/10/cool-php/","link":"","permalink":"https://rovast.github.io/2018/12/10/cool-php/","excerpt":"","text":"记录一些平时不怎么用到的，有点 cold 的函数或代码片段 array_walk array_walk 也是对数组的一个遍历，可以拿到 key 和 value，并且返回值是 bool 类型 blog 博客园 《【php学习】array_map，array_walk，array_filter的区别》 example12345678$a = [\"a\" =&gt; 1, \"b\" =&gt; 2];$res = array_walk($a, function(&amp;$v, $k) &#123; echo $k; $v = $v + 1;&#125;);print_r($res); // trueprint_r($a); // [\"a\" =&gt; 2, \"b\" =&gt; 3] clonehttps://stackoverflow.com/questions/10831798/php-deep-clone-object php object 深度拷贝 error_logbool error_log ( string $message [, int $message_type = 0 [, string $destination [, string $extra_headers ]]] ) 把错误信息发送到 web 服务器的错误日志，或者到一个文件里。 @php.netphp.net/manual/zh/function.error-log.php 12345// 记录日志到文件\\error_log('message', 3, '/home/rovast/debug.log');// 记录日志到文件\\error_log('message', 3, '/home/rovast/debug' . \\posix_getpid() . '.log'); 当在开发过程中需要记录日志到文件时，这种方式格外好用。 JsonSerializable 自定义 json_encode 的实现。 blog 鸟哥的博客 《JsonSerializable接口》 list使用 list 可实现类似 go 的多值返回12345678function multi_return() &#123; return [200, 'success'];&#125;list($code, $msg) = multi_return();echo $code; // 200echo $msg; // success 在 php7.1 之后有了一种便捷的写法 [$code, $msg] = multi_return(), 这里的方括号是 list 的简写 register_shutdown_function register_shutdown_function — 注册一个会在php中止时执行的函数 example1234567891011121314151617function shutdown() &#123; echo 'php 脚本运行结束';&#125;register_shutdown_function('shutdown');class Controller &#123; public function responseJson() &#123; echo json_encode(['code' =&gt; 200, 'msg' =&gt; 'success']); exit; &#125;&#125;$controller = new Controller();$controller-&gt;responseJson();// &#123;\"code\":200,\"msg\":\"success\"&#125;php 脚本运行结束 我们手动触发的 exit 最后会去执行 register_shutdown_function 注册的函数。比如在框架中直接 exit 了之后，进行一些回收动作。 set_exception_handler set_exception_handler — 设置用户自定义的异常处理函数。 设置默认的异常处理程序，用于没有用 try/catch 块来捕获的异常。 在 exception_handler 调用后异常会中止。 example // 执行完此函数后，运行终止 function exception_handler($exception) { echo \"自定义异常处理: \" , $exception-&gt;getMessage(), \"\\n\"; } set_exception_handler('exception_handler'); throw new Exception('我来抛出一个异常'); echo \"异常之后的代码\\n\"; // 此行代码不会执行 输出 自定义异常处理: 我来抛出一个异常。 在 exception_handler 后调用异常会终止","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://rovast.github.io/tags/PHP/"}]},{"title":"运用位操作设计权限系统","slug":"bit-operation-in-auth-system","date":"2018-12-10T01:41:41.000Z","updated":"2020-11-28T08:49:18.044Z","comments":true,"path":"2018/12/10/bit-operation-in-auth-system/","link":"","permalink":"https://rovast.github.io/2018/12/10/bit-operation-in-auth-system/","excerpt":"","text":"参考资料 php位运算的权限设计 运用PHP位运算做网站权限 位运算符","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[]},{"title":"科学上网之 Shadowsocks 安装及优化加速","slug":"install-shadowsocks","date":"2018-12-09T12:04:45.000Z","updated":"2020-11-28T08:49:18.065Z","comments":true,"path":"2018/12/09/install-shadowsocks/","link":"","permalink":"https://rovast.github.io/2018/12/09/install-shadowsocks/","excerpt":"","text":"本文转载自 《科学上网之 Shadowsocks 安装及优化加速》 原文地址： https://yq.aliyun.com/articles/137280?commentId=11711 Shadowsocks使用自行设计的协议进行加密通信。加密算法有AES、Blowfish、IDEA、RC4等，除创建TCP连接外无需握手，每次请求只转发一个连接，因此使用起来网速较快，在移动设备上也比较省电。所有的流量都经过算法加密，允许自行选择算法，所以比较安全。Shadowsocks通过异步I/O和事件驱动程序运行，响应速度快。客户端覆盖多个主流操作系统和平台，包括Windows，OS X，Android和iOS系统和路由器（OpenWrt）等 专为移动设备和无线网络优化 0. 更换算法为 chacha2012345678yum groupinstall \"Development Tools\"wget https://download.libsodium.org/libsodium/releases/LATEST.tar.gztar zxvf LATEST.tar.gz &amp;&amp; cd LATEST./configure &amp;&amp; make -j4 &amp;&amp; make installecho /usr/local/lib &gt; /etc/ld.so.conf.d/usr_local_lib.confldconfig 1. 服务端安装官方推荐 Ubuntu 14.04 LTS 作为服务器以便使用 TCP Fast Open。服务器端的安装非常简单。 Debian / Ubuntu:12apt-get install python-pippip install shadowsocks CentOS:12yum install python-setuptools &amp;&amp; easy_install pippip install shadowsocks 然后直接在后台运行： ssserver -p 38018 -k password -m rc4-md5 -d start 当然也可以使用配置文件进行配置，方法创建/etc/shadowsocks.json文件，填入如下内容： 123456789&#123; \"server\":\"0.0.0.0\", \"server_port\":38018, \"local_address\": \"127.0.0.1\", \"local_port\":1080, \"password\":\"mypassword\", \"timeout\":300, \"method\":\"rc4-md5\"&#125; 然后使用配置文件在后台运行： ssserver -c /etc/shadowsocks.json -d start 如果要停止运行，将命令中的start改成stop。 TIPS: 加密方式推荐使用rc4-md5，因为 RC4 比 AES 速度快好几倍，如果用在路由器上会带来显著性能提升。旧的 RC4 加密之所以不安全是因为 Shadowsocks 在每个连接上重复使用 key，没有使用 IV。现在已经重新正确实现，可以放心使用。更多可以看 issue。 2. 多用户配置网上很多用户vps安装的Linux是debian或ubuntu的，所以可以通过修改/etc/shadowsock.json文件，通过添加端口号以及密码的方法，进行多用户配置。这种配置方案，网上可以搜出很多。我这里也粘贴一下具体修改json文件的方法.示例如下 1234567891011121314&#123; \"server\":\"0.0.0.0\"， \"local_address\": \"127.0.0.1\", \"local_port\":1080, \"port_password\": &#123; \"38011\": \"passwd\", \"38012\": \"passwd\", \"38013\": \"passwd\", \"38014\": \"passwd\" &#125;, \"timeout\":300, \"method\":\"rc4-md5\", \"fast_open\": false &#125; 3. 加速优化下面介绍几种简单的优化方法，也是比较推荐的几种，能够得到立竿见影的效果。当然还有一些黑科技我没提到，如有大神路过，也可留言指出。 3.1 内核参数优化首先，将 Linux 内核升级到 3.5 或以上。 第一步，增加系统文件描述符的最大限数 编辑文件 limits.conf vi /etc/security/limits.conf 增加以下两行 12* soft nofile 51200* hard nofile 51200 启动shadowsocks服务器之前，设置以下参数 ulimit -n 51200 第二步，调整内核参数 修改配置文件 /etc/sysctl.conf 123456789101112131415161718fs.file-max = 51200net.core.rmem_max = 67108864net.core.wmem_max = 67108864net.core.netdev_max_backlog = 250000net.core.somaxconn = 4096net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 0net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1200net.ipv4.ip_local_port_range = 10000 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_fastopen = 3net.ipv4.tcp_rmem = 4096 87380 67108864net.ipv4.tcp_wmem = 4096 65536 67108864net.ipv4.tcp_mtu_probing = 1net.ipv4.tcp_congestion_control = hybla 修改后执行 sysctl -p 使配置生效 3.2 锐速锐速是一款非常不错的TCP底层加速软件，可以非常方便快速地完成服务器网络的优化，配合 ShadowSocks 效果奇佳。目前锐速官方也出了永久免费版本，适用带宽20M、3000加速连接，个人使用是足够了。如果需要，先要在锐速官网注册个账户。 然后确定自己的内核是否在锐速的支持列表里，如果不在，请先更换内核，如果不确定，请使用 手动安装。 确定自己的内核版本在支持列表里，就可以使用以下命令快速安装了。 123wget http://my.serverspeeder.com/d/ls/serverSpeederInstaller.tar.gztar xzvf serverSpeederInstaller.tar.gzbash serverSpeederInstaller.sh 输入在官网注册的账号密码进行安装，参数设置直接回车默认即可，最后两项输入 y 开机自动启动锐速，y 立刻启动锐速。之后可以通过lsmod查看是否有appex模块在运行。到这里还没结束，我们还要修改锐速的3 个参数， 123456vi /serverspeeder/etc/configrsc=\"1\" #RSC网卡驱动模式 advinacc=\"1\" #流量方向加速 maxmode=\"1\" #最大传输模式digitalocean vps的网卡支持rsc和gso高级算法，所以可以开启rsc=\"1\"，gso=\"1\"。 重新启动锐速 service serverSpeeder restart 3.3 net-speedernet-speeder 原理非常简单粗暴，就是发包翻倍，这会占用大量的国际出口带宽，本质是损人利己，不建议使用。 (1) Ubuntu/Debian 下安装依赖包 1234apt-get install libnet1apt-get install libpcap0.8apt-get install libnet1-devapt-get install libpcap0.8-dev (2) Centos 下安装依赖包 需要配置 epel 第三方源。下载 epel ：http://dl.fedoraproject.org/pub/epe l/ 。例如，Centos 7 x64： 1234wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpmrpm -ivh epel-release-7-5.noarch.rpmyum repolist 然后安装依赖包： yum install libnet libpcap libnet-devel libpcap-devel (3) 下载官方的 tar.gz 压缩包。解压安装运行： 12345wget http://net-speeder.googlecode.com/files/net_speeder-v0.1.tar.gz tar zxvf net_speeder-v0.1.tar.gzcd net_speederchmod 777 *sh build.sh -DCOOKED 首先你需要知道你的网卡设备名，可以使用 ifconfig 查看。假设是eth0， 那么运行方法是: ./net_speeder eth0 &quot;ip&quot; 关闭 net-speeder killall net_speeder 哦，对了，作者已经将 net-speeder 迁移到 GitHub 了，感兴趣的可以关 注、贡献。以上几种方法是我用过的几种比较有效的加速方法。有任何错误之处还请在下面留言指出。 如果你不想折腾服务端安装和优化，你可以使用虫洞咖啡厅提供的免费 shadowsocks 服务。 一键安装脚本连接地址 https://teddysun.com/486.html 123wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.shchmod +x shadowsocks-all.sh./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://rovast.github.io/tags/转载/"}]},{"title":"软件合集","slug":"software-collection","date":"2018-12-07T10:38:21.000Z","updated":"2020-11-28T08:49:18.083Z","comments":true,"path":"2018/12/07/software-collection/","link":"","permalink":"https://rovast.github.io/2018/12/07/software-collection/","excerpt":"","text":"command tool albert axel git gitk oh-my-zsh tig tmux zsh axel1axel -n 10 -a https://download.url proxyscript1234567891011function openproxy() &#123; export https_proxy=https://127.0.0.1:1080 export http_proxy=http://127.0.0.1:1080 export all_proxy=socks5://127.0.0.1:1080&#125;function offproxy() &#123; unset https_proxy unset http_proxy unset all_proxy&#125; killByNamescript123function killByName() &#123; sudo kill -9 $(ps -aux | grep $1 | awk '&#123;print $2&#125;')&#125; Gnomeextensions Clipboard Indicator Dash to dock Screenshot Tool Topicons plus Unite User themes themes Mojave-light Mojave-dark Linux GUI software calibre goland kchmViewer phpstorm OBS Studio （录屏软件） Typora XMind ZEN PhpStormuseful command reset to factory settings rm -rf ~/.PhpStorm2018.3 some path app cache path ~/.PhpStorm2018.3 /Users/rovast/Library/Preferences/PhpStorm2018.3 keymap path ~/.PhpStorm2018.3/config/keymaps/ /Users/rovast/Library/Preferences/PhpStorm2018.3/keymaps keymap sublime plugins DynamicReturnTypePlugin CodeGlance Material Theme UI Atom One Dark color:#7F7CE9 WebStorm配置 webpack 别名 vue cli3 下的 @ alias 解决方案 https://intellij-support.jetbrains.com/hc/en-us/community/posts/360000578284--alias-in-vue-cli-3-projects 打开 webpack 配置，即 ctrl + shift + p 输入 node_modules/@vue/cli-service/webpack.config.js .desktop Jetbrains 家族创建桌面快捷方式，可以直接 tools -&gt; create desktop entry 即可 /usr/share/applications 新建 .desktop 文件 12345678910[Desktop Entry]Encoding=UTF-8Name=phpstorm IDEComment=The Smarter Way to CodeExec=/bin/sh &quot;/home/rovast/Software/PhpStorm-182.4129.45/bin/phpstorm.sh&quot;Icon=/home/rovast/Software/PhpStorm-182.4129.45/bin/phpstorm.pngCategories=Application;Development;Java;IDEVersion=1.0Type=ApplicationTerminal=0 QA 文件导航失效（intellij-navigate-to-file-stopped-working） 点击菜单 File | Invalidate Caches ，然后 restart 即可 参考： https://stackoverflow.com/questions/10588408/intellij-navigate-to-file-stopped-working Wechatwindows 微信多开 替换路径即可 1234567@echo offstart /d &quot;C:\\Program Files (x86)\\Tencent\\WeChat\\&quot; wechat.exestart /d &quot;C:\\Program Files (x86)\\Tencent\\WeChat\\&quot; wechat.exeexit MacOS 微信多开 12#!/bin/bashopen -n /Applications/WeChat.app/Contents/MacOS/WeChat &amp;&amp; open -n /Applications/WeChat.app/Contents/MacOS/WeChat NginxNginx 配置跨域script1234567891011121314151617181920212223242526272829server &#123; listen 80; server_name demo.test; index index.php index.html; error_log /var/log/nginx/demo-error.log; access_log /var/log/nginx/demo-access.log; root /home/rovast/Code/demo/public; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location ~ \\.php &#123; add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS, PUT'; try_files $uri =404; fastcgi_split_path_info ^(.+\\.php)(/.+)$; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_index index.php; fastcgi_pass 127.0.0.1:9000; fastcgi_read_timeout 180; &#125;&#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://rovast.github.io/categories/工具/"}],"tags":[]},{"title":"二进制运算","slug":"binary-operation","date":"2018-12-07T10:34:26.000Z","updated":"2020-11-28T08:49:18.044Z","comments":true,"path":"2018/12/07/binary-operation/","link":"","permalink":"https://rovast.github.io/2018/12/07/binary-operation/","excerpt":"","text":"二进制逻辑运算逻辑加法（“或”运算）逻辑加法通常用符号“+”或“∨”来表示。逻辑加法运算规则如下：12340+0=0， 0∨0=00+1=1， 0∨1=11+0=1， 1∨0=11+1=1， 1∨1=1 从上式可见，逻辑加法有“或”的意义。也就是说，在给定的逻辑变量中，A或B只要有一个为1，其逻辑加的结果就为1；只有当两者都为0时逻辑加的结果才为0。 逻辑乘法（“与”运算）逻辑乘法通常用符号“×”或“∧”或“·”来表示。逻辑乘法运算规则如下：12340×0=0， 0∧0=0， 0·0=00×1=0， 0∧1=0， 0·1=01×0=0， 1∧0=0， 1·0=01×1=1， 1∧1=1， 1·1=1 不难看出，逻辑乘法有“与”的意义。它表示只当参与运算的逻辑变量都同时取值为1时，其逻辑乘积才等于1。 异或逻辑运算（“半加”运算）异或运算通常用符号”⊕”表示，其运算规则为：12340⊕0=0 0同0异或，结果为00⊕1=1 0同1异或，结果为11⊕0=1 1同0异或，结果为11⊕1=0 1同1异或，结果为0 即两个逻辑变量相异，输出才为1 反码将二进制数反转，得到的数即为原二进制的反码（ones’ complement）。若某一位为0，则使其变为1，反之亦然。 例如，+3是0011，用反码表示-3便是1100。 下表列出了4-bit二进数所能表示的整数。wiki 反码 二进数 无符号 符号比特 反码 0000 0 0 0 0001 1 1 1 0010 2 2 2 0011 3 3 3 0100 4 4 4 0101 5 5 5 0110 6 6 6 0111 7 7 7 1000 8 -0 -7 1001 9 -1 -6 1010 10 -2 -5 1011 11 -3 -4 1100 12 -4 -3 1101 13 -5 -2 1110 14 -6 -1 1111 15 -7 -0 补码wiki 补码 补码（英语：2’s complement）是一种用二进制表示有号数的方法，也是一种将数字的正负号变号的方式，常在计算机科学中使用。 一个数字的补码就是将该数字作比特反相运算（即反码），再将结果加1。即：反码加1 。在补码系统中，一个负数就是用其对应正数的补码来表示。 以下用4位的补码数字来说明补码系统的数字表示方式 在表示正数和零时，补码数字和一般二进制一样，唯一的不同是在补码系统中，正数的最高比特恒为0，因此4位的补码正数，最大数字为0111 (7)。 补码数字的负数，最高比特恒为1，4位补码的数字中，最接近0的负数为1111 (-1)，以此类推，因此绝对值最大的负数是1000(-8)。 以上的表示方式在计算机处理时格外方便，用以下的例子说明：1234 0011 ( 3) + 1111 (-1)-------------- 10010 ( 2) 结果10010似乎是错的，因为已经超过四个比特，不过若忽略掉（从右数起的）第5个比特，结果是0010 (2)，和我们计算的结果一样。而且若可以将二进制的1111 (-1)变号为0001 (1)，以上的式子也可以计算减法：3-1 = 2。 运算加法 二补数系统数字的加法和一般加法相同，而且在运算完成后就可以看出结果的正负号，不需特别的处理。 正数与负数相加不会出现上溢错误，因为它们的和一定会小于加数。只有在两个同正负号的数相加时，上溢错误才有可能发生，这时候它们的和与加数的正负号相反。 以15加 -5为例：12345 11111 111（进位） 0000 1111 (15)+ 1111 1011 (-5)================== 0000 1010 (10) 由于加数和被加数都是8位，因此运算结果也限制在8位内。第8位相加后产生的进位不考虑（因为不存在第9比特）的1被忽略，所以其结果为10。而15 + (-5) = 10，计算结果正确。 在以上计算式中，可以由进位列的最左侧二个比特得知结果是否出现溢出。溢出就是数字的绝对值太大，以致于无法在指定的二进制比特个数来表示（在此例中，是超过8位的范围）。若进位列的最左侧二个比特同为0或同为1，表示结果正确，若是一个为0，另一个为1，表示出现溢出错误。也可以对此二个比特进行异或运算，结果为1时，表示出现溢出错误。以下以7 + 3的4位加法说明溢出错误的情形。 12345 0111 (进位) 0111 (7)+ 0011 (3)============= 1010 (−6) 结果不正确！在此例中，进位列的最左侧二个比特为01，因此出现溢出错误。溢出的原因是7 + 3的结果(10)超过补码系统4位所可以表示的数字范围 -8~7。 故为防止溢出错误，二补数在进行加法运算时通常讲符号位进行复制后追加到最高位之前，即设二补数B的位数为WIDTH，则B′={B[WIDTH-1],B}。应注意此处B′的位数为WIDTH+1。 如上两例用此方法进行计算： 12345 11 1111 111（进位） 0 0000 1111 (15) +1 1111 1011 (-5) ==================(1)0 0000 1010 (10) 由于WIDTH+1=8+1=9，故而第十位的1同样由于溢出而被省略，结果仍为10。两负数(符号位为1)相加时同理。 12345 111 (进位) 0 0111 (7)+0 0011 (3)============= 0 1010 (10) 结果正确！由于WIDTH+1=4+1=5，故第五位的0仍为符号位，得结果正数10(十进制)。 减法 减法通常转化为加法进行运算，将减数取补之后，再与被减数进行加法运算，即可得出差。 乘法 乘法在计算机的世界里其实就是不断的做加法。 例如:3*5=3+3+3+3+3=15 除法 除法就是相减。 例如:10/3=10-3-3-3=1mod3 而减法又可做二的补数相加，所以所有四则运算的基础都是由加法而来。 补码的工作原理为什么补码能这么巧妙实现了正负数的加减运算？答案是：指定n比特字长，那么就只有2n个可能的值，加减法运算都存在上溢出与下溢出的情况，实际上都等价于模2n的加减法运算。这对于n比特无符号整数类型或是n比特有符号整数类型都同样适用。 例如，8位无符号整数的值的范围是0到255.因此4+254将上溢出，结果是2，即(4+254) \\equiv 258 \\equiv 2 \\pmod{256}。 例如，8位有符号整数的值的范围，如果规定为−128到127,则126+125将上溢出，结果是−5，即(126+125) \\equiv 251 \\equiv -5 \\pmod{256}。 对于8位字长的有符号整数类型，以28即256为模，则 12345-128 &amp; \\equiv 128 \\pmod&#123;256&#125; \\\\-127 &amp; \\equiv 129 \\pmod&#123;256&#125; \\\\-2 &amp; \\equiv 254 \\pmod&#123;256&#125; \\\\-1 &amp; \\equiv 255 \\pmod&#123;256&#125; \\\\ 所以模256下的加减法，用0, 1, 2,…, 254,255表示其值，或者用−128, −127,…, −1, 0, 1, 2,…,127是完全等价的。−128与128，−127与129，…，−2与254，−1与255可以互换而加减法的结果不变。从而，把8位（octet）的高半部分（即二进制的1000 0000到1111 1111）解释为−128到−1，同样也实现了模256的加减法，而且所需要的CPU加法运算器的电路实现与8位无符号整数并无不同。 实际上对于8比特的存储单元，把它的取值[00000000,…, 11111111]解释为[0, 255],或者[-1, 254]，或者[-2, 253]，或者[-128, 127]，或者[-200, 55]，甚至或者[500, 755]，对于加法硬件实现并无不同。","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[]},{"title":"mac 上配置 nginx 端口转发访问 angular 项目","slug":"nginx-proxy-on-mac","date":"2018-12-06T13:03:01.000Z","updated":"2020-11-28T08:49:18.067Z","comments":true,"path":"2018/12/06/nginx-proxy-on-mac/","link":"","permalink":"https://rovast.github.io/2018/12/06/nginx-proxy-on-mac/","excerpt":"","text":"背景在进行前端的移动端开发时，需要在手机上预览电脑上的项目。以 angular 为例，默认启动项目后，在开发机（以 Mac 为例）的浏览器地址栏输入 http://localhost:4200 即可访问。 我们假设前端默认开启的端口号是4200 如果想要在手机上访问，我们先确保手机和 Mac 链接的同一个网络（链接同一个 WIFI 即可），Mac 上输入 12# 查看本机 ip 地址ifconfig 输出1234567en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 ether f0:xxxxxxxx inet6 xxxxxxxx prefixlen 64 secured scopeid 0xa inet 192.168.1.102 netmask 0xffffff00 broadcast 192.168.1.255 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: active 我们看到，我们 ip 为 192.168.1.102。那么我们直接在手机浏览器输入 http://192.168.1.102:4200，发现并不能访问。理论上，我们可以修改 webpack 或者其他的一些配置来使手机正常访问。这里，我们采用另一种方式来解决，即：Nginx 端口转发。 使用 Nginx 进行端口转发1. 安装 Nginx1brew install nginx 2. 新建配置文件12345# 进入 nginx server 配置目录cd /usr/local/etc/nginx/servers# 新建配置文件sudo vi fe.conf 在打开的 vi 编辑器中进行下述操作 分别输入 : i，看到编辑器左下角进入 ‘INSERT’ 模式 输入下述内容1234567server &#123; listen 8888; server_name localhost; location / &#123; proxy_pass http://127.0.0.1:4200; &#125; &#125; 其中 8888 表示我们希望手机端访问的端口号，而 4200 表示开发环境中 angular 实际的端口号 3. 重启 Nginx12# 重启 nginx 服务sudo brew services restart nginx 4. 验证结果12# 查看本机已经打开的所有端口netstat -an | grep -i listen 输入的结果类似于12345678➜ servers showportstcp4 0 0 *.8888 *.* LISTENtcp4 0 0 *.8080 *.* LISTENtcp4 0 0 127.0.0.1.4200 *.* LISTENtcp6 0 0 *.50306 *.* LISTENtcp4 0 0 *.50306 *.* LISTENtcp4 0 0 127.0.0.1.4301 *.* LISTENtcp4 0 0 127.0.0.1.4300 *.* LISTEN 我们看到第一行就有 *.8888，表示成功了！ 5 手机端访问确保手机端和 Mac 在同一局域网后，手机端访问 http://192.168.1.102:8888/ 即可 DONE!","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://rovast.github.io/tags/nginx/"}]},{"title":"makefile 中 竖线、|、管道符的作用","slug":"pipe-symbol-in-makefile","date":"2018-12-04T10:07:53.000Z","updated":"2020-11-28T08:49:18.081Z","comments":true,"path":"2018/12/04/pipe-symbol-in-makefile/","link":"","permalink":"https://rovast.github.io/2018/12/04/pipe-symbol-in-makefile/","excerpt":"","text":"最近在看一个开源项目时，被 makefile 里的一个小问题困扰了好久。搜索良久，终于找到了权威的解释，特此记录下。 那就是，makefile 中管道符号（|）的作用。 以下摘自 https://www.gnu.org/software/make/manual/make.html ， 4.3 Types of PrerequisitesThere are actually two different types of prerequisites understood by GNU make: normal prerequisites such as described in the previous section, and order-only prerequisites. A normal prerequisite makes two statements: first, it imposes an order in which recipes will be invoked: the recipes for all prerequisites of a target will be completed before the recipe for the target is run. Second, it imposes a dependency relationship: if any prerequisite is newer than the target, then the target is considered out-of-date and must be rebuilt. Normally, this is exactly what you want: if a target’s prerequisite is updated, then the target should also be updated. Occasionally, however, you have a situation where you want to impose a specific ordering on the rules to be invoked without forcing the target to be updated if one of those rules is executed. In that case, you want to define order-only prerequisites. Order-only prerequisites can be specified by placing a pipe symbol (|) in the prerequisites list: any prerequisites to the left of the pipe symbol are normal; any prerequisites to the right are order-only: targets : normal-prerequisites | order-only-prerequisites The normal prerequisites section may of course be empty. Also, you may still declare multiple lines of prerequisites for the same target: they are appended appropriately (normal prerequisites are appended to the list of normal prerequisites; order-only prerequisites are appended to the list of order-only prerequisites). Note that if you declare the same file to be both a normal and an order-only prerequisite, the normal prerequisite takes precedence (since they have a strict superset of the behavior of an order-only prerequisite). Consider an example where your targets are to be placed in a separate directory, and that directory might not exist before make is run. In this situation, you want the directory to be created before any targets are placed into it but, because the timestamps on directories change whenever a file is added, removed, or renamed, we certainly don’t want to rebuild all the targets whenever the directory’s timestamp changes. One way to manage this is with order-only prerequisites: make the directory an order-only prerequisite on all the targets: 123456789101112OBJDIR := objdirOBJS := $(addprefix $(OBJDIR)/,foo.o bar.o baz.o)$(OBJDIR)/%.o : %.c $(COMPILE.c) $(OUTPUT_OPTION) $&lt;all: $(OBJS)$(OBJS): | $(OBJDIR)$(OBJDIR): mkdir $(OBJDIR) Now the rule to create the objdir directory will be run, if needed, before any ‘.o’ is built, but no ‘.o’ will be built because the objdir directory timestamp changed. 可能需要的单词列表 prerequisites 先决条件 Occasionally 偶然的 impose 强制 invoked 引用 recipes 方法","categories":[{"name":"编程","slug":"编程","permalink":"https://rovast.github.io/categories/编程/"}],"tags":[{"name":"makefile","slug":"makefile","permalink":"https://rovast.github.io/tags/makefile/"},{"name":"管道","slug":"管道","permalink":"https://rovast.github.io/tags/管道/"}]},{"title":"gnome主题推荐macOS Mojave","slug":"gnome-theme-macos-mojave","date":"2018-12-04T09:51:09.000Z","updated":"2020-11-28T08:49:18.052Z","comments":true,"path":"2018/12/04/gnome-theme-macos-mojave/","link":"","permalink":"https://rovast.github.io/2018/12/04/gnome-theme-macos-mojave/","excerpt":"","text":"效果预览 其实 gnome 折腾主题出乎意料的方便，基本在 gnome-look 网站上看好了，下载到指定目录就完事了。下面推荐一款 macOS Mojave 的主题，仿真度还是蛮高的。 网址：https://www.opendesktop.org/p/1275087/ 下载对应文件即可 解压后，放到以下目录 主题目录： ~/.themes 图标目录： ~/.icons 然后就 ok 了","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"gnome","slug":"gnome","permalink":"https://rovast.github.io/tags/gnome/"}]},{"title":"linux根据进程名称杀死进程","slug":"linux根据进程名称杀死进程","date":"2018-12-04T09:17:21.000Z","updated":"2020-11-28T08:49:18.065Z","comments":true,"path":"2018/12/04/linux根据进程名称杀死进程/","link":"","permalink":"https://rovast.github.io/2018/12/04/linux根据进程名称杀死进程/","excerpt":"","text":"我们知道，通过 kill -9 PID 命令可以指定 pid 的进程，如果我们只知道进程的名称怎么杀死呢？ 通过 pkill 也能根据名称杀死，感兴趣的读者可以自行搜索下 思路 根据名称找出需要杀死的进程列表 ps -aux | grep 列出 pid 列表 awk 调用 kill 杀死进程 示例杀死包含名称为 phpstorm 的所有进程（其实就是强制关闭 phpstorm，在 phpstorm 假死时很有用） 先找出名为 phpstorm 的进程列表1ps -aux | grep phpstorm 打印出 pid 列表1ps -aux | grep phpstorm | awk '&#123;print $2&#125;' 杀死1sudo kill -9 $(ps -aux | grep phpstorm | awk '&#123;print $2&#125;') 其实就是把结果的列表用 $ 包裹起来作为一个变量，然后 kill -9 会把那些结果都用起来。awk 中的 $2 表示结果的第二列，也就是 id 列，试着改成 $1，就会打印出第一列，即 rovast 总结我们可以加一个函数，便于直接调用，在 ~/.bashrc 或者是 ~/.zshrc 中加入下述函数 123function killByName() &#123; sudo kill -9 $(ps -aux | grep $1 | awk '&#123;print $2&#125;')&#125; 这样，杀死 phpstorm 可以简化为 killByName phpstorm 函数中的 $1 表示拿到命令行 killByName 后的第一个参数，即 phpstorm，之后会执行 sudo kill -9 $(ps -aux | grep phpstorm | awk ‘{print $2}’) 这里主要需要注意下述指令 ps grep awk 在删除已退出 docker 容器时，也用到了此类方法 1docker rm $(docker ps -a | grep Exit | awk '&#123;print $1&#125;') 其实就是把 docker ps -a | grep Exit 的第一行结果（就是hashid列表）提取出来，用 docker rm 删掉这些结果。 我们同样可以写一个函数，这里就不写了，需要的童鞋自己根据 killByName 应该能写出来。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rovast.github.io/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://rovast.github.io/tags/linux/"},{"name":"kill","slug":"kill","permalink":"https://rovast.github.io/tags/kill/"}]},{"title":"Ubuntu18.04安装深度截图","slug":"Ubuntu18-04安装深度截图","date":"2018-12-03T13:04:15.000Z","updated":"2020-11-28T08:49:18.042Z","comments":true,"path":"2018/12/03/Ubuntu18-04安装深度截图/","link":"","permalink":"https://rovast.github.io/2018/12/03/Ubuntu18-04安装深度截图/","excerpt":"","text":"Ubuntu默认的截图可以使用 shift + printScreen 组合键来截取区域截图，保存在图片文件夹中。但是， 我觉得还是深度截图好用。 1. 下载deb包访问 http://packages.linuxdeepin.com/deepin/pool/main/d/deepin-scrot/ 下载 deepin-scrot_2.0-0deepin_all.deb 或者直接 wget http://packages.linuxdeepin.com/deepin/pool/main/d/deepin-scrot/deepin-scrot_2.0-0deepin_all.deb 2019年06月17日 更新 上面的链接失效了，现在上传了这个 deb 包，点击可下载 deepin-scrot_2.0-0deepin_all.deb 2. 安装1234sudo dpkg -i deepin-scrot_2.0-0deepin_all.deb# 出现依赖问题sudo apt-get -f install 3. 安装其他一些依赖123sudo apt-get install qt5-qmake qttools5-dev qt5-default \\qtbase5-dev python-gtk2 python-gtk2-dbg python-gtk2-dev \\python-gtk2-doc libcanberra-gtk-dev 4. 使用命令行运行 deepin-scrot 即可 也可以自定义快捷键 （我的是 Ctrl Shift A）","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://rovast.github.io/tags/ubuntu/"},{"name":"截图","slug":"截图","permalink":"https://rovast.github.io/tags/截图/"}]},{"title":"解决命令行中方向键及小键盘不可用的问题","slug":"解决命令行中方向键及小键盘不可用的问题","date":"2018-11-27T12:37:24.000Z","updated":"2020-11-28T08:49:18.090Z","comments":true,"path":"2018/11/27/解决命令行中方向键及小键盘不可用的问题/","link":"","permalink":"https://rovast.github.io/2018/11/27/解决命令行中方向键及小键盘不可用的问题/","excerpt":"","text":"最近在使用 Laravel 的 tinker 的时候，出现输入方向键或者是小键盘的时候，显示类似 ^[[A ^[[B 的情况，特此记录。 在 Google 一番搜索后，找到解决方案：https://stackoverflow.com/questions/28733733/arrow-keys-not-working-in-shell 使用下述命令打开即可：1rlwrap php artisan tinker 如果本机未安装 rlwrap，可以自行安装12345# debiansudo apt-get install rlwrap# centossudo yum install rlwrap 记录点滴，避免重复爬坑","categories":[{"name":"杂项","slug":"杂项","permalink":"https://rovast.github.io/categories/杂项/"}],"tags":[{"name":"laravel","slug":"laravel","permalink":"https://rovast.github.io/tags/laravel/"},{"name":"命令行","slug":"命令行","permalink":"https://rovast.github.io/tags/命令行/"},{"name":"tinker","slug":"tinker","permalink":"https://rovast.github.io/tags/tinker/"}]}]}